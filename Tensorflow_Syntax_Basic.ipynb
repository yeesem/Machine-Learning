{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEu/m638ipNLyC2wJhO0mj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeesem/Machine-Learning/blob/main/Tensorflow_Syntax_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aWVOVFSzk-Tu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/yeesem/Machine-Learning-Datasets/main/Housing.csv')"
      ],
      "metadata": {
        "id": "kad6yaRQlOMH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "sQL-8LyAmkiT",
        "outputId": "c7a89953-9973-4252-e4d1-e7c46eaad728"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
              "0  13300000  7420         4          2        3      yes        no       no   \n",
              "1  12250000  8960         4          4        4      yes        no       no   \n",
              "2  12250000  9960         3          2        2      yes        no      yes   \n",
              "3  12215000  7500         4          2        2      yes        no      yes   \n",
              "4  11410000  7420         4          1        2      yes       yes      yes   \n",
              "\n",
              "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
              "0              no             yes        2      yes        furnished  \n",
              "1              no             yes        3       no        furnished  \n",
              "2              no              no        2      yes   semi-furnished  \n",
              "3              no             yes        3      yes        furnished  \n",
              "4              no             yes        2       no        furnished  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-f9ae3d04-95d2-48a0-b72f-102434db5fe9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>area</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>stories</th>\n",
              "      <th>mainroad</th>\n",
              "      <th>guestroom</th>\n",
              "      <th>basement</th>\n",
              "      <th>hotwaterheating</th>\n",
              "      <th>airconditioning</th>\n",
              "      <th>parking</th>\n",
              "      <th>prefarea</th>\n",
              "      <th>furnishingstatus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13300000</td>\n",
              "      <td>7420</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>furnished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12250000</td>\n",
              "      <td>8960</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>furnished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12250000</td>\n",
              "      <td>9960</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>semi-furnished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12215000</td>\n",
              "      <td>7500</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>yes</td>\n",
              "      <td>furnished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11410000</td>\n",
              "      <td>7420</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>furnished</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9ae3d04-95d2-48a0-b72f-102434db5fe9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-c56f561d-1de1-4c3d-8afa-d0aa879bf443\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c56f561d-1de1-4c3d-8afa-d0aa879bf443')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-c56f561d-1de1-4c3d-8afa-d0aa879bf443 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9ae3d04-95d2-48a0-b72f-102434db5fe9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9ae3d04-95d2-48a0-b72f-102434db5fe9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "6vCWn47Iml_f",
        "outputId": "4697e177-2f07-4a7c-ef1b-a18612810d57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.PairGrid at 0x7e3604974f40>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 42 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(df[['price','bedrooms','bathrooms']])"
      ],
      "metadata": {
        "id": "NwSHMnGUoA1z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hrAldJKWoN-W",
        "outputId": "dba5fe53-cd4a-45c0-b4bf-aa076d4581c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      price  bedrooms  bathrooms\n",
              "0  13300000         4          2\n",
              "1  12250000         4          4\n",
              "2  12250000         3          2\n",
              "3  12215000         4          2\n",
              "4  11410000         4          1"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-1bd6d279-3d88-4f70-b432-9aec6fd23449\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13300000</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12250000</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12250000</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12215000</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11410000</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bd6d279-3d88-4f70-b432-9aec6fd23449')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-8273eddd-89f2-4615-a287-37b0b2b1f346\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8273eddd-89f2-4615-a287-37b0b2b1f346')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-8273eddd-89f2-4615-a287-37b0b2b1f346 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1bd6d279-3d88-4f70-b432-9aec6fd23449 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1bd6d279-3d88-4f70-b432-9aec6fd23449');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['bathrooms','bedrooms']].values"
      ],
      "metadata": {
        "id": "3wfCq0gypCHn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-AvjFQypNWw",
        "outputId": "3c85dca2-5aa9-4185-fc07-ef6c33256fe7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 4],\n",
              "       [4, 4],\n",
              "       [2, 3],\n",
              "       ...,\n",
              "       [1, 2],\n",
              "       [1, 3],\n",
              "       [1, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['price'].values"
      ],
      "metadata": {
        "id": "MC95p7LmoiNJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tNpgC4CtnNM7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=101)"
      ],
      "metadata": {
        "id": "KCdC5Sc5ngp9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkJAe3xnovbX",
        "outputId": "191ef042-acc2-4f55-9340-9693d5f0bdf0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(381, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWRX11pQsGY4",
        "outputId": "19bfb5be-e72f-411f-bc6e-db954167adde"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(164, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "Qg0433-OsJAn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Explanation of MinMaxScaler\n",
        "help(MinMaxScaler)"
      ],
      "metadata": {
        "id": "zf6qf6d3sWJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a52128c-633a-426f-d255-38d00862a865"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class MinMaxScaler in module sklearn.preprocessing._data:\n",
            "\n",
            "class MinMaxScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
            " |  MinMaxScaler(feature_range=(0, 1), *, copy=True, clip=False)\n",
            " |  \n",
            " |  Transform features by scaling each feature to a given range.\n",
            " |  \n",
            " |  This estimator scales and translates each feature individually such\n",
            " |  that it is in the given range on the training set, e.g. between\n",
            " |  zero and one.\n",
            " |  \n",
            " |  The transformation is given by::\n",
            " |  \n",
            " |      X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
            " |      X_scaled = X_std * (max - min) + min\n",
            " |  \n",
            " |  where min, max = feature_range.\n",
            " |  \n",
            " |  This transformation is often used as an alternative to zero mean,\n",
            " |  unit variance scaling.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  feature_range : tuple (min, max), default=(0, 1)\n",
            " |      Desired range of transformed data.\n",
            " |  \n",
            " |  copy : bool, default=True\n",
            " |      Set to False to perform inplace row normalization and avoid a\n",
            " |      copy (if the input is already a numpy array).\n",
            " |  \n",
            " |  clip : bool, default=False\n",
            " |      Set to True to clip transformed values of held-out data to\n",
            " |      provided `feature range`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  min_ : ndarray of shape (n_features,)\n",
            " |      Per feature adjustment for minimum. Equivalent to\n",
            " |      ``min - X.min(axis=0) * self.scale_``\n",
            " |  \n",
            " |  scale_ : ndarray of shape (n_features,)\n",
            " |      Per feature relative scaling of the data. Equivalent to\n",
            " |      ``(max - min) / (X.max(axis=0) - X.min(axis=0))``\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         *scale_* attribute.\n",
            " |  \n",
            " |  data_min_ : ndarray of shape (n_features,)\n",
            " |      Per feature minimum seen in the data\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         *data_min_*\n",
            " |  \n",
            " |  data_max_ : ndarray of shape (n_features,)\n",
            " |      Per feature maximum seen in the data\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         *data_max_*\n",
            " |  \n",
            " |  data_range_ : ndarray of shape (n_features,)\n",
            " |      Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         *data_range_*\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  n_samples_seen_ : int\n",
            " |      The number of samples processed by the estimator.\n",
            " |      It will be reset on new calls to fit, but increments across\n",
            " |      ``partial_fit`` calls.\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  minmax_scale : Equivalent function without the estimator API.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
            " |  transform.\n",
            " |  \n",
            " |  For a comparison of the different scalers, transformers, and normalizers,\n",
            " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
            " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn.preprocessing import MinMaxScaler\n",
            " |  >>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
            " |  >>> scaler = MinMaxScaler()\n",
            " |  >>> print(scaler.fit(data))\n",
            " |  MinMaxScaler()\n",
            " |  >>> print(scaler.data_max_)\n",
            " |  [ 1. 18.]\n",
            " |  >>> print(scaler.transform(data))\n",
            " |  [[0.   0.  ]\n",
            " |   [0.25 0.25]\n",
            " |   [0.5  0.5 ]\n",
            " |   [1.   1.  ]]\n",
            " |  >>> print(scaler.transform([[2, 2]]))\n",
            " |  [[1.5 0. ]]\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      MinMaxScaler\n",
            " |      sklearn.base.OneToOneFeatureMixin\n",
            " |      sklearn.base.TransformerMixin\n",
            " |      sklearn.utils._set_output._SetOutputMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, feature_range=(0, 1), *, copy=True, clip=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y=None)\n",
            " |      Compute the minimum and maximum to be used for later scaling.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          The data used to compute the per-feature minimum and maximum\n",
            " |          used for later scaling along the features axis.\n",
            " |      \n",
            " |      y : None\n",
            " |          Ignored.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Fitted scaler.\n",
            " |  \n",
            " |  inverse_transform(self, X)\n",
            " |      Undo the scaling of X according to feature_range.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Input data that will be transformed. It cannot be sparse.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      Xt : ndarray of shape (n_samples, n_features)\n",
            " |          Transformed data.\n",
            " |  \n",
            " |  partial_fit(self, X, y=None)\n",
            " |      Online computation of min and max on X for later scaling.\n",
            " |      \n",
            " |      All of X is processed as a single batch. This is intended for cases\n",
            " |      when :meth:`fit` is not feasible due to very large number of\n",
            " |      `n_samples` or because X is read from a continuous stream.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          The data used to compute the mean and standard deviation\n",
            " |          used for later scaling along the features axis.\n",
            " |      \n",
            " |      y : None\n",
            " |          Ignored.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Fitted scaler.\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Scale features of X according to feature_range.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Input data that will be transformed.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      Xt : ndarray of shape (n_samples, n_features)\n",
            " |          Transformed data.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
            " |  \n",
            " |  get_feature_names_out(self, input_features=None)\n",
            " |      Get output feature names for transformation.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      input_features : array-like of str or None, default=None\n",
            " |          Input features.\n",
            " |      \n",
            " |          - If `input_features` is `None`, then `feature_names_in_` is\n",
            " |            used as feature names in. If `feature_names_in_` is not defined,\n",
            " |            then the following input feature names are generated:\n",
            " |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
            " |          - If `input_features` is an array-like, then `input_features` must\n",
            " |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_names_out : ndarray of str objects\n",
            " |          Same as input features.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.TransformerMixin:\n",
            " |  \n",
            " |  fit_transform(self, X, y=None, **fit_params)\n",
            " |      Fit to data, then transform it.\n",
            " |      \n",
            " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
            " |      and returns a transformed version of `X`.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Input samples.\n",
            " |      \n",
            " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
            " |          Target values (None for unsupervised transformations).\n",
            " |      \n",
            " |      **fit_params : dict\n",
            " |          Additional fit parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
            " |          Transformed array.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
            " |  \n",
            " |  set_output(self, *, transform=None)\n",
            " |      Set output container.\n",
            " |      \n",
            " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
            " |      for an example on how to use the API.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      transform : {\"default\", \"pandas\"}, default=None\n",
            " |          Configure output of `transform` and `fit_transform`.\n",
            " |      \n",
            " |          - `\"default\"`: Default output format of a transformer\n",
            " |          - `\"pandas\"`: DataFrame output\n",
            " |          - `None`: Transform configuration is unchanged\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
            " |  \n",
            " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs) from builtins.type\n",
            " |      This method is called when a class is subclassed.\n",
            " |      \n",
            " |      The default implementation does nothing. It may be\n",
            " |      overridden to extend subclasses.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "jGedXGKesZJP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.fit(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "UUkMRMuDslF_",
        "outputId": "a524ac00-6811-425f-ad5b-5ebd535916fb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = scaler.transform(X_train)"
      ],
      "metadata": {
        "id": "bioPi32rsq4n"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "EhHKCLj6s48a"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "fPmeZsrEtAh3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Documentation of Sequential\n",
        "help(Sequential)"
      ],
      "metadata": {
        "id": "jzo9BTilt6FA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704e92ce-efd0-448e-b5a2-769262a77916"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class Sequential in module keras.engine.sequential:\n",
            "\n",
            "class Sequential(keras.engine.functional.Functional)\n",
            " |  Sequential(layers=None, name=None)\n",
            " |  \n",
            " |  `Sequential` groups a linear stack of layers into a `tf.keras.Model`.\n",
            " |  \n",
            " |  `Sequential` provides training and inference features on this model.\n",
            " |  \n",
            " |  Examples:\n",
            " |  \n",
            " |  ```python\n",
            " |  # Optionally, the first layer can receive an `input_shape` argument:\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
            " |  # Afterwards, we do automatic shape inference:\n",
            " |  model.add(tf.keras.layers.Dense(4))\n",
            " |  \n",
            " |  # This is identical to the following:\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.Input(shape=(16,)))\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  \n",
            " |  # Note that you can also omit the `input_shape` argument.\n",
            " |  # In that case the model doesn't have any weights until the first call\n",
            " |  # to a training/evaluation method (since it isn't yet built):\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  model.add(tf.keras.layers.Dense(4))\n",
            " |  # model.weights not created yet\n",
            " |  \n",
            " |  # Whereas if you specify the input shape, the model gets built\n",
            " |  # continuously as you are adding layers:\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
            " |  model.add(tf.keras.layers.Dense(4))\n",
            " |  len(model.weights)\n",
            " |  # Returns \"4\"\n",
            " |  \n",
            " |  # When using the delayed-build pattern (no input shape specified), you can\n",
            " |  # choose to manually build your model by calling\n",
            " |  # `build(batch_input_shape)`:\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  model.add(tf.keras.layers.Dense(4))\n",
            " |  model.build((None, 16))\n",
            " |  len(model.weights)\n",
            " |  # Returns \"4\"\n",
            " |  \n",
            " |  # Note that when using the delayed-build pattern (no input shape specified),\n",
            " |  # the model gets built the first time you call `fit`, `eval`, or `predict`,\n",
            " |  # or the first time you call the model on some input data.\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  model.add(tf.keras.layers.Dense(1))\n",
            " |  model.compile(optimizer='sgd', loss='mse')\n",
            " |  # This builds the model for the first time:\n",
            " |  model.fit(x, y, batch_size=32, epochs=10)\n",
            " |  ```\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Sequential\n",
            " |      keras.engine.functional.Functional\n",
            " |      keras.engine.training.Model\n",
            " |      keras.engine.base_layer.Layer\n",
            " |      tensorflow.python.module.module.Module\n",
            " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
            " |      tensorflow.python.trackable.base.Trackable\n",
            " |      keras.utils.version_utils.LayerVersionSelector\n",
            " |      keras.utils.version_utils.ModelVersionSelector\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, layers=None, name=None)\n",
            " |      Creates a `Sequential` model instance.\n",
            " |      \n",
            " |      Args:\n",
            " |        layers: Optional list of layers to add to the model.\n",
            " |        name: Optional name for the model.\n",
            " |  \n",
            " |  add(self, layer)\n",
            " |      Adds a layer instance on top of the layer stack.\n",
            " |      \n",
            " |      Args:\n",
            " |          layer: layer instance.\n",
            " |      \n",
            " |      Raises:\n",
            " |          TypeError: If `layer` is not a layer instance.\n",
            " |          ValueError: In case the `layer` argument does not\n",
            " |              know its input shape.\n",
            " |          ValueError: In case the `layer` argument has\n",
            " |              multiple output tensors, or is already connected\n",
            " |              somewhere else (forbidden in `Sequential` models).\n",
            " |  \n",
            " |  build(self, input_shape=None)\n",
            " |      Builds the model based on input shapes received.\n",
            " |      \n",
            " |      This is to be used for subclassed models, which do not know at\n",
            " |      instantiation time what their inputs look like.\n",
            " |      \n",
            " |      This method only exists for users who want to call `model.build()` in a\n",
            " |      standalone way (as a substitute for calling the model on real data to\n",
            " |      build it). It will never be called by the framework (and thus it will\n",
            " |      never throw unexpected errors in an unrelated workflow).\n",
            " |      \n",
            " |      Args:\n",
            " |       input_shape: Single tuple, `TensorShape` instance, or list/dict of\n",
            " |         shapes, where shapes are tuples, integers, or `TensorShape`\n",
            " |         instances.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError:\n",
            " |          1. In case of invalid user-provided data (not of type tuple,\n",
            " |             list, `TensorShape`, or dict).\n",
            " |          2. If the model requires call arguments that are agnostic\n",
            " |             to the input shapes (positional or keyword arg in call\n",
            " |             signature).\n",
            " |          3. If not all layers were properly built.\n",
            " |          4. If float type inputs are not supported within the layers.\n",
            " |      \n",
            " |        In each of these cases, the user should build their model by calling\n",
            " |        it on real tensor data.\n",
            " |  \n",
            " |  call(self, inputs, training=None, mask=None)\n",
            " |      Calls the model on new inputs.\n",
            " |      \n",
            " |      In this case `call` just reapplies\n",
            " |      all ops in the graph to the new inputs\n",
            " |      (e.g. build a new computational graph from the provided inputs).\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: A tensor or list of tensors.\n",
            " |          training: Boolean or boolean scalar tensor, indicating whether to\n",
            " |              run the `Network` in training mode or inference mode.\n",
            " |          mask: A mask or list of masks. A mask can be\n",
            " |              either a tensor or None (no mask).\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor if there is a single output, or\n",
            " |          a list of tensors if there are more than one outputs.\n",
            " |  \n",
            " |  compute_mask(self, inputs, mask)\n",
            " |      Computes an output mask tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: Tensor or list of tensors.\n",
            " |          mask: Tensor or list of tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None or a tensor (or list of tensors,\n",
            " |              one per output tensor of the layer).\n",
            " |  \n",
            " |  compute_output_shape(self, input_shape)\n",
            " |      Computes the output shape of the layer.\n",
            " |      \n",
            " |      This method will cause the layer's state to be built, if that has not\n",
            " |      happened before. This requires that the layer will later be used with\n",
            " |      inputs that match the input shape provided here.\n",
            " |      \n",
            " |      Args:\n",
            " |          input_shape: Shape tuple (tuple of integers) or `tf.TensorShape`,\n",
            " |              or structure of shape tuples / `tf.TensorShape` instances\n",
            " |              (one per output tensor of the layer).\n",
            " |              Shape tuples can include None for free dimensions,\n",
            " |              instead of an integer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `tf.TensorShape` instance\n",
            " |          or structure of `tf.TensorShape` instances.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config of the `Model`.\n",
            " |      \n",
            " |      Config is a Python dictionary (serializable) containing the\n",
            " |      configuration of an object, which in this case is a `Model`. This allows\n",
            " |      the `Model` to be be reinstantiated later (without its trained weights)\n",
            " |      from this configuration.\n",
            " |      \n",
            " |      Note that `get_config()` does not guarantee to return a fresh copy of\n",
            " |      dict every time it is called. The callers should make a copy of the\n",
            " |      returned dict if they want to modify it.\n",
            " |      \n",
            " |      Developers of subclassed `Model` are advised to override this method,\n",
            " |      and continue to update the dict from `super(MyModel, self).get_config()`\n",
            " |      to provide the proper configuration of this `Model`. The default config\n",
            " |      will return config dict for init parameters if they are basic types.\n",
            " |      Raises `NotImplementedError` when in cases where a custom\n",
            " |      `get_config()` implementation is required for the subclassed model.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Python dictionary containing the configuration of this `Model`.\n",
            " |  \n",
            " |  pop(self)\n",
            " |      Removes the last layer in the model.\n",
            " |      \n",
            " |      Raises:\n",
            " |          TypeError: if there are no layers in the model.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  from_config(config, custom_objects=None) from builtins.type\n",
            " |      Creates a layer from its config.\n",
            " |      \n",
            " |      This method is the reverse of `get_config`,\n",
            " |      capable of instantiating the same layer from the config\n",
            " |      dictionary. It does not handle layer connectivity\n",
            " |      (handled by Network), nor weights (handled by `set_weights`).\n",
            " |      \n",
            " |      Args:\n",
            " |          config: A Python dictionary, typically the\n",
            " |              output of get_config.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties defined here:\n",
            " |  \n",
            " |  layers\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  input_spec\n",
            " |      `InputSpec` instance(s) describing the input format for this layer.\n",
            " |      \n",
            " |      When you create a layer subclass, you can set `self.input_spec` to\n",
            " |      enable the layer to run input compatibility checks when it is called.\n",
            " |      Consider a `Conv2D` layer: it can only be called on a single input\n",
            " |      tensor of rank 4. As such, you can set, in `__init__()`:\n",
            " |      \n",
            " |      ```python\n",
            " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
            " |      ```\n",
            " |      \n",
            " |      Now, if you try to call the layer on an input that isn't rank 4\n",
            " |      (for instance, an input of shape `(2,)`, it will raise a\n",
            " |      nicely-formatted error:\n",
            " |      \n",
            " |      ```\n",
            " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
            " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
            " |      ```\n",
            " |      \n",
            " |      Input checks that can be specified via `input_spec` include:\n",
            " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
            " |      - Shape\n",
            " |      - Rank (ndim)\n",
            " |      - Dtype\n",
            " |      \n",
            " |      For more information, see `tf.keras.layers.InputSpec`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.functional.Functional:\n",
            " |  \n",
            " |  get_weight_paths(self)\n",
            " |      Retrieve all the variables and their paths for the model.\n",
            " |      \n",
            " |      The variable path (string) is a stable key to identify a `tf.Variable`\n",
            " |      instance owned by the model. It can be used to specify variable-specific\n",
            " |      configurations (e.g. DTensor, quantization) from a global view.\n",
            " |      \n",
            " |      This method returns a dict with weight object paths as keys\n",
            " |      and the corresponding `tf.Variable` instances as values.\n",
            " |      \n",
            " |      Note that if the model is a subclassed model and the weights haven't\n",
            " |      been initialized, an empty dict will be returned.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A dict where keys are variable paths and values are `tf.Variable`\n",
            " |           instances.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class SubclassModel(tf.keras.Model):\n",
            " |      \n",
            " |        def __init__(self, name=None):\n",
            " |          super().__init__(name=name)\n",
            " |          self.d1 = tf.keras.layers.Dense(10)\n",
            " |          self.d2 = tf.keras.layers.Dense(20)\n",
            " |      \n",
            " |        def call(self, inputs):\n",
            " |          x = self.d1(inputs)\n",
            " |          return self.d2(x)\n",
            " |      \n",
            " |      model = SubclassModel()\n",
            " |      model(tf.zeros((10, 10)))\n",
            " |      weight_paths = model.get_weight_paths()\n",
            " |      # weight_paths:\n",
            " |      # {\n",
            " |      #    'd1.kernel': model.d1.kernel,\n",
            " |      #    'd1.bias': model.d1.bias,\n",
            " |      #    'd2.kernel': model.d2.kernel,\n",
            " |      #    'd2.bias': model.d2.bias,\n",
            " |      # }\n",
            " |      \n",
            " |      # Functional model\n",
            " |      inputs = tf.keras.Input((10,), batch_size=10)\n",
            " |      x = tf.keras.layers.Dense(20, name='d1')(inputs)\n",
            " |      output = tf.keras.layers.Dense(30, name='d2')(x)\n",
            " |      model = tf.keras.Model(inputs, output)\n",
            " |      d1 = model.layers[1]\n",
            " |      d2 = model.layers[2]\n",
            " |      weight_paths = model.get_weight_paths()\n",
            " |      # weight_paths:\n",
            " |      # {\n",
            " |      #    'd1.kernel': d1.kernel,\n",
            " |      #    'd1.bias': d1.bias,\n",
            " |      #    'd2.kernel': d2.kernel,\n",
            " |      #    'd2.bias': d2.bias,\n",
            " |      # }\n",
            " |      ```\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from keras.engine.functional.Functional:\n",
            " |  \n",
            " |  input\n",
            " |      Retrieves the input tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input tensor or list of input tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |        AttributeError: If no inbound nodes are found.\n",
            " |  \n",
            " |  input_shape\n",
            " |      Retrieves the input shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            " |      have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per input tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined input_shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output\n",
            " |      Retrieves the output tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one output,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor or list of output tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        AttributeError: if the layer is connected to more than one incoming\n",
            " |          layers.\n",
            " |        RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output_shape\n",
            " |      Retrieves the output shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has one output,\n",
            " |      or if all outputs have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per output tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined output shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  __call__(self, *args, **kwargs)\n",
            " |  \n",
            " |  __copy__(self)\n",
            " |  \n",
            " |  __deepcopy__(self, memo)\n",
            " |  \n",
            " |  __reduce__(self)\n",
            " |      Helper for pickle.\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, jit_compile=None, **kwargs)\n",
            " |      Configures the model for training.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
            " |                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
            " |                    metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
            " |                             tf.keras.metrics.FalseNegatives()])\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
            " |            `tf.keras.optimizers`.\n",
            " |          loss: Loss function. May be a string (name of loss function), or\n",
            " |            a `tf.keras.losses.Loss` instance. See `tf.keras.losses`. A loss\n",
            " |            function is any callable with the signature `loss = fn(y_true,\n",
            " |            y_pred)`, where `y_true` are the ground truth values, and\n",
            " |            `y_pred` are the model's predictions.\n",
            " |            `y_true` should have shape\n",
            " |            `(batch_size, d0, .. dN)` (except in the case of\n",
            " |            sparse loss functions such as\n",
            " |            sparse categorical crossentropy which expects integer arrays of\n",
            " |            shape `(batch_size, d0, .. dN-1)`).\n",
            " |            `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
            " |            The loss function should return a float tensor.\n",
            " |            If a custom `Loss` instance is\n",
            " |            used and reduction is set to `None`, return value has shape\n",
            " |            `(batch_size, d0, .. dN-1)` i.e. per-sample or per-timestep loss\n",
            " |            values; otherwise, it is a scalar. If the model has multiple\n",
            " |            outputs, you can use a different loss on each output by passing a\n",
            " |            dictionary or a list of losses. The loss value that will be\n",
            " |            minimized by the model will then be the sum of all individual\n",
            " |            losses, unless `loss_weights` is specified.\n",
            " |          metrics: List of metrics to be evaluated by the model during\n",
            " |            training and testing. Each of this can be a string (name of a\n",
            " |            built-in function), function or a `tf.keras.metrics.Metric`\n",
            " |            instance. See `tf.keras.metrics`. Typically you will use\n",
            " |            `metrics=['accuracy']`.\n",
            " |            A function is any callable with the signature `result = fn(y_true,\n",
            " |            y_pred)`. To specify different metrics for different outputs of a\n",
            " |            multi-output model, you could also pass a dictionary, such as\n",
            " |            `metrics={'output_a':'accuracy', 'output_b':['accuracy', 'mse']}`.\n",
            " |            You can also pass a list to specify a metric or a list of metrics\n",
            " |            for each output, such as\n",
            " |            `metrics=[['accuracy'], ['accuracy', 'mse']]`\n",
            " |            or `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
            " |            strings 'accuracy' or 'acc', we convert this to one of\n",
            " |            `tf.keras.metrics.BinaryAccuracy`,\n",
            " |            `tf.keras.metrics.CategoricalAccuracy`,\n",
            " |            `tf.keras.metrics.SparseCategoricalAccuracy` based on the shapes\n",
            " |            of the targets and of the model output. We do a similar\n",
            " |            conversion for the strings 'crossentropy' and 'ce' as well.\n",
            " |            The metrics passed here are evaluated without sample weighting; if\n",
            " |            you would like sample weighting to apply, you can specify your\n",
            " |            metrics via the `weighted_metrics` argument instead.\n",
            " |          loss_weights: Optional list or dictionary specifying scalar\n",
            " |            coefficients (Python floats) to weight the loss contributions of\n",
            " |            different model outputs. The loss value that will be minimized by\n",
            " |            the model will then be the *weighted sum* of all individual\n",
            " |            losses, weighted by the `loss_weights` coefficients.  If a list,\n",
            " |            it is expected to have a 1:1 mapping to the model's outputs. If a\n",
            " |            dict, it is expected to map output names (strings) to scalar\n",
            " |            coefficients.\n",
            " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
            " |            `sample_weight` or `class_weight` during training and testing.\n",
            " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
            " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
            " |            this as `None` unless your `Model` cannot be run inside a\n",
            " |            `tf.function`. `run_eagerly=True` is not supported when using\n",
            " |            `tf.distribute.experimental.ParameterServerStrategy`.\n",
            " |          steps_per_execution: Int. Defaults to 1. The number of batches to\n",
            " |            run during each `tf.function` call. Running multiple batches\n",
            " |            inside a single `tf.function` call can greatly improve performance\n",
            " |            on TPUs or small models with a large Python overhead. At most, one\n",
            " |            full epoch will be run each execution. If a number larger than the\n",
            " |            size of the epoch is passed, the execution will be truncated to\n",
            " |            the size of the epoch. Note that if `steps_per_execution` is set\n",
            " |            to `N`, `Callback.on_batch_begin` and `Callback.on_batch_end`\n",
            " |            methods will only be called every `N` batches (i.e. before/after\n",
            " |            each `tf.function` execution).\n",
            " |          jit_compile: If `True`, compile the model training step with XLA.\n",
            " |            [XLA](https://www.tensorflow.org/xla) is an optimizing compiler\n",
            " |            for machine learning.\n",
            " |            `jit_compile` is not enabled for by default.\n",
            " |            Note that `jit_compile=True`\n",
            " |            may not necessarily work for all models.\n",
            " |            For more information on supported operations please refer to the\n",
            " |            [XLA documentation](https://www.tensorflow.org/xla).\n",
            " |            Also refer to\n",
            " |            [known XLA issues](https://www.tensorflow.org/xla/known_issues)\n",
            " |            for more details.\n",
            " |          **kwargs: Arguments supported for backwards compatibility only.\n",
            " |  \n",
            " |  compile_from_config(self, config)\n",
            " |  \n",
            " |  compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None)\n",
            " |      Compute the total loss, validate it, and return it.\n",
            " |      \n",
            " |      Subclasses can optionally override this method to provide custom loss\n",
            " |      computation logic.\n",
            " |      \n",
            " |      Example:\n",
            " |      ```python\n",
            " |      class MyModel(tf.keras.Model):\n",
            " |      \n",
            " |        def __init__(self, *args, **kwargs):\n",
            " |          super(MyModel, self).__init__(*args, **kwargs)\n",
            " |          self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
            " |      \n",
            " |        def compute_loss(self, x, y, y_pred, sample_weight):\n",
            " |          loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))\n",
            " |          loss += tf.add_n(self.losses)\n",
            " |          self.loss_tracker.update_state(loss)\n",
            " |          return loss\n",
            " |      \n",
            " |        def reset_metrics(self):\n",
            " |          self.loss_tracker.reset_states()\n",
            " |      \n",
            " |        @property\n",
            " |        def metrics(self):\n",
            " |          return [self.loss_tracker]\n",
            " |      \n",
            " |      tensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))\n",
            " |      dataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)\n",
            " |      \n",
            " |      inputs = tf.keras.layers.Input(shape=(10,), name='my_input')\n",
            " |      outputs = tf.keras.layers.Dense(10)(inputs)\n",
            " |      model = MyModel(inputs, outputs)\n",
            " |      model.add_loss(tf.reduce_sum(outputs))\n",
            " |      \n",
            " |      optimizer = tf.keras.optimizers.SGD()\n",
            " |      model.compile(optimizer, loss='mse', steps_per_execution=10)\n",
            " |      model.fit(dataset, epochs=2, steps_per_epoch=10)\n",
            " |      print('My custom loss: ', model.loss_tracker.result().numpy())\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: Input data.\n",
            " |        y: Target data.\n",
            " |        y_pred: Predictions returned by the model (output of `model(x)`)\n",
            " |        sample_weight: Sample weights for weighting the loss function.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The total loss as a `tf.Tensor`, or `None` if no loss results (which\n",
            " |        is the case when called by `Model.test_step`).\n",
            " |  \n",
            " |  compute_metrics(self, x, y, y_pred, sample_weight)\n",
            " |      Update metric states and collect all metrics to be returned.\n",
            " |      \n",
            " |      Subclasses can optionally override this method to provide custom metric\n",
            " |      updating and collection logic.\n",
            " |      \n",
            " |      Example:\n",
            " |      ```python\n",
            " |      class MyModel(tf.keras.Sequential):\n",
            " |      \n",
            " |        def compute_metrics(self, x, y, y_pred, sample_weight):\n",
            " |      \n",
            " |          # This super call updates `self.compiled_metrics` and returns\n",
            " |          # results for all metrics listed in `self.metrics`.\n",
            " |          metric_results = super(MyModel, self).compute_metrics(\n",
            " |              x, y, y_pred, sample_weight)\n",
            " |      \n",
            " |          # Note that `self.custom_metric` is not listed in `self.metrics`.\n",
            " |          self.custom_metric.update_state(x, y, y_pred, sample_weight)\n",
            " |          metric_results['custom_metric_name'] = self.custom_metric.result()\n",
            " |          return metric_results\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: Input data.\n",
            " |        y: Target data.\n",
            " |        y_pred: Predictions returned by the model (output of `model.call(x)`)\n",
            " |        sample_weight: Sample weights for weighting the loss function.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end()`. Typically, the\n",
            " |        values of the metrics listed in `self.metrics` are returned. Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  evaluate(self, x=None, y=None, batch_size=None, verbose='auto', sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False, **kwargs)\n",
            " |      Returns the loss value & metrics values for the model in test mode.\n",
            " |      \n",
            " |      Computation is done in batches (see the `batch_size` arg.)\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |            - A `tf.data` dataset. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |            - A generator or `keras.utils.Sequence` returning `(inputs,\n",
            " |              targets)` or `(inputs, targets, sample_weights)`.\n",
            " |            A more detailed description of unpacking behavior for iterator\n",
            " |            types (Dataset, generator, Sequence) is given in the `Unpacking\n",
            " |            behavior for iterator-like inputs` section of `Model.fit`.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |            If `x` is a dataset, generator or `keras.utils.Sequence` instance,\n",
            " |            `y` should not be specified (since targets will be obtained from\n",
            " |            the iterator/dataset).\n",
            " |          batch_size: Integer or `None`. Number of samples per batch of\n",
            " |            computation. If unspecified, `batch_size` will default to 32. Do\n",
            " |            not specify the `batch_size` if your data is in the form of a\n",
            " |            dataset, generators, or `keras.utils.Sequence` instances (since\n",
            " |            they generate batches).\n",
            " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = single line.\n",
            " |              `\"auto\"` defaults to 1 for most cases, and to 2 when used with\n",
            " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
            " |              particularly useful when logged to a file, so `verbose=2` is\n",
            " |              recommended when not running interactively (e.g. in a production\n",
            " |              environment).\n",
            " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
            " |            used for weighting the loss function. You can either pass a flat\n",
            " |            (1D) Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples), or in the case of\n",
            " |                temporal data, you can pass a 2D array with shape `(samples,\n",
            " |                sequence_length)`, to apply a different weight to every\n",
            " |                timestep of every sample. This argument is not supported when\n",
            " |                `x` is a dataset, instead pass sample weights as the third\n",
            " |                element of `x`.\n",
            " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
            " |            before declaring the evaluation round finished. Ignored with the\n",
            " |            default value of `None`. If x is a `tf.data` dataset and `steps`\n",
            " |            is None, 'evaluate' will run until the dataset is exhausted. This\n",
            " |            argument is not supported with array inputs.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
            " |            callbacks to apply during evaluation. See\n",
            " |            [callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or\n",
            " |            `keras.utils.Sequence` input only. Maximum size for the generator\n",
            " |            queue. If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |            only. Maximum number of processes to spin up when using\n",
            " |            process-based threading. If unspecified, `workers` will default to\n",
            " |            1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |            threading. If unspecified, `use_multiprocessing` will default to\n",
            " |            `False`. Note that because this implementation relies on\n",
            " |            multiprocessing, you should not pass non-picklable arguments to\n",
            " |            the generator as they can't be passed easily to children\n",
            " |            processes.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a\n",
            " |            dict, with each key being the name of the metric. If `False`, they\n",
            " |            are returned as a list.\n",
            " |          **kwargs: Unused at this time.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Evaluates the model on a data generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.evaluate` now supports generators, so there is no longer any\n",
            " |        need to use this endpoint.\n",
            " |  \n",
            " |  export(self, filepath)\n",
            " |      Create a SavedModel artifact for inference (e.g. via TF-Serving).\n",
            " |      \n",
            " |      This method lets you export a model to a lightweight SavedModel artifact\n",
            " |      that contains the model's forward pass only (its `call()` method)\n",
            " |      and can be served via e.g. TF-Serving. The forward pass is registered\n",
            " |      under the name `serve()` (see example below).\n",
            " |      \n",
            " |      The original code of the model (including any custom layers you may\n",
            " |      have used) is *no longer* necessary to reload the artifact -- it is\n",
            " |      entirely standalone.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: `str` or `pathlib.Path` object. Path where to save\n",
            " |              the artifact.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      # Create the artifact\n",
            " |      model.export(\"path/to/location\")\n",
            " |      \n",
            " |      # Later, in a different process / environment...\n",
            " |      reloaded_artifact = tf.saved_model.load(\"path/to/location\")\n",
            " |      predictions = reloaded_artifact.serve(input_data)\n",
            " |      ```\n",
            " |      \n",
            " |      If you would like to customize your serving endpoints, you can\n",
            " |      use the lower-level `keras.export.ExportArchive` class. The `export()`\n",
            " |      method relies on `ExportArchive` internally.\n",
            " |  \n",
            " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            " |      Trains the model for a fixed number of epochs (dataset iterations).\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |            - A `tf.data` dataset. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |            - A generator or `keras.utils.Sequence` returning `(inputs,\n",
            " |              targets)` or `(inputs, targets, sample_weights)`.\n",
            " |            - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a\n",
            " |              callable that takes a single argument of type\n",
            " |              `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.\n",
            " |              `DatasetCreator` should be used when users prefer to specify the\n",
            " |              per-replica batching and sharding logic for the `Dataset`.\n",
            " |              See `tf.keras.utils.experimental.DatasetCreator` doc for more\n",
            " |              information.\n",
            " |            A more detailed description of unpacking behavior for iterator\n",
            " |            types (Dataset, generator, Sequence) is given below. If these\n",
            " |            include `sample_weights` as a third component, note that sample\n",
            " |            weighting applies to the `weighted_metrics` argument but not the\n",
            " |            `metrics` argument in `compile()`. If using\n",
            " |            `tf.distribute.experimental.ParameterServerStrategy`, only\n",
            " |            `DatasetCreator` type is supported for `x`.\n",
            " |          y: Target data. Like the input data `x`,\n",
            " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
            " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
            " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
            " |            or `keras.utils.Sequence` instance, `y` should\n",
            " |            not be specified (since targets will be obtained from `x`).\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per gradient update.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of datasets, generators, or `keras.utils.Sequence`\n",
            " |              instances (since they generate batches).\n",
            " |          epochs: Integer. Number of epochs to train the model.\n",
            " |              An epoch is an iteration over the entire `x` and `y`\n",
            " |              data provided\n",
            " |              (unless the `steps_per_epoch` flag is set to\n",
            " |              something other than None).\n",
            " |              Note that in conjunction with `initial_epoch`,\n",
            " |              `epochs` is to be understood as \"final epoch\".\n",
            " |              The model is not trained for a number of iterations\n",
            " |              given by `epochs`, but merely until the epoch\n",
            " |              of index `epochs` is reached.\n",
            " |          verbose: 'auto', 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
            " |              'auto' defaults to 1 for most cases, but 2 when used with\n",
            " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
            " |              particularly useful when logged to a file, so verbose=2 is\n",
            " |              recommended when not running interactively (eg, in a production\n",
            " |              environment).\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during training.\n",
            " |              See `tf.keras.callbacks`. Note\n",
            " |              `tf.keras.callbacks.ProgbarLogger` and\n",
            " |              `tf.keras.callbacks.History` callbacks are created automatically\n",
            " |              and need not be passed into `model.fit`.\n",
            " |              `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
            " |              `verbose` argument to `model.fit`.\n",
            " |              Callbacks with batch-level calls are currently unsupported with\n",
            " |              `tf.distribute.experimental.ParameterServerStrategy`, and users\n",
            " |              are advised to implement epoch-level calls instead with an\n",
            " |              appropriate `steps_per_epoch` value.\n",
            " |          validation_split: Float between 0 and 1.\n",
            " |              Fraction of the training data to be used as validation data.\n",
            " |              The model will set apart this fraction of the training data,\n",
            " |              will not train on it, and will evaluate\n",
            " |              the loss and any model metrics\n",
            " |              on this data at the end of each epoch.\n",
            " |              The validation data is selected from the last samples\n",
            " |              in the `x` and `y` data provided, before shuffling. This\n",
            " |              argument is not supported when `x` is a dataset, generator or\n",
            " |              `keras.utils.Sequence` instance.\n",
            " |              If both `validation_data` and `validation_split` are provided,\n",
            " |              `validation_data` will override `validation_split`.\n",
            " |              `validation_split` is not yet supported with\n",
            " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
            " |          validation_data: Data on which to evaluate\n",
            " |              the loss and any model metrics at the end of each epoch.\n",
            " |              The model will not be trained on this data. Thus, note the fact\n",
            " |              that the validation loss of data provided using\n",
            " |              `validation_split` or `validation_data` is not affected by\n",
            " |              regularization layers like noise and dropout.\n",
            " |              `validation_data` will override `validation_split`.\n",
            " |              `validation_data` could be:\n",
            " |                - A tuple `(x_val, y_val)` of Numpy arrays or tensors.\n",
            " |                - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
            " |                  arrays.\n",
            " |                - A `tf.data.Dataset`.\n",
            " |                - A Python generator or `keras.utils.Sequence` returning\n",
            " |                `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
            " |              `validation_data` is not yet supported with\n",
            " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
            " |          shuffle: Boolean (whether to shuffle the training data\n",
            " |              before each epoch) or str (for 'batch'). This argument is\n",
            " |              ignored when `x` is a generator or an object of tf.data.Dataset.\n",
            " |              'batch' is a special option for dealing\n",
            " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
            " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers)\n",
            " |              to a weight (float) value, used for weighting the loss function\n",
            " |              (during training only).\n",
            " |              This can be useful to tell the model to\n",
            " |              \"pay more attention\" to samples from\n",
            " |              an under-represented class.\n",
            " |          sample_weight: Optional Numpy array of weights for\n",
            " |              the training samples, used for weighting the loss function\n",
            " |              (during training only). You can either pass a flat (1D)\n",
            " |              Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples),\n",
            " |              or in the case of temporal data,\n",
            " |              you can pass a 2D array with shape\n",
            " |              `(samples, sequence_length)`,\n",
            " |              to apply a different weight to every timestep of every sample.\n",
            " |              This argument is not supported when `x` is a dataset, generator,\n",
            " |              or `keras.utils.Sequence` instance, instead provide the\n",
            " |              sample_weights as the third element of `x`.\n",
            " |              Note that sample weighting does not apply to metrics specified\n",
            " |              via the `metrics` argument in `compile()`. To apply sample\n",
            " |              weighting to your metrics, you can specify them via the\n",
            " |              `weighted_metrics` in `compile()` instead.\n",
            " |          initial_epoch: Integer.\n",
            " |              Epoch at which to start training\n",
            " |              (useful for resuming a previous training run).\n",
            " |          steps_per_epoch: Integer or `None`.\n",
            " |              Total number of steps (batches of samples)\n",
            " |              before declaring one epoch finished and starting the\n",
            " |              next epoch. When training with input tensors such as\n",
            " |              TensorFlow data tensors, the default `None` is equal to\n",
            " |              the number of samples in your dataset divided by\n",
            " |              the batch size, or 1 if that cannot be determined. If x is a\n",
            " |              `tf.data` dataset, and 'steps_per_epoch'\n",
            " |              is None, the epoch will run until the input dataset is\n",
            " |              exhausted.  When passing an infinitely repeating dataset, you\n",
            " |              must specify the `steps_per_epoch` argument. If\n",
            " |              `steps_per_epoch=-1` the training will run indefinitely with an\n",
            " |              infinitely repeating dataset.  This argument is not supported\n",
            " |              with array inputs.\n",
            " |              When using `tf.distribute.experimental.ParameterServerStrategy`:\n",
            " |                * `steps_per_epoch=None` is not supported.\n",
            " |          validation_steps: Only relevant if `validation_data` is provided and\n",
            " |              is a `tf.data` dataset. Total number of steps (batches of\n",
            " |              samples) to draw before stopping when performing validation\n",
            " |              at the end of every epoch. If 'validation_steps' is None,\n",
            " |              validation will run until the `validation_data` dataset is\n",
            " |              exhausted. In the case of an infinitely repeated dataset, it\n",
            " |              will run into an infinite loop. If 'validation_steps' is\n",
            " |              specified and only part of the dataset will be consumed, the\n",
            " |              evaluation will start from the beginning of the dataset at each\n",
            " |              epoch. This ensures that the same validation samples are used\n",
            " |              every time.\n",
            " |          validation_batch_size: Integer or `None`.\n",
            " |              Number of samples per validation batch.\n",
            " |              If unspecified, will default to `batch_size`.\n",
            " |              Do not specify the `validation_batch_size` if your data is in\n",
            " |              the form of datasets, generators, or `keras.utils.Sequence`\n",
            " |              instances (since they generate batches).\n",
            " |          validation_freq: Only relevant if validation data is provided.\n",
            " |            Integer or `collections.abc.Container` instance (e.g. list, tuple,\n",
            " |            etc.).  If an integer, specifies how many training epochs to run\n",
            " |            before a new validation run is performed, e.g. `validation_freq=2`\n",
            " |            runs validation every 2 epochs. If a Container, specifies the\n",
            " |            epochs on which to run validation, e.g.\n",
            " |            `validation_freq=[1, 2, 10]` runs validation at the end of the\n",
            " |            1st, 2nd, and 10th epochs.\n",
            " |          max_queue_size: Integer. Used for generator or\n",
            " |            `keras.utils.Sequence` input only. Maximum size for the generator\n",
            " |            queue.  If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up\n",
            " |              when using process-based threading. If unspecified, `workers`\n",
            " |              will default to 1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-picklable arguments to\n",
            " |              the generator as they can't be passed easily to children\n",
            " |              processes.\n",
            " |      \n",
            " |      Unpacking behavior for iterator-like inputs:\n",
            " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
            " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
            " |        yield not only features (x) but optionally targets (y) and sample\n",
            " |        weights.  Keras requires that the output of such iterator-likes be\n",
            " |        unambiguous. The iterator should return a tuple of length 1, 2, or 3,\n",
            " |        where the optional second and third elements will be used for y and\n",
            " |        sample_weight respectively. Any other type provided will be wrapped in\n",
            " |        a length one tuple, effectively treating everything as 'x'. When\n",
            " |        yielding dicts, they should still adhere to the top-level tuple\n",
            " |        structure.\n",
            " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
            " |        features, targets, and weights from the keys of a single dict.\n",
            " |          A notable unsupported data type is the namedtuple. The reason is\n",
            " |        that it behaves like both an ordered datatype (tuple) and a mapping\n",
            " |        datatype (dict). So given a namedtuple of the form:\n",
            " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
            " |        it is ambiguous whether to reverse the order of the elements when\n",
            " |        interpreting the value. Even worse is a tuple of the form:\n",
            " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
            " |        where it is unclear if the tuple was intended to be unpacked into x,\n",
            " |        y, and sample_weight or passed through as a single element to `x`. As\n",
            " |        a result the data processing code will simply raise a ValueError if it\n",
            " |        encounters a namedtuple. (Along with instructions to remedy the\n",
            " |        issue.)\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `History` object. Its `History.history` attribute is\n",
            " |          a record of training loss values and metrics values\n",
            " |          at successive epochs, as well as validation loss values\n",
            " |          and validation metrics values (if applicable).\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: 1. If the model was never compiled or,\n",
            " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
            " |      \n",
            " |          ValueError: In case of mismatch between the provided input data\n",
            " |              and what the model expects or when the input data is empty.\n",
            " |  \n",
            " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
            " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.fit` now supports generators, so there is no longer any need to\n",
            " |        use this endpoint.\n",
            " |  \n",
            " |  get_compile_config(self)\n",
            " |  \n",
            " |  get_layer(self, name=None, index=None)\n",
            " |      Retrieves a layer based on either its name (unique) or index.\n",
            " |      \n",
            " |      If `name` and `index` are both provided, `index` will take precedence.\n",
            " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
            " |      \n",
            " |      Args:\n",
            " |          name: String, name of layer.\n",
            " |          index: Integer, index of layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  get_metrics_result(self)\n",
            " |      Returns the model's metrics values as a dict.\n",
            " |      \n",
            " |      If any of the metric result is a dict (containing multiple metrics),\n",
            " |      each of them gets added to the top level returned dict of this method.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values of the metrics listed in `self.metrics`.\n",
            " |        Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  get_weights(self)\n",
            " |      Retrieves the weights of the model.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A flat list of Numpy arrays.\n",
            " |  \n",
            " |  load_weights(self, filepath, skip_mismatch=False, by_name=False, options=None)\n",
            " |      Loads all layer weights from a saved files.\n",
            " |      \n",
            " |      The saved file could be a SavedModel file, a `.keras` file (v3 saving\n",
            " |      format), or a file created via `model.save_weights()`.\n",
            " |      \n",
            " |      By default, weights are loaded based on the network's\n",
            " |      topology. This means the architecture should be the same as when the\n",
            " |      weights were saved. Note that layers that don't have weights are not\n",
            " |      taken into account in the topological ordering, so adding or removing\n",
            " |      layers is fine as long as they don't have weights.\n",
            " |      \n",
            " |      **Partial weight loading**\n",
            " |      \n",
            " |      If you have modified your model, for instance by adding a new layer\n",
            " |      (with weights) or by changing the shape of the weights of a layer,\n",
            " |      you can choose to ignore errors and continue loading\n",
            " |      by setting `skip_mismatch=True`. In this case any layer with\n",
            " |      mismatching weights will be skipped. A warning will be displayed\n",
            " |      for each skipped layer.\n",
            " |      \n",
            " |      **Weight loading by name**\n",
            " |      \n",
            " |      If your weights are saved as a `.h5` file created\n",
            " |      via `model.save_weights()`, you can use the argument `by_name=True`.\n",
            " |      \n",
            " |      In this case, weights are loaded into layers only if they share\n",
            " |      the same name. This is useful for fine-tuning or transfer-learning\n",
            " |      models where some of the layers have changed.\n",
            " |      \n",
            " |      Note that only topological loading (`by_name=False`) is supported when\n",
            " |      loading weights from the `.keras` v3 format or from the TensorFlow\n",
            " |      SavedModel format.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: String, path to the weights file to load. For weight files\n",
            " |              in TensorFlow format, this is the file prefix (the same as was\n",
            " |              passed to `save_weights()`). This can also be a path to a\n",
            " |              SavedModel or a `.keras` file (v3 saving format) saved\n",
            " |              via `model.save()`.\n",
            " |          skip_mismatch: Boolean, whether to skip loading of layers where\n",
            " |              there is a mismatch in the number of weights, or a mismatch in\n",
            " |              the shape of the weights.\n",
            " |          by_name: Boolean, whether to load weights by name or by topological\n",
            " |              order. Only topological loading is supported for weight files in\n",
            " |              the `.keras` v3 format or in the TensorFlow SavedModel format.\n",
            " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            " |              options for loading weights (only valid for a SavedModel file).\n",
            " |  \n",
            " |  make_predict_function(self, force=False)\n",
            " |      Creates a function that executes one step of inference.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            " |      logic to `Model.predict_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.predict` or\n",
            " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the predict function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
            " |  \n",
            " |  make_test_function(self, force=False)\n",
            " |      Creates a function that executes one step of evaluation.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            " |      logic to `Model.test_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.evaluate` or\n",
            " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the test function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
            " |  \n",
            " |  make_train_function(self, force=False)\n",
            " |      Creates a function that executes one step of training.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
            " |      logic to `Model.train_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.fit` or\n",
            " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the train function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  predict(self, x, batch_size=None, verbose='auto', steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            " |      Generates output predictions for the input samples.\n",
            " |      \n",
            " |      Computation is done in batches. This method is designed for batch\n",
            " |      processing of large numbers of inputs. It is not intended for use inside\n",
            " |      of loops that iterate over your data and process small numbers of inputs\n",
            " |      at a time.\n",
            " |      \n",
            " |      For small numbers of inputs that fit in one batch,\n",
            " |      directly use `__call__()` for faster execution, e.g.,\n",
            " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
            " |      `tf.keras.layers.BatchNormalization` that behave differently during\n",
            " |      inference. You may pair the individual model call with a `tf.function`\n",
            " |      for additional performance inside your inner loop.\n",
            " |      If you need access to numpy array values instead of tensors after your\n",
            " |      model call, you can use `tensor.numpy()` to get the numpy array value of\n",
            " |      an eager tensor.\n",
            " |      \n",
            " |      Also, note the fact that test loss is not affected by\n",
            " |      regularization layers like noise and dropout.\n",
            " |      \n",
            " |      Note: See [this FAQ entry](\n",
            " |      https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)\n",
            " |      for more details about the difference between `Model` methods\n",
            " |      `predict()` and `__call__()`.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input samples. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A `tf.data` dataset.\n",
            " |            - A generator or `keras.utils.Sequence` instance.\n",
            " |            A more detailed description of unpacking behavior for iterator\n",
            " |            types (Dataset, generator, Sequence) is given in the `Unpacking\n",
            " |            behavior for iterator-like inputs` section of `Model.fit`.\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per batch.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = single line.\n",
            " |              `\"auto\"` defaults to 1 for most cases, and to 2 when used with\n",
            " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
            " |              particularly useful when logged to a file, so `verbose=2` is\n",
            " |              recommended when not running interactively (e.g. in a production\n",
            " |              environment).\n",
            " |          steps: Total number of steps (batches of samples)\n",
            " |              before declaring the prediction round finished.\n",
            " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
            " |              dataset and `steps` is None, `predict()` will\n",
            " |              run until the input dataset is exhausted.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during prediction.\n",
            " |              See [callbacks](\n",
            " |              https://www.tensorflow.org/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. Maximum size for the\n",
            " |              generator queue. If unspecified, `max_queue_size` will default\n",
            " |              to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up when using\n",
            " |              process-based threading. If unspecified, `workers` will default\n",
            " |              to 1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-picklable arguments to\n",
            " |              the generator as they can't be passed easily to children\n",
            " |              processes.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`. Note that Model.predict uses the same interpretation rules\n",
            " |      as `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for\n",
            " |      all three methods.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.predict` is wrapped in a `tf.function`.\n",
            " |          ValueError: In case of mismatch between the provided\n",
            " |              input data and the model's expectations,\n",
            " |              or in case a stateful model receives a number of samples\n",
            " |              that is not a multiple of the batch size.\n",
            " |  \n",
            " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Generates predictions for the input samples from a data generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.predict` now supports generators, so there is no longer any\n",
            " |        need to use this endpoint.\n",
            " |  \n",
            " |  predict_on_batch(self, x)\n",
            " |      Returns predictions for a single batch of samples.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
            " |                model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
            " |                multiple inputs).\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.predict_on_batch` is wrapped in a\n",
            " |            `tf.function`.\n",
            " |  \n",
            " |  predict_step(self, data)\n",
            " |      The logic for one inference step.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.make_predict_function`.\n",
            " |      \n",
            " |      This method should contain the mathematical logic for one step of\n",
            " |      inference.  This typically includes the forward pass.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function`\n",
            " |      and `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_predict_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The result of one inference step, typically the output of calling the\n",
            " |        `Model` on data.\n",
            " |  \n",
            " |  reset_metrics(self)\n",
            " |      Resets the state of all the metrics in the model.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> _ = model.fit(x, y, verbose=0)\n",
            " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
            " |      \n",
            " |      >>> model.reset_metrics()\n",
            " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
            " |  \n",
            " |  reset_states(self)\n",
            " |  \n",
            " |  save(self, filepath, overwrite=True, save_format=None, **kwargs)\n",
            " |      Saves a model as a TensorFlow SavedModel or HDF5 file.\n",
            " |      \n",
            " |      See the [Serialization and Saving guide](\n",
            " |          https://keras.io/guides/serialization_and_saving/) for details.\n",
            " |      \n",
            " |      Args:\n",
            " |          model: Keras model instance to be saved.\n",
            " |          filepath: `str` or `pathlib.Path` object. Path where to save the\n",
            " |              model.\n",
            " |          overwrite: Whether we should overwrite any existing model at the\n",
            " |              target location, or instead ask the user via an interactive\n",
            " |              prompt.\n",
            " |          save_format: Either `\"keras\"`, `\"tf\"`, `\"h5\"`,\n",
            " |              indicating whether to save the model\n",
            " |              in the native Keras format (`.keras`),\n",
            " |              in the TensorFlow SavedModel format\n",
            " |              (referred to as \"SavedModel\" below),\n",
            " |              or in the legacy HDF5 format (`.h5`).\n",
            " |              Defaults to `\"tf\"` in TF 2.X, and `\"h5\"` in TF 1.X.\n",
            " |      \n",
            " |      SavedModel format arguments:\n",
            " |          include_optimizer: Only applied to SavedModel and legacy HDF5\n",
            " |              formats. If False, do not save the optimizer state.\n",
            " |              Defaults to True.\n",
            " |          signatures: Only applies to SavedModel format. Signatures to save\n",
            " |              with the SavedModel. See the `signatures` argument in\n",
            " |              `tf.saved_model.save` for details.\n",
            " |          options: Only applies to SavedModel format.\n",
            " |              `tf.saved_model.SaveOptions` object that specifies SavedModel\n",
            " |              saving options.\n",
            " |          save_traces: Only applies to SavedModel format. When enabled, the\n",
            " |              SavedModel will store the function traces for each layer. This\n",
            " |              can be disabled, so that only the configs of each layer are\n",
            " |              stored. Defaults to `True`.\n",
            " |              Disabling this will decrease serialization time\n",
            " |              and reduce file size, but it requires that all custom\n",
            " |              layers/models implement a `get_config()` method.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      model = tf.keras.Sequential([\n",
            " |          tf.keras.layers.Dense(5, input_shape=(3,)),\n",
            " |          tf.keras.layers.Softmax()])\n",
            " |      model.save(\"model.keras\")\n",
            " |      loaded_model = tf.keras.models.load_model(\"model.keras\")\n",
            " |      x = tf.random.uniform((10, 3))\n",
            " |      assert np.allclose(model.predict(x), loaded_model.predict(x))\n",
            " |      ```\n",
            " |      \n",
            " |      Note that `model.save()` is an alias for `tf.keras.models.save_model()`.\n",
            " |  \n",
            " |  save_spec(self, dynamic_batch=True)\n",
            " |      Returns the `tf.TensorSpec` of call args as a tuple `(args, kwargs)`.\n",
            " |      \n",
            " |      This value is automatically defined after calling the model for the\n",
            " |      first time. Afterwards, you can use it when exporting the model for\n",
            " |      serving:\n",
            " |      \n",
            " |      ```python\n",
            " |      model = tf.keras.Model(...)\n",
            " |      \n",
            " |      @tf.function\n",
            " |      def serve(*args, **kwargs):\n",
            " |        outputs = model(*args, **kwargs)\n",
            " |        # Apply postprocessing steps, or add additional outputs.\n",
            " |        ...\n",
            " |        return outputs\n",
            " |      \n",
            " |      # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this\n",
            " |      # example, is an empty dict since functional models do not use keyword\n",
            " |      # arguments.\n",
            " |      arg_specs, kwarg_specs = model.save_spec()\n",
            " |      \n",
            " |      model.save(path, signatures={\n",
            " |        'serving_default': serve.get_concrete_function(*arg_specs,\n",
            " |                                                       **kwarg_specs)\n",
            " |      })\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        dynamic_batch: Whether to set the batch sizes of all the returned\n",
            " |          `tf.TensorSpec` to `None`. (Note that when defining functional or\n",
            " |          Sequential models with `tf.keras.Input([...], batch_size=X)`, the\n",
            " |          batch size will always be preserved). Defaults to `True`.\n",
            " |      Returns:\n",
            " |        If the model inputs are defined, returns a tuple `(args, kwargs)`. All\n",
            " |        elements in `args` and `kwargs` are `tf.TensorSpec`.\n",
            " |        If the model inputs are not defined, returns `None`.\n",
            " |        The model inputs are automatically set when calling the model,\n",
            " |        `model.fit`, `model.evaluate` or `model.predict`.\n",
            " |  \n",
            " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
            " |      Saves all layer weights.\n",
            " |      \n",
            " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
            " |      argument.\n",
            " |      \n",
            " |      When saving in HDF5 format, the weight file has:\n",
            " |        - `layer_names` (attribute), a list of strings\n",
            " |            (ordered names of model layers).\n",
            " |        - For every layer, a `group` named `layer.name`\n",
            " |            - For every such layer group, a group attribute `weight_names`,\n",
            " |                a list of strings\n",
            " |                (ordered names of weights tensor of the layer).\n",
            " |            - For every weight in the layer, a dataset\n",
            " |                storing the weight value, named after the weight tensor.\n",
            " |      \n",
            " |      When saving in TensorFlow format, all objects referenced by the network\n",
            " |      are saved in the same format as `tf.train.Checkpoint`, including any\n",
            " |      `Layer` instances or `Optimizer` instances assigned to object\n",
            " |      attributes. For networks constructed from inputs and outputs using\n",
            " |      `tf.keras.Model(inputs, outputs)`, `Layer` instances used by the network\n",
            " |      are tracked/saved automatically. For user-defined classes which inherit\n",
            " |      from `tf.keras.Model`, `Layer` instances must be assigned to object\n",
            " |      attributes, typically in the constructor. See the documentation of\n",
            " |      `tf.train.Checkpoint` and `tf.keras.Model` for details.\n",
            " |      \n",
            " |      While the formats are the same, do not mix `save_weights` and\n",
            " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should\n",
            " |      be loaded using `Model.load_weights`. Checkpoints saved using\n",
            " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
            " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
            " |      `save_weights` for training checkpoints.\n",
            " |      \n",
            " |      The TensorFlow format matches objects and variables by starting at a\n",
            " |      root object, `self` for `save_weights`, and greedily matching attribute\n",
            " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save`\n",
            " |      this is the `Checkpoint` even if the `Checkpoint` has a model attached.\n",
            " |      This means saving a `tf.keras.Model` using `save_weights` and loading\n",
            " |      into a `tf.train.Checkpoint` with a `Model` attached (or vice versa)\n",
            " |      will not match the `Model`'s variables. See the\n",
            " |      [guide to training checkpoints](\n",
            " |      https://www.tensorflow.org/guide/checkpoint) for details on\n",
            " |      the TensorFlow format.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: String or PathLike, path to the file to save the weights\n",
            " |              to. When saving in TensorFlow format, this is the prefix used\n",
            " |              for checkpoint files (multiple files are generated). Note that\n",
            " |              the '.h5' suffix causes weights to be saved in HDF5 format.\n",
            " |          overwrite: Whether to silently overwrite any existing file at the\n",
            " |              target location, or provide the user with a manual prompt.\n",
            " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
            " |              '.keras' will default to HDF5 if `save_format` is `None`.\n",
            " |              Otherwise `None` defaults to 'tf'.\n",
            " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            " |              options for saving weights.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: If `h5py` is not available when attempting to save in\n",
            " |              HDF5 format.\n",
            " |  \n",
            " |  summary(self, line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False, layer_range=None)\n",
            " |      Prints a string summary of the network.\n",
            " |      \n",
            " |      Args:\n",
            " |          line_length: Total length of printed lines\n",
            " |              (e.g. set this to adapt the display to different\n",
            " |              terminal window sizes).\n",
            " |          positions: Relative or absolute positions of log elements\n",
            " |              in each line. If not provided,\n",
            " |              defaults to `[.33, .55, .67, 1.]`.\n",
            " |          print_fn: Print function to use. By default, prints to `stdout`.\n",
            " |              If `stdout` doesn't work in your environment, change to `print`.\n",
            " |              It will be called on each line of the summary.\n",
            " |              You can set it to a custom function\n",
            " |              in order to capture the string summary.\n",
            " |          expand_nested: Whether to expand the nested models.\n",
            " |              If not provided, defaults to `False`.\n",
            " |          show_trainable: Whether to show if a layer is trainable.\n",
            " |              If not provided, defaults to `False`.\n",
            " |          layer_range: a list or tuple of 2 strings,\n",
            " |              which is the starting layer name and ending layer name\n",
            " |              (both inclusive) indicating the range of layers to be printed\n",
            " |              in summary. It also accepts regex patterns instead of exact\n",
            " |              name. In such case, start predicate will be the first element\n",
            " |              it matches to `layer_range[0]` and the end predicate will be\n",
            " |              the last element it matches to `layer_range[1]`.\n",
            " |              By default `None` which considers all layers of model.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if `summary()` is called before the model is built.\n",
            " |  \n",
            " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Test the model on a single batch of samples.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
            " |                model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
            " |                multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |                if the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case\n",
            " |            of temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated\n",
            " |            across batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a\n",
            " |            dict, with each key being the name of the metric. If `False`, they\n",
            " |            are returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.test_on_batch` is wrapped in a\n",
            " |            `tf.function`.\n",
            " |  \n",
            " |  test_step(self, data)\n",
            " |      The logic for one evaluation step.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.make_test_function`.\n",
            " |      \n",
            " |      This function should contain the mathematical logic for one step of\n",
            " |      evaluation.\n",
            " |      This typically includes the forward pass, loss calculation, and metrics\n",
            " |      updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function`\n",
            " |      and `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_test_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned.\n",
            " |  \n",
            " |  to_json(self, **kwargs)\n",
            " |      Returns a JSON string containing the network configuration.\n",
            " |      \n",
            " |      To load a network from a JSON save file, use\n",
            " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: Additional keyword arguments to be passed to\n",
            " |              *`json.dumps()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A JSON string.\n",
            " |  \n",
            " |  to_yaml(self, **kwargs)\n",
            " |      Returns a yaml string containing the network configuration.\n",
            " |      \n",
            " |      Note: Since TF 2.6, this method is no longer supported and will raise a\n",
            " |      RuntimeError.\n",
            " |      \n",
            " |      To load a network from a yaml save file, use\n",
            " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
            " |      \n",
            " |      `custom_objects` should be a dictionary mapping\n",
            " |      the names of custom losses / layers / etc to the corresponding\n",
            " |      functions / classes.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `yaml.dump()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A YAML string.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: announces that the method poses a security risk\n",
            " |  \n",
            " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Runs a single gradient update on a single batch of data.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |                if the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case\n",
            " |            of temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers)\n",
            " |            to a weight (float) to apply to the model's loss for the samples\n",
            " |            from this class during training. This can be useful to tell the\n",
            " |            model to \"pay more attention\" to samples from an under-represented\n",
            " |            class.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated\n",
            " |            across batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a\n",
            " |            dict, with each key being the name of the metric. If `False`, they\n",
            " |            are returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar training loss\n",
            " |          (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  train_step(self, data)\n",
            " |      The logic for one training step.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      For concrete examples of how to override this method see\n",
            " |      [Customizing what happens in fit](\n",
            " |      https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n",
            " |      This method is called by `Model.make_train_function`.\n",
            " |      \n",
            " |      This method should contain the mathematical logic for one step of\n",
            " |      training.  This typically includes the forward pass, loss calculation,\n",
            " |      backpropagation, and metric updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function`\n",
            " |      and `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_train_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned. Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  __new__(cls, *args, **kwargs)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  distribute_strategy\n",
            " |      The `tf.distribute.Strategy` this model was created under.\n",
            " |  \n",
            " |  metrics\n",
            " |      Return metrics added using `compile()` or `add_metric()`.\n",
            " |      \n",
            " |      Note: Metrics passed to `compile()` are available only after a\n",
            " |      `keras.Model` has been trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> model.fit(x, y)\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.add_metric(\n",
            " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> model.fit(x, (y, y))\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc', 'mean']\n",
            " |  \n",
            " |  metrics_names\n",
            " |      Returns the model's display labels for all outputs.\n",
            " |      \n",
            " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
            " |      trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> model.metrics_names\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> model.fit(x, y)\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> model.fit(x, (y, y))\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc']\n",
            " |  \n",
            " |  non_trainable_weights\n",
            " |      List of all non-trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Non-trainable weights are *not* updated during training. They are\n",
            " |      expected to be updated manually in `call()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of non-trainable variables.\n",
            " |  \n",
            " |  state_updates\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Returns the `updates` from all layers that are stateful.\n",
            " |      \n",
            " |      This is useful for separating training updates and\n",
            " |      state updates, e.g. when we need to update a layer's internal state\n",
            " |      during prediction.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A list of update ops.\n",
            " |  \n",
            " |  trainable_weights\n",
            " |      List of all trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Trainable weights are updated via gradient descent during training.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of trainable variables.\n",
            " |  \n",
            " |  weights\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
            " |      not themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  distribute_reduction_method\n",
            " |      The method employed to reduce per-replica values during training.\n",
            " |      \n",
            " |      Unless specified, the value \"auto\" will be assumed, indicating that\n",
            " |      the reduction strategy should be chosen based on the current\n",
            " |      running environment.\n",
            " |      See `reduce_per_replica` function for more details.\n",
            " |  \n",
            " |  jit_compile\n",
            " |      Specify whether to compile the model with XLA.\n",
            " |      \n",
            " |      [XLA](https://www.tensorflow.org/xla) is an optimizing compiler\n",
            " |      for machine learning. `jit_compile` is not enabled by default.\n",
            " |      Note that `jit_compile=True` may not necessarily work for all models.\n",
            " |      \n",
            " |      For more information on supported operations please refer to the\n",
            " |      [XLA documentation](https://www.tensorflow.org/xla). Also refer to\n",
            " |      [known XLA issues](https://www.tensorflow.org/xla/known_issues)\n",
            " |      for more details.\n",
            " |  \n",
            " |  run_eagerly\n",
            " |      Settable attribute indicating whether the model should run eagerly.\n",
            " |      \n",
            " |      Running eagerly means that your model will be run step by step,\n",
            " |      like Python code. Your model might run slower, but it should become\n",
            " |      easier for you to debug it by stepping into individual layer calls.\n",
            " |      \n",
            " |      By default, we will attempt to compile your model to a static graph to\n",
            " |      deliver the best execution performance.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Boolean, whether the model should run eagerly.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_loss(self, losses, **kwargs)\n",
            " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Some losses (for instance, activity regularization losses) may be\n",
            " |      dependent on the inputs passed when calling a layer. Hence, when reusing\n",
            " |      the same layer on different inputs `a` and `b`, some entries in\n",
            " |      `layer.losses` may be dependent on `a` and some on `b`. This method\n",
            " |      automatically keeps track of dependencies.\n",
            " |      \n",
            " |      This method can be used inside a subclassed layer or model's `call`\n",
            " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyLayer(tf.keras.layers.Layer):\n",
            " |        def call(self, inputs):\n",
            " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      The same code works in distributed training: the input to `add_loss()`\n",
            " |      is treated like a regularization loss and averaged across replicas\n",
            " |      by the training loop (both built-in `Model.fit()` and compliant custom\n",
            " |      training loops).\n",
            " |      \n",
            " |      The `add_loss` method can also be called directly on a Functional Model\n",
            " |      during construction. In this case, any loss Tensors passed to this Model\n",
            " |      must be symbolic and be able to be traced back to the model's `Input`s.\n",
            " |      These losses become part of the model's topology and are tracked in\n",
            " |      `get_config`.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Activity regularization.\n",
            " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      ```\n",
            " |      \n",
            " |      If this is not the case for your loss (if, for example, your loss\n",
            " |      references a `Variable` of one of the model's layers), you can wrap your\n",
            " |      loss in a zero-argument lambda. These losses are not tracked as part of\n",
            " |      the model's topology since they can't be serialized.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      d = tf.keras.layers.Dense(10)\n",
            " |      x = d(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Weight regularization.\n",
            " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors,\n",
            " |          losses may also be zero-argument callables which create a loss\n",
            " |          tensor.\n",
            " |        **kwargs: Used for backwards compatibility only.\n",
            " |  \n",
            " |  add_metric(self, value, name=None, **kwargs)\n",
            " |      Adds metric tensor to the layer.\n",
            " |      \n",
            " |      This method can be used inside the `call()` method of a subclassed layer\n",
            " |      or model.\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
            " |        def __init__(self):\n",
            " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
            " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
            " |      \n",
            " |        def call(self, inputs):\n",
            " |          self.add_metric(self.mean(inputs))\n",
            " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any tensor passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      metrics become part of the model's topology and are tracked when you\n",
            " |      save the model via `save()`.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
            " |      Functional Model, as shown in the example below, is not supported. This\n",
            " |      is because we cannot trace the metric result tensor back to the model's\n",
            " |      inputs.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        value: Metric tensor.\n",
            " |        name: String metric name.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |          `aggregation` - When the `value` tensor provided is not the result\n",
            " |          of calling a `keras.Metric` instance, it will be aggregated by\n",
            " |          default using a `keras.Metric.Mean`.\n",
            " |  \n",
            " |  add_update(self, updates)\n",
            " |      Add update op(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Weight updates (for instance, the updates of the moving mean and\n",
            " |      variance in a BatchNormalization layer) may be dependent on the inputs\n",
            " |      passed when calling a layer. Hence, when reusing the same layer on\n",
            " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This call is ignored when eager execution is enabled (in that case,\n",
            " |      variable updates are run on the fly and thus do not need to be tracked\n",
            " |      for later execution).\n",
            " |      \n",
            " |      Args:\n",
            " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            " |          that returns an update op. A zero-arg callable should be passed in\n",
            " |          order to disable running the updates by setting `trainable=False`\n",
            " |          on this Layer, when executing in Eager mode.\n",
            " |  \n",
            " |  add_variable(self, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
            " |  \n",
            " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
            " |      Adds a new variable to the layer.\n",
            " |      \n",
            " |      Args:\n",
            " |        name: Variable name.\n",
            " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
            " |        initializer: Initializer instance (callable).\n",
            " |        regularizer: Regularizer instance (callable).\n",
            " |        trainable: Boolean, whether the variable should be part of the layer's\n",
            " |          \"trainable_variables\" (e.g. variables, biases)\n",
            " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            " |          Note that `trainable` cannot be `True` if `synchronization`\n",
            " |          is set to `ON_READ`.\n",
            " |        constraint: Constraint instance (callable).\n",
            " |        use_resource: Whether to use a `ResourceVariable` or not.\n",
            " |          See [this guide](\n",
            " |          https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)\n",
            " |           for more information.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set\n",
            " |          to `AUTO` and the current `DistributionStrategy` chooses when to\n",
            " |          synchronize. If `synchronization` is set to `ON_READ`, `trainable`\n",
            " |          must not be set to `True`.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            " |          `collections`, `experimental_autocast` and `caching_device`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The variable created.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: When giving unsupported dtype and no initializer or when\n",
            " |          trainable has been set to True with synchronization set as\n",
            " |          `ON_READ`.\n",
            " |  \n",
            " |  build_from_config(self, config)\n",
            " |  \n",
            " |  compute_output_signature(self, input_signature)\n",
            " |      Compute the output tensor signature of the layer based on the inputs.\n",
            " |      \n",
            " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            " |      and dtype information for a tensor. This method allows layers to provide\n",
            " |      output dtype information if it is different from the input dtype.\n",
            " |      For any layer that doesn't implement this function,\n",
            " |      the framework will fall back to use `compute_output_shape`, and will\n",
            " |      assume that the output dtype matches the input dtype.\n",
            " |      \n",
            " |      Args:\n",
            " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            " |          objects, describing a candidate input for the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Single TensorSpec or nested structure of TensorSpec objects,\n",
            " |          describing how the layer would transform the provided input.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            " |  \n",
            " |  count_params(self)\n",
            " |      Count the total number of scalars composing the weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An integer count.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if the layer isn't yet built\n",
            " |            (in which case its weights aren't yet defined).\n",
            " |  \n",
            " |  finalize_state(self)\n",
            " |      Finalizes the layers state after updating layer weights.\n",
            " |      \n",
            " |      This function can be subclassed in a layer and will be called after\n",
            " |      updating a layer weights. It can be overridden to finalize any\n",
            " |      additional layer state after a weight update.\n",
            " |      \n",
            " |      This function will be called after weights of a layer have been restored\n",
            " |      from a loaded model.\n",
            " |  \n",
            " |  get_build_config(self)\n",
            " |  \n",
            " |  get_input_at(self, node_index)\n",
            " |      Retrieves the input tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first input node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_input_mask_at(self, node_index)\n",
            " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple inputs).\n",
            " |  \n",
            " |  get_input_shape_at(self, node_index)\n",
            " |      Retrieves the input shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_at(self, node_index)\n",
            " |      Retrieves the output tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first output node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_mask_at(self, node_index)\n",
            " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple outputs).\n",
            " |  \n",
            " |  get_output_shape_at(self, node_index)\n",
            " |      Retrieves the output shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  set_weights(self, weights)\n",
            " |      Sets the weights of the layer, from NumPy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      sets the weight values from numpy arrays. The weight values should be\n",
            " |      passed in the order they are created by the layer. Note that the layer's\n",
            " |      weights must be instantiated before calling this function, by calling\n",
            " |      the layer.\n",
            " |      \n",
            " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
            " |      matrix and the bias vector. These can be used to set the weights of\n",
            " |      another `Dense` layer:\n",
            " |      \n",
            " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> layer_a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Args:\n",
            " |        weights: a list of NumPy arrays. The number\n",
            " |          of arrays and their shape must match\n",
            " |          number of the dimensions of the weights\n",
            " |          of the layer (i.e. it should match the\n",
            " |          output of `get_weights`).\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If the provided weights list does not match the\n",
            " |          layer's specifications.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  compute_dtype\n",
            " |      The dtype of the layer's computations.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
            " |      the weights.\n",
            " |      \n",
            " |      Layers automatically cast their inputs to the compute dtype, which\n",
            " |      causes computations and the output to be in the compute dtype as well.\n",
            " |      This is done by the base Layer class in `Layer.__call__`, so you do not\n",
            " |      have to insert these casts if implementing your own layer.\n",
            " |      \n",
            " |      Layers often perform certain internal computations in higher precision\n",
            " |      when `compute_dtype` is float16 or bfloat16 for numeric stability. The\n",
            " |      output will still typically be float16 or bfloat16 in such cases.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The layer's compute dtype.\n",
            " |  \n",
            " |  dtype\n",
            " |      The dtype of the layer weights.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
            " |      dtype of the layer's computations.\n",
            " |  \n",
            " |  dtype_policy\n",
            " |      The dtype policy associated with this layer.\n",
            " |      \n",
            " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
            " |  \n",
            " |  dynamic\n",
            " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
            " |  \n",
            " |  inbound_nodes\n",
            " |      Return Functional API nodes upstream of this layer.\n",
            " |  \n",
            " |  input_mask\n",
            " |      Retrieves the input mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input mask tensor (potentially None) or list of input\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  losses\n",
            " |      List of losses added using the `add_loss()` API.\n",
            " |      \n",
            " |      Variable regularization tensors are created when this property is\n",
            " |      accessed, so it is eager safe: accessing `losses` under a\n",
            " |      `tf.GradientTape` will propagate gradients back to the corresponding\n",
            " |      variables.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
            " |      ...   def call(self, inputs):\n",
            " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |      ...     return inputs\n",
            " |      >>> l = MyLayer()\n",
            " |      >>> l(np.ones((10, 1)))\n",
            " |      >>> l.losses\n",
            " |      [1.0]\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Activity regularization.\n",
            " |      >>> len(model.losses)\n",
            " |      0\n",
            " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      >>> len(model.losses)\n",
            " |      1\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
            " |      >>> x = d(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Weight regularization.\n",
            " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      >>> model.losses\n",
            " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of tensors.\n",
            " |  \n",
            " |  name\n",
            " |      Name of the layer (string), set in the constructor.\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  outbound_nodes\n",
            " |      Return Functional API nodes downstream of this layer.\n",
            " |  \n",
            " |  output_mask\n",
            " |      Retrieves the output mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output mask tensor (potentially None) or list of output\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      Sequence of trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  updates\n",
            " |  \n",
            " |  variable_dtype\n",
            " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
            " |  \n",
            " |  variables\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Alias of `self.weights`.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
            " |      not themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  activity_regularizer\n",
            " |      Optional regularizer function for the output of this layer.\n",
            " |  \n",
            " |  stateful\n",
            " |  \n",
            " |  supports_masking\n",
            " |      Whether this layer supports computing a mask using `compute_mask`.\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  with_name_scope(method) from builtins.type\n",
            " |      Decorator to automatically enter the module name scope.\n",
            " |      \n",
            " |      >>> class MyModule(tf.Module):\n",
            " |      ...   @tf.Module.with_name_scope\n",
            " |      ...   def __call__(self, x):\n",
            " |      ...     if not hasattr(self, 'w'):\n",
            " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            " |      ...     return tf.matmul(x, self.w)\n",
            " |      \n",
            " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            " |      names included the module name:\n",
            " |      \n",
            " |      >>> mod = MyModule()\n",
            " |      >>> mod(tf.ones([1, 2]))\n",
            " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            " |      >>> mod.w\n",
            " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            " |      numpy=..., dtype=float32)>\n",
            " |      \n",
            " |      Args:\n",
            " |        method: The method to wrap.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The original method wrapped such that it enters the module's name scope.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  name_scope\n",
            " |      Returns a `tf.name_scope` instance for this class.\n",
            " |  \n",
            " |  submodules\n",
            " |      Sequence of all sub-modules.\n",
            " |      \n",
            " |      Submodules are modules which are properties of this module, or found as\n",
            " |      properties of modules which are properties of this module (and so on).\n",
            " |      \n",
            " |      >>> a = tf.Module()\n",
            " |      >>> b = tf.Module()\n",
            " |      >>> c = tf.Module()\n",
            " |      >>> a.b = b\n",
            " |      >>> b.c = c\n",
            " |      >>> list(a.submodules) == [b, c]\n",
            " |      True\n",
            " |      >>> list(b.submodules) == [c]\n",
            " |      True\n",
            " |      >>> list(c.submodules) == []\n",
            " |      True\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of all submodules.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Ways of creating Sequential Model\n",
        "#Method 1\n",
        "model = Sequential([Dense(4,activation = 'relu'),\n",
        "                    Dense(2,activation = 'relu'),\n",
        "                    Dense(1)])"
      ],
      "metadata": {
        "id": "j3-byk1auHMo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Method 2\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(4,activation='relu'))\n",
        "model.add(Dense(4,activation='relu'))\n",
        "model.add(Dense(4,activation='relu'))\n",
        "\n",
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "Uz7pMA1Wu2RS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',loss='mse')"
      ],
      "metadata": {
        "id": "jsBa8HGlvMRS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x = X_train,y = y_train,epochs=2500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXwP9OoXwSyR",
        "outputId": "a7698eba-7321-4e76-b2c2-d54f6429fc5a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2472735145984.0000\n",
            "Epoch 2/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2472894267392.0000\n",
            "Epoch 3/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2472853372928.0000\n",
            "Epoch 4/2500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2472597258240.0000\n",
            "Epoch 5/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2472624259072.0000\n",
            "Epoch 6/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2472734883840.0000\n",
            "Epoch 7/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2472742223872.0000\n",
            "Epoch 8/2500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2472543518720.0000\n",
            "Epoch 9/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2472535654400.0000\n",
            "Epoch 10/2500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2472503934976.0000\n",
            "Epoch 11/2500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2472701329408.0000\n",
            "Epoch 12/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2472503410688.0000\n",
            "Epoch 13/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2472398290944.0000\n",
            "Epoch 14/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2472409825280.0000\n",
            "Epoch 15/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2472775254016.0000\n",
            "Epoch 16/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2472328298496.0000\n",
            "Epoch 17/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2472315977728.0000\n",
            "Epoch 18/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2472374173696.0000\n",
            "Epoch 19/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2472355037184.0000\n",
            "Epoch 20/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2472234975232.0000\n",
            "Epoch 21/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2472160788480.0000\n",
            "Epoch 22/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2472164196352.0000\n",
            "Epoch 23/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2472101281792.0000\n",
            "Epoch 24/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2472211644416.0000\n",
            "Epoch 25/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2472066940928.0000\n",
            "Epoch 26/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2472145321984.0000\n",
            "Epoch 27/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471946878976.0000\n",
            "Epoch 28/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2472012677120.0000\n",
            "Epoch 29/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2472135360512.0000\n",
            "Epoch 30/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471879245824.0000\n",
            "Epoch 31/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471902314496.0000\n",
            "Epoch 32/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471889731584.0000\n",
            "Epoch 33/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471918829568.0000\n",
            "Epoch 34/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2472000094208.0000\n",
            "Epoch 35/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471751319552.0000\n",
            "Epoch 36/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471745814528.0000\n",
            "Epoch 37/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471761543168.0000\n",
            "Epoch 38/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471877148672.0000\n",
            "Epoch 39/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471672676352.0000\n",
            "Epoch 40/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471871381504.0000\n",
            "Epoch 41/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471685783552.0000\n",
            "Epoch 42/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2471611596800.0000\n",
            "Epoch 43/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471504379904.0000\n",
            "Epoch 44/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471563362304.0000\n",
            "Epoch 45/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471609499648.0000\n",
            "Epoch 46/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471446183936.0000\n",
            "Epoch 47/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471532167168.0000\n",
            "Epoch 48/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471534264320.0000\n",
            "Epoch 49/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471322451968.0000\n",
            "Epoch 50/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471351287808.0000\n",
            "Epoch 51/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471357579264.0000\n",
            "Epoch 52/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471257702400.0000\n",
            "Epoch 53/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471171981312.0000\n",
            "Epoch 54/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471293878272.0000\n",
            "Epoch 55/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471282081792.0000\n",
            "Epoch 56/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471328219136.0000\n",
            "Epoch 57/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471182204928.0000\n",
            "Epoch 58/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471140786176.0000\n",
            "Epoch 59/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471106445312.0000\n",
            "Epoch 60/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471122173952.0000\n",
            "Epoch 61/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471043530752.0000\n",
            "Epoch 62/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470971179008.0000\n",
            "Epoch 63/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471170932736.0000\n",
            "Epoch 64/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470897254400.0000\n",
            "Epoch 65/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470957809664.0000\n",
            "Epoch 66/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470783746048.0000\n",
            "Epoch 67/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470895419392.0000\n",
            "Epoch 68/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471066861568.0000\n",
            "Epoch 69/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2470860029952.0000\n",
            "Epoch 70/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470772998144.0000\n",
            "Epoch 71/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470658703360.0000\n",
            "Epoch 72/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2471037501440.0000\n",
            "Epoch 73/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470609420288.0000\n",
            "Epoch 74/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470650052608.0000\n",
            "Epoch 75/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470645858304.0000\n",
            "Epoch 76/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470530514944.0000\n",
            "Epoch 77/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470692257792.0000\n",
            "Epoch 78/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470590021632.0000\n",
            "Epoch 79/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2470631702528.0000\n",
            "Epoch 80/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470749929472.0000\n",
            "Epoch 81/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470459736064.0000\n",
            "Epoch 82/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470386335744.0000\n",
            "Epoch 83/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2470544408576.0000\n",
            "Epoch 84/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470536544256.0000\n",
            "Epoch 85/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470322110464.0000\n",
            "Epoch 86/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470748618752.0000\n",
            "Epoch 87/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470300876800.0000\n",
            "Epoch 88/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470250807296.0000\n",
            "Epoch 89/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2470223282176.0000\n",
            "Epoch 90/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470430113792.0000\n",
            "Epoch 91/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470228525056.0000\n",
            "Epoch 92/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470198902784.0000\n",
            "Epoch 93/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470117638144.0000\n",
            "Epoch 94/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470374014976.0000\n",
            "Epoch 95/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470162464768.0000\n",
            "Epoch 96/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470008061952.0000\n",
            "Epoch 97/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470168494080.0000\n",
            "Epoch 98/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2469983682560.0000\n",
            "Epoch 99/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470256050176.0000\n",
            "Epoch 100/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469913427968.0000\n",
            "Epoch 101/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470022742016.0000\n",
            "Epoch 102/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470010683392.0000\n",
            "Epoch 103/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2470006226944.0000\n",
            "Epoch 104/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469920243712.0000\n",
            "Epoch 105/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469859950592.0000\n",
            "Epoch 106/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469973196800.0000\n",
            "Epoch 107/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469803065344.0000\n",
            "Epoch 108/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469939380224.0000\n",
            "Epoch 109/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469901893632.0000\n",
            "Epoch 110/2500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2469872533504.0000\n",
            "Epoch 111/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469682741248.0000\n",
            "Epoch 112/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469672779776.0000\n",
            "Epoch 113/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469836095488.0000\n",
            "Epoch 114/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469707120640.0000\n",
            "Epoch 115/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469557174272.0000\n",
            "Epoch 116/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469634768896.0000\n",
            "Epoch 117/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2469643943936.0000\n",
            "Epoch 118/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469637128192.0000\n",
            "Epoch 119/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469391237120.0000\n",
            "Epoch 120/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469724684288.0000\n",
            "Epoch 121/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469565562880.0000\n",
            "Epoch 122/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469353488384.0000\n",
            "Epoch 123/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469386780672.0000\n",
            "Epoch 124/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469381537792.0000\n",
            "Epoch 125/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469348507648.0000\n",
            "Epoch 126/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469362663424.0000\n",
            "Epoch 127/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469179686912.0000\n",
            "Epoch 128/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469246271488.0000\n",
            "Epoch 129/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469263048704.0000\n",
            "Epoch 130/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469135646720.0000\n",
            "Epoch 131/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469103403008.0000\n",
            "Epoch 132/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2469442355200.0000\n",
            "Epoch 133/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469049925632.0000\n",
            "Epoch 134/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469076402176.0000\n",
            "Epoch 135/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469283233792.0000\n",
            "Epoch 136/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469189386240.0000\n",
            "Epoch 137/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469007196160.0000\n",
            "Epoch 138/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469079547904.0000\n",
            "Epoch 139/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469127520256.0000\n",
            "Epoch 140/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469050187776.0000\n",
            "Epoch 141/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469072207872.0000\n",
            "Epoch 142/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468821336064.0000\n",
            "Epoch 143/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468964990976.0000\n",
            "Epoch 144/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468808491008.0000\n",
            "Epoch 145/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468845191168.0000\n",
            "Epoch 146/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2469130928128.0000\n",
            "Epoch 147/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468794597376.0000\n",
            "Epoch 148/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468800364544.0000\n",
            "Epoch 149/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468730372096.0000\n",
            "Epoch 150/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468744790016.0000\n",
            "Epoch 151/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2468783063040.0000\n",
            "Epoch 152/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468591960064.0000\n",
            "Epoch 153/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468797480960.0000\n",
            "Epoch 154/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468617650176.0000\n",
            "Epoch 155/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468580163584.0000\n",
            "Epoch 156/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468516724736.0000\n",
            "Epoch 157/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468620533760.0000\n",
            "Epoch 158/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468579377152.0000\n",
            "Epoch 159/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468358651904.0000\n",
            "Epoch 160/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468534288384.0000\n",
            "Epoch 161/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468351836160.0000\n",
            "Epoch 162/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468599562240.0000\n",
            "Epoch 163/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468434935808.0000\n",
            "Epoch 164/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468407672832.0000\n",
            "Epoch 165/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468330078208.0000\n",
            "Epoch 166/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468469538816.0000\n",
            "Epoch 167/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468288921600.0000\n",
            "Epoch 168/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468247240704.0000\n",
            "Epoch 169/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468396138496.0000\n",
            "Epoch 170/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468160995328.0000\n",
            "Epoch 171/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468059807744.0000\n",
            "Epoch 172/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468153393152.0000\n",
            "Epoch 173/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468077371392.0000\n",
            "Epoch 174/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468108566528.0000\n",
            "Epoch 175/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467972775936.0000\n",
            "Epoch 176/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468119314432.0000\n",
            "Epoch 177/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468039884800.0000\n",
            "Epoch 178/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467920871424.0000\n",
            "Epoch 179/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2468108304384.0000\n",
            "Epoch 180/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467999252480.0000\n",
            "Epoch 181/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467846684672.0000\n",
            "Epoch 182/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467923230720.0000\n",
            "Epoch 183/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467761750016.0000\n",
            "Epoch 184/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467922968576.0000\n",
            "Epoch 185/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467848519680.0000\n",
            "Epoch 186/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467765420032.0000\n",
            "Epoch 187/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467796090880.0000\n",
            "Epoch 188/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467904356352.0000\n",
            "Epoch 189/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467726622720.0000\n",
            "Epoch 190/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467531849728.0000\n",
            "Epoch 191/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467875782656.0000\n",
            "Epoch 192/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467651649536.0000\n",
            "Epoch 193/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467671048192.0000\n",
            "Epoch 194/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467670261760.0000\n",
            "Epoch 195/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467610492928.0000\n",
            "Epoch 196/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467527655424.0000\n",
            "Epoch 197/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467456876544.0000\n",
            "Epoch 198/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467460022272.0000\n",
            "Epoch 199/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467548102656.0000\n",
            "Epoch 200/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467497508864.0000\n",
            "Epoch 201/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467637755904.0000\n",
            "Epoch 202/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467317678080.0000\n",
            "Epoch 203/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467441147904.0000\n",
            "Epoch 204/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467494887424.0000\n",
            "Epoch 205/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467459497984.0000\n",
            "Epoch 206/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467503013888.0000\n",
            "Epoch 207/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467302211584.0000\n",
            "Epoch 208/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467239034880.0000\n",
            "Epoch 209/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467343630336.0000\n",
            "Epoch 210/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467313745920.0000\n",
            "Epoch 211/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467448750080.0000\n",
            "Epoch 212/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2467131293696.0000\n",
            "Epoch 213/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467279142912.0000\n",
            "Epoch 214/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467093807104.0000\n",
            "Epoch 215/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467039805440.0000\n",
            "Epoch 216/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467112157184.0000\n",
            "Epoch 217/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467133652992.0000\n",
            "Epoch 218/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467146498048.0000\n",
            "Epoch 219/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466961948672.0000\n",
            "Epoch 220/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467045048320.0000\n",
            "Epoch 221/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466972696576.0000\n",
            "Epoch 222/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466806497280.0000\n",
            "Epoch 223/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466913976320.0000\n",
            "Epoch 224/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466909519872.0000\n",
            "Epoch 225/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2467105865728.0000\n",
            "Epoch 226/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466857615360.0000\n",
            "Epoch 227/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466986590208.0000\n",
            "Epoch 228/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466844508160.0000\n",
            "Epoch 229/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466901655552.0000\n",
            "Epoch 230/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466771894272.0000\n",
            "Epoch 231/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466856828928.0000\n",
            "Epoch 232/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466698231808.0000\n",
            "Epoch 233/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466734931968.0000\n",
            "Epoch 234/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466756165632.0000\n",
            "Epoch 235/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466608578560.0000\n",
            "Epoch 236/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466561392640.0000\n",
            "Epoch 237/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466617229312.0000\n",
            "Epoch 238/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466577121280.0000\n",
            "Epoch 239/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466604646400.0000\n",
            "Epoch 240/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466656288768.0000\n",
            "Epoch 241/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466404106240.0000\n",
            "Epoch 242/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466703474688.0000\n",
            "Epoch 243/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466467282944.0000\n",
            "Epoch 244/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466344599552.0000\n",
            "Epoch 245/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466737553408.0000\n",
            "Epoch 246/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466325463040.0000\n",
            "Epoch 247/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466363211776.0000\n",
            "Epoch 248/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466556936192.0000\n",
            "Epoch 249/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466339094528.0000\n",
            "Epoch 250/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466496905216.0000\n",
            "Epoch 251/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466280112128.0000\n",
            "Epoch 252/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466211168256.0000\n",
            "Epoch 253/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466224275456.0000\n",
            "Epoch 254/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466209071104.0000\n",
            "Epoch 255/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466079309824.0000\n",
            "Epoch 256/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466217721856.0000\n",
            "Epoch 257/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466065940480.0000\n",
            "Epoch 258/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2466111553536.0000\n",
            "Epoch 259/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466206973952.0000\n",
            "Epoch 260/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466078261248.0000\n",
            "Epoch 261/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466062270464.0000\n",
            "Epoch 262/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466031599616.0000\n",
            "Epoch 263/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465994899456.0000\n",
            "Epoch 264/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465886109696.0000\n",
            "Epoch 265/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465922809856.0000\n",
            "Epoch 266/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2466136719360.0000\n",
            "Epoch 267/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465968160768.0000\n",
            "Epoch 268/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465895022592.0000\n",
            "Epoch 269/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465951907840.0000\n",
            "Epoch 270/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465775222784.0000\n",
            "Epoch 271/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465935392768.0000\n",
            "Epoch 272/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465758707712.0000\n",
            "Epoch 273/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465865400320.0000\n",
            "Epoch 274/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465777844224.0000\n",
            "Epoch 275/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465792524288.0000\n",
            "Epoch 276/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465745862656.0000\n",
            "Epoch 277/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465776271360.0000\n",
            "Epoch 278/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465746911232.0000\n",
            "Epoch 279/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465663811584.0000\n",
            "Epoch 280/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465802485760.0000\n",
            "Epoch 281/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465586216960.0000\n",
            "Epoch 282/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465876672512.0000\n",
            "Epoch 283/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465477951488.0000\n",
            "Epoch 284/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465639170048.0000\n",
            "Epoch 285/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465521467392.0000\n",
            "Epoch 286/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465566031872.0000\n",
            "Epoch 287/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465443348480.0000\n",
            "Epoch 288/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465364705280.0000\n",
            "Epoch 289/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465450164224.0000\n",
            "Epoch 290/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465580711936.0000\n",
            "Epoch 291/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465357103104.0000\n",
            "Epoch 292/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465492369408.0000\n",
            "Epoch 293/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465261158400.0000\n",
            "Epoch 294/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465229963264.0000\n",
            "Epoch 295/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465414250496.0000\n",
            "Epoch 296/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465251459072.0000\n",
            "Epoch 297/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465253031936.0000\n",
            "Epoch 298/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465242808320.0000\n",
            "Epoch 299/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465200078848.0000\n",
            "Epoch 300/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465372045312.0000\n",
            "Epoch 301/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465212923904.0000\n",
            "Epoch 302/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465208467456.0000\n",
            "Epoch 303/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465130348544.0000\n",
            "Epoch 304/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465365229568.0000\n",
            "Epoch 305/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465127464960.0000\n",
            "Epoch 306/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465171243008.0000\n",
            "Epoch 307/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2464938196992.0000\n",
            "Epoch 308/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465242546176.0000\n",
            "Epoch 309/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2464954449920.0000\n",
            "Epoch 310/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464872923136.0000\n",
            "Epoch 311/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2465088929792.0000\n",
            "Epoch 312/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465074774016.0000\n",
            "Epoch 313/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2464930594816.0000\n",
            "Epoch 314/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464905428992.0000\n",
            "Epoch 315/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2465089191936.0000\n",
            "Epoch 316/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464785891328.0000\n",
            "Epoch 317/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464802930688.0000\n",
            "Epoch 318/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464838320128.0000\n",
            "Epoch 319/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464858505216.0000\n",
            "Epoch 320/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2464739491840.0000\n",
            "Epoch 321/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464730841088.0000\n",
            "Epoch 322/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464719306752.0000\n",
            "Epoch 323/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2464845922304.0000\n",
            "Epoch 324/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464811319296.0000\n",
            "Epoch 325/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464532398080.0000\n",
            "Epoch 326/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464626245632.0000\n",
            "Epoch 327/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464587972608.0000\n",
            "Epoch 328/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2464573816832.0000\n",
            "Epoch 329/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464653508608.0000\n",
            "Epoch 330/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464509329408.0000\n",
            "Epoch 331/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464455852032.0000\n",
            "Epoch 332/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464676315136.0000\n",
            "Epoch 333/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2464602914816.0000\n",
            "Epoch 334/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464401588224.0000\n",
            "Epoch 335/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464434880512.0000\n",
            "Epoch 336/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2464457949184.0000\n",
            "Epoch 337/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464340770816.0000\n",
            "Epoch 338/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464387956736.0000\n",
            "Epoch 339/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464543408128.0000\n",
            "Epoch 340/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464351518720.0000\n",
            "Epoch 341/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464300662784.0000\n",
            "Epoch 342/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464311672832.0000\n",
            "Epoch 343/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2464320323584.0000\n",
            "Epoch 344/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464175095808.0000\n",
            "Epoch 345/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464174833664.0000\n",
            "Epoch 346/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464195805184.0000\n",
            "Epoch 347/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464298041344.0000\n",
            "Epoch 348/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464203931648.0000\n",
            "Epoch 349/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464205504512.0000\n",
            "Epoch 350/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464180338688.0000\n",
            "Epoch 351/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2464039043072.0000\n",
            "Epoch 352/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464149405696.0000\n",
            "Epoch 353/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464093306880.0000\n",
            "Epoch 354/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464210485248.0000\n",
            "Epoch 355/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464223330304.0000\n",
            "Epoch 356/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463954108416.0000\n",
            "Epoch 357/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464079413248.0000\n",
            "Epoch 358/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463861309440.0000\n",
            "Epoch 359/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2464108773376.0000\n",
            "Epoch 360/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464093831168.0000\n",
            "Epoch 361/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463862358016.0000\n",
            "Epoch 362/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2464082034688.0000\n",
            "Epoch 363/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463861309440.0000\n",
            "Epoch 364/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463856590848.0000\n",
            "Epoch 365/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2463971409920.0000\n",
            "Epoch 366/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463979012096.0000\n",
            "Epoch 367/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2463767986176.0000\n",
            "Epoch 368/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463944409088.0000\n",
            "Epoch 369/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463760908288.0000\n",
            "Epoch 370/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463635341312.0000\n",
            "Epoch 371/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463890407424.0000\n",
            "Epoch 372/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463696158720.0000\n",
            "Epoch 373/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463707168768.0000\n",
            "Epoch 374/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463776899072.0000\n",
            "Epoch 375/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463563251712.0000\n",
            "Epoch 376/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463704547328.0000\n",
            "Epoch 377/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463526289408.0000\n",
            "Epoch 378/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463480152064.0000\n",
            "Epoch 379/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463611224064.0000\n",
            "Epoch 380/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463577931776.0000\n",
            "Epoch 381/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463386566656.0000\n",
            "Epoch 382/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463569805312.0000\n",
            "Epoch 383/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2463473336320.0000\n",
            "Epoch 384/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463393906688.0000\n",
            "Epoch 385/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463622496256.0000\n",
            "Epoch 386/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463377129472.0000\n",
            "Epoch 387/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463452364800.0000\n",
            "Epoch 388/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463361925120.0000\n",
            "Epoch 389/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463389188096.0000\n",
            "Epoch 390/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463307399168.0000\n",
            "Epoch 391/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463569281024.0000\n",
            "Epoch 392/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463283806208.0000\n",
            "Epoch 393/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463310020608.0000\n",
            "Epoch 394/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463291146240.0000\n",
            "Epoch 395/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2463283806208.0000\n",
            "Epoch 396/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2463151685632.0000\n",
            "Epoch 397/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463348817920.0000\n",
            "Epoch 398/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2463149064192.0000\n",
            "Epoch 399/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2463257067520.0000\n",
            "Epoch 400/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2463235309568.0000\n",
            "Epoch 401/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2463232688128.0000\n",
            "Epoch 402/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463165579264.0000\n",
            "Epoch 403/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463119441920.0000\n",
            "Epoch 404/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2463224561664.0000\n",
            "Epoch 405/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463123111936.0000\n",
            "Epoch 406/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2463102402560.0000\n",
            "Epoch 407/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463067537408.0000\n",
            "Epoch 408/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463121014784.0000\n",
            "Epoch 409/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462869880832.0000\n",
            "Epoch 410/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462923358208.0000\n",
            "Epoch 411/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462994923520.0000\n",
            "Epoch 412/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2462865424384.0000\n",
            "Epoch 413/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462927814656.0000\n",
            "Epoch 414/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2463063343104.0000\n",
            "Epoch 415/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2462846287872.0000\n",
            "Epoch 416/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462881415168.0000\n",
            "Epoch 417/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462856511488.0000\n",
            "Epoch 418/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462931746816.0000\n",
            "Epoch 419/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462754275328.0000\n",
            "Epoch 420/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2462797791232.0000\n",
            "Epoch 421/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462827413504.0000\n",
            "Epoch 422/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462930436096.0000\n",
            "Epoch 423/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2462755323904.0000\n",
            "Epoch 424/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462744838144.0000\n",
            "Epoch 425/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2463008292864.0000\n",
            "Epoch 426/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2462553997312.0000\n",
            "Epoch 427/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462555308032.0000\n",
            "Epoch 428/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462763712512.0000\n",
            "Epoch 429/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462838947840.0000\n",
            "Epoch 430/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462553735168.0000\n",
            "Epoch 431/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462563172352.0000\n",
            "Epoch 432/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2462617698304.0000\n",
            "Epoch 433/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462707089408.0000\n",
            "Epoch 434/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462735138816.0000\n",
            "Epoch 435/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462537482240.0000\n",
            "Epoch 436/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462569201664.0000\n",
            "Epoch 437/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462512316416.0000\n",
            "Epoch 438/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462569988096.0000\n",
            "Epoch 439/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462339039232.0000\n",
            "Epoch 440/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462538006528.0000\n",
            "Epoch 441/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462515462144.0000\n",
            "Epoch 442/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462429478912.0000\n",
            "Epoch 443/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462253580288.0000\n",
            "Epoch 444/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462453596160.0000\n",
            "Epoch 445/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462401691648.0000\n",
            "Epoch 446/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462227890176.0000\n",
            "Epoch 447/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2462459101184.0000\n",
            "Epoch 448/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462358437888.0000\n",
            "Epoch 449/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462172315648.0000\n",
            "Epoch 450/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462253056000.0000\n",
            "Epoch 451/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462327767040.0000\n",
            "Epoch 452/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462188568576.0000\n",
            "Epoch 453/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462309416960.0000\n",
            "Epoch 454/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462374690816.0000\n",
            "Epoch 455/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2462102061056.0000\n",
            "Epoch 456/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462266425344.0000\n",
            "Epoch 457/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462080303104.0000\n",
            "Epoch 458/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462280843264.0000\n",
            "Epoch 459/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462157373440.0000\n",
            "Epoch 460/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462039670784.0000\n",
            "Epoch 461/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462124605440.0000\n",
            "Epoch 462/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462111236096.0000\n",
            "Epoch 463/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2462153179136.0000\n",
            "Epoch 464/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2462121721856.0000\n",
            "Epoch 465/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461977542656.0000\n",
            "Epoch 466/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462067720192.0000\n",
            "Epoch 467/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462199578624.0000\n",
            "Epoch 468/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2462050418688.0000\n",
            "Epoch 469/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461880025088.0000\n",
            "Epoch 470/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461998776320.0000\n",
            "Epoch 471/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461778051072.0000\n",
            "Epoch 472/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461848043520.0000\n",
            "Epoch 473/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461937172480.0000\n",
            "Epoch 474/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461980688384.0000\n",
            "Epoch 475/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461843849216.0000\n",
            "Epoch 476/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461820518400.0000\n",
            "Epoch 477/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461666377728.0000\n",
            "Epoch 478/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461974921216.0000\n",
            "Epoch 479/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461861150720.0000\n",
            "Epoch 480/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461693640704.0000\n",
            "Epoch 481/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461803479040.0000\n",
            "Epoch 482/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461688135680.0000\n",
            "Epoch 483/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461869277184.0000\n",
            "Epoch 484/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461529276416.0000\n",
            "Epoch 485/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461715660800.0000\n",
            "Epoch 486/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461650649088.0000\n",
            "Epoch 487/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2461637541888.0000\n",
            "Epoch 488/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2461622075392.0000\n",
            "Epoch 489/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461611327488.0000\n",
            "Epoch 490/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461588783104.0000\n",
            "Epoch 491/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461576462336.0000\n",
            "Epoch 492/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461638852608.0000\n",
            "Epoch 493/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461438312448.0000\n",
            "Epoch 494/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461720379392.0000\n",
            "Epoch 495/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461396369408.0000\n",
            "Epoch 496/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461468196864.0000\n",
            "Epoch 497/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461510402048.0000\n",
            "Epoch 498/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461358096384.0000\n",
            "Epoch 499/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461462167552.0000\n",
            "Epoch 500/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461440671744.0000\n",
            "Epoch 501/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461600579584.0000\n",
            "Epoch 502/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461488906240.0000\n",
            "Epoch 503/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461406855168.0000\n",
            "Epoch 504/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2461467934720.0000\n",
            "Epoch 505/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461220995072.0000\n",
            "Epoch 506/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461308551168.0000\n",
            "Epoch 507/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461266608128.0000\n",
            "Epoch 508/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2461291511808.0000\n",
            "Epoch 509/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2461465313280.0000\n",
            "Epoch 510/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461160177664.0000\n",
            "Epoch 511/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461172760576.0000\n",
            "Epoch 512/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461222567936.0000\n",
            "Epoch 513/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461125574656.0000\n",
            "Epoch 514/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461446963200.0000\n",
            "Epoch 515/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461039853568.0000\n",
            "Epoch 516/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461105651712.0000\n",
            "Epoch 517/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2461034348544.0000\n",
            "Epoch 518/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2461157031936.0000\n",
            "Epoch 519/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461028843520.0000\n",
            "Epoch 520/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461093330944.0000\n",
            "Epoch 521/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461232791552.0000\n",
            "Epoch 522/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461035397120.0000\n",
            "Epoch 523/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461128720384.0000\n",
            "Epoch 524/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460918743040.0000\n",
            "Epoch 525/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461061349376.0000\n",
            "Epoch 526/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461071310848.0000\n",
            "Epoch 527/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460873916416.0000\n",
            "Epoch 528/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460826468352.0000\n",
            "Epoch 529/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460948365312.0000\n",
            "Epoch 530/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460891480064.0000\n",
            "Epoch 531/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2461148119040.0000\n",
            "Epoch 532/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460712435712.0000\n",
            "Epoch 533/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460883091456.0000\n",
            "Epoch 534/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460841148416.0000\n",
            "Epoch 535/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2460903014400.0000\n",
            "Epoch 536/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460797894656.0000\n",
            "Epoch 537/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460821749760.0000\n",
            "Epoch 538/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460732620800.0000\n",
            "Epoch 539/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460711911424.0000\n",
            "Epoch 540/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460644016128.0000\n",
            "Epoch 541/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460847964160.0000\n",
            "Epoch 542/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460809953280.0000\n",
            "Epoch 543/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460604694528.0000\n",
            "Epoch 544/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460571926528.0000\n",
            "Epoch 545/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2460741533696.0000\n",
            "Epoch 546/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2460614918144.0000\n",
            "Epoch 547/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2460688318464.0000\n",
            "Epoch 548/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460720300032.0000\n",
            "Epoch 549/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2460523429888.0000\n",
            "Epoch 550/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460558032896.0000\n",
            "Epoch 551/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460531294208.0000\n",
            "Epoch 552/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460727902208.0000\n",
            "Epoch 553/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460446621696.0000\n",
            "Epoch 554/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460421718016.0000\n",
            "Epoch 555/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460475981824.0000\n",
            "Epoch 556/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460366405632.0000\n",
            "Epoch 557/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460556460032.0000\n",
            "Epoch 558/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460474933248.0000\n",
            "Epoch 559/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460290646016.0000\n",
            "Epoch 560/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460271771648.0000\n",
            "Epoch 561/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460548595712.0000\n",
            "Epoch 562/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460261810176.0000\n",
            "Epoch 563/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460234547200.0000\n",
            "Epoch 564/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460383182848.0000\n",
            "Epoch 565/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460296151040.0000\n",
            "Epoch 566/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460229566464.0000\n",
            "Epoch 567/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460550430720.0000\n",
            "Epoch 568/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460358279168.0000\n",
            "Epoch 569/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460173205504.0000\n",
            "Epoch 570/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460148826112.0000\n",
            "Epoch 571/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460357230592.0000\n",
            "Epoch 572/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460070969344.0000\n",
            "Epoch 573/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460188672000.0000\n",
            "Epoch 574/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460197322752.0000\n",
            "Epoch 575/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460047638528.0000\n",
            "Epoch 576/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460111339520.0000\n",
            "Epoch 577/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459989180416.0000\n",
            "Epoch 578/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460027715584.0000\n",
            "Epoch 579/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460221702144.0000\n",
            "Epoch 580/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460015394816.0000\n",
            "Epoch 581/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459949858816.0000\n",
            "Epoch 582/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460134932480.0000\n",
            "Epoch 583/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460047638528.0000\n",
            "Epoch 584/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459976073216.0000\n",
            "Epoch 585/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460063629312.0000\n",
            "Epoch 586/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460089319424.0000\n",
            "Epoch 587/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459812233216.0000\n",
            "Epoch 588/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460104785920.0000\n",
            "Epoch 589/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2460043182080.0000\n",
            "Epoch 590/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459807252480.0000\n",
            "Epoch 591/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459771076608.0000\n",
            "Epoch 592/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459807252480.0000\n",
            "Epoch 593/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459878293504.0000\n",
            "Epoch 594/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459805941760.0000\n",
            "Epoch 595/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459905294336.0000\n",
            "Epoch 596/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459789688832.0000\n",
            "Epoch 597/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459963228160.0000\n",
            "Epoch 598/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459783397376.0000\n",
            "Epoch 599/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459756920832.0000\n",
            "Epoch 600/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459775270912.0000\n",
            "Epoch 601/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459642101760.0000\n",
            "Epoch 602/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459754823680.0000\n",
            "Epoch 603/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459556904960.0000\n",
            "Epoch 604/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459788902400.0000\n",
            "Epoch 605/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459682471936.0000\n",
            "Epoch 606/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459566866432.0000\n",
            "Epoch 607/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459554545664.0000\n",
            "Epoch 608/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459987607552.0000\n",
            "Epoch 609/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459654160384.0000\n",
            "Epoch 610/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459650752512.0000\n",
            "Epoch 611/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459508932608.0000\n",
            "Epoch 612/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459605663744.0000\n",
            "Epoch 613/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459569487872.0000\n",
            "Epoch 614/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459451260928.0000\n",
            "Epoch 615/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459621392384.0000\n",
            "Epoch 616/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459674869760.0000\n",
            "Epoch 617/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459541700608.0000\n",
            "Epoch 618/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459372093440.0000\n",
            "Epoch 619/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459524399104.0000\n",
            "Epoch 620/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459489533952.0000\n",
            "Epoch 621/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459442872320.0000\n",
            "Epoch 622/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459360559104.0000\n",
            "Epoch 623/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459361869824.0000\n",
            "Epoch 624/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459392540672.0000\n",
            "Epoch 625/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459520204800.0000\n",
            "Epoch 626/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459351121920.0000\n",
            "Epoch 627/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459298955264.0000\n",
            "Epoch 628/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459281915904.0000\n",
            "Epoch 629/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459231059968.0000\n",
            "Epoch 630/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459472494592.0000\n",
            "Epoch 631/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459341946880.0000\n",
            "Epoch 632/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459185709056.0000\n",
            "Epoch 633/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459215069184.0000\n",
            "Epoch 634/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459109687296.0000\n",
            "Epoch 635/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459203534848.0000\n",
            "Epoch 636/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459092647936.0000\n",
            "Epoch 637/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459126464512.0000\n",
            "Epoch 638/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459028684800.0000\n",
            "Epoch 639/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459315208192.0000\n",
            "Epoch 640/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459065647104.0000\n",
            "Epoch 641/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459113357312.0000\n",
            "Epoch 642/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459025539072.0000\n",
            "Epoch 643/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459199602688.0000\n",
            "Epoch 644/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459149533184.0000\n",
            "Epoch 645/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459130658816.0000\n",
            "Epoch 646/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459030519808.0000\n",
            "Epoch 647/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459105230848.0000\n",
            "Epoch 648/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458991460352.0000\n",
            "Epoch 649/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2459178631168.0000\n",
            "Epoch 650/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458921205760.0000\n",
            "Epoch 651/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458965770240.0000\n",
            "Epoch 652/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458997227520.0000\n",
            "Epoch 653/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458817396736.0000\n",
            "Epoch 654/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458997227520.0000\n",
            "Epoch 655/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458910195712.0000\n",
            "Epoch 656/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458849116160.0000\n",
            "Epoch 657/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459204583424.0000\n",
            "Epoch 658/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2459135901696.0000\n",
            "Epoch 659/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458897612800.0000\n",
            "Epoch 660/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458886864896.0000\n",
            "Epoch 661/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458811367424.0000\n",
            "Epoch 662/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458833911808.0000\n",
            "Epoch 663/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458716995584.0000\n",
            "Epoch 664/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458985693184.0000\n",
            "Epoch 665/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458717519872.0000\n",
            "Epoch 666/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458634944512.0000\n",
            "Epoch 667/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458865369088.0000\n",
            "Epoch 668/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458699694080.0000\n",
            "Epoch 669/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458773880832.0000\n",
            "Epoch 670/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458558136320.0000\n",
            "Epoch 671/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458776240128.0000\n",
            "Epoch 672/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458653294592.0000\n",
            "Epoch 673/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458619478016.0000\n",
            "Epoch 674/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458586185728.0000\n",
            "Epoch 675/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458738229248.0000\n",
            "Epoch 676/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458640973824.0000\n",
            "Epoch 677/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458647789568.0000\n",
            "Epoch 678/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458726694912.0000\n",
            "Epoch 679/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458494435328.0000\n",
            "Epoch 680/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458585661440.0000\n",
            "Epoch 681/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458536902656.0000\n",
            "Epoch 682/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458516193280.0000\n",
            "Epoch 683/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458513047552.0000\n",
            "Epoch 684/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458703626240.0000\n",
            "Epoch 685/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458368606208.0000\n",
            "Epoch 686/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458538999808.0000\n",
            "Epoch 687/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458638614528.0000\n",
            "Epoch 688/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458455113728.0000\n",
            "Epoch 689/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458498629632.0000\n",
            "Epoch 690/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458603225088.0000\n",
            "Epoch 691/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2458459570176.0000\n",
            "Epoch 692/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458420248576.0000\n",
            "Epoch 693/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458584612864.0000\n",
            "Epoch 694/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458284457984.0000\n",
            "Epoch 695/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458488143872.0000\n",
            "Epoch 696/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458294157312.0000\n",
            "Epoch 697/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458376470528.0000\n",
            "Epoch 698/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458332168192.0000\n",
            "Epoch 699/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458373849088.0000\n",
            "Epoch 700/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458298089472.0000\n",
            "Epoch 701/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458358906880.0000\n",
            "Epoch 702/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458247757824.0000\n",
            "Epoch 703/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458542407680.0000\n",
            "Epoch 704/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458085228544.0000\n",
            "Epoch 705/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458172260352.0000\n",
            "Epoch 706/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458251952128.0000\n",
            "Epoch 707/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458346061824.0000\n",
            "Epoch 708/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458066354176.0000\n",
            "Epoch 709/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458305429504.0000\n",
            "Epoch 710/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458065305600.0000\n",
            "Epoch 711/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2458194018304.0000\n",
            "Epoch 712/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458272661504.0000\n",
            "Epoch 713/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458287079424.0000\n",
            "Epoch 714/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458012352512.0000\n",
            "Epoch 715/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458090209280.0000\n",
            "Epoch 716/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458158891008.0000\n",
            "Epoch 717/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457920602112.0000\n",
            "Epoch 718/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458095976448.0000\n",
            "Epoch 719/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458247757824.0000\n",
            "Epoch 720/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2457975128064.0000\n",
            "Epoch 721/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457952321536.0000\n",
            "Epoch 722/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458118520832.0000\n",
            "Epoch 723/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458119569408.0000\n",
            "Epoch 724/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457882066944.0000\n",
            "Epoch 725/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457920864256.0000\n",
            "Epoch 726/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457943670784.0000\n",
            "Epoch 727/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2458136870912.0000\n",
            "Epoch 728/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457906970624.0000\n",
            "Epoch 729/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457933185024.0000\n",
            "Epoch 730/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2458068189184.0000\n",
            "Epoch 731/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457823084544.0000\n",
            "Epoch 732/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2458254311424.0000\n",
            "Epoch 733/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457928204288.0000\n",
            "Epoch 734/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457820987392.0000\n",
            "Epoch 735/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457806569472.0000\n",
            "Epoch 736/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457882066944.0000\n",
            "Epoch 737/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457738149888.0000\n",
            "Epoch 738/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2457699352576.0000\n",
            "Epoch 739/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457875251200.0000\n",
            "Epoch 740/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457799753728.0000\n",
            "Epoch 741/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457664487424.0000\n",
            "Epoch 742/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457860833280.0000\n",
            "Epoch 743/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457800015872.0000\n",
            "Epoch 744/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457779306496.0000\n",
            "Epoch 745/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457665273856.0000\n",
            "Epoch 746/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457656885248.0000\n",
            "Epoch 747/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457743917056.0000\n",
            "Epoch 748/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457637486592.0000\n",
            "Epoch 749/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457500123136.0000\n",
            "Epoch 750/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457685983232.0000\n",
            "Epoch 751/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457593970688.0000\n",
            "Epoch 752/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2457740771328.0000\n",
            "Epoch 753/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457554124800.0000\n",
            "Epoch 754/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457750208512.0000\n",
            "Epoch 755/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457589252096.0000\n",
            "Epoch 756/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457595019264.0000\n",
            "Epoch 757/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457495666688.0000\n",
            "Epoch 758/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457595019264.0000\n",
            "Epoch 759/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457480724480.0000\n",
            "Epoch 760/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457521094656.0000\n",
            "Epoch 761/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457668681728.0000\n",
            "Epoch 762/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457439830016.0000\n",
            "Epoch 763/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457505890304.0000\n",
            "Epoch 764/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457407324160.0000\n",
            "Epoch 765/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457512968192.0000\n",
            "Epoch 766/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457426984960.0000\n",
            "Epoch 767/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457465782272.0000\n",
            "Epoch 768/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457377177600.0000\n",
            "Epoch 769/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457455296512.0000\n",
            "Epoch 770/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457199968256.0000\n",
            "Epoch 771/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457422790656.0000\n",
            "Epoch 772/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457357778944.0000\n",
            "Epoch 773/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457369575424.0000\n",
            "Epoch 774/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457249513472.0000\n",
            "Epoch 775/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457450315776.0000\n",
            "Epoch 776/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457250824192.0000\n",
            "Epoch 777/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457308758016.0000\n",
            "Epoch 778/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457203113984.0000\n",
            "Epoch 779/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457539444736.0000\n",
            "Epoch 780/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457133907968.0000\n",
            "Epoch 781/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457155403776.0000\n",
            "Epoch 782/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457145180160.0000\n",
            "Epoch 783/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457545474048.0000\n",
            "Epoch 784/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457123684352.0000\n",
            "Epoch 785/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457170345984.0000\n",
            "Epoch 786/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457220153344.0000\n",
            "Epoch 787/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457325535232.0000\n",
            "Epoch 788/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457111101440.0000\n",
            "Epoch 789/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457347817472.0000\n",
            "Epoch 790/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457098518528.0000\n",
            "Epoch 791/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457203638272.0000\n",
            "Epoch 792/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457047924736.0000\n",
            "Epoch 793/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457187647488.0000\n",
            "Epoch 794/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457209929728.0000\n",
            "Epoch 795/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457113722880.0000\n",
            "Epoch 796/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2457154093056.0000\n",
            "Epoch 797/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457048973312.0000\n",
            "Epoch 798/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456886444032.0000\n",
            "Epoch 799/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457100091392.0000\n",
            "Epoch 800/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456956436480.0000\n",
            "Epoch 801/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457072566272.0000\n",
            "Epoch 802/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457013059584.0000\n",
            "Epoch 803/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456914755584.0000\n",
            "Epoch 804/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457108480000.0000\n",
            "Epoch 805/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457017253888.0000\n",
            "Epoch 806/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456958271488.0000\n",
            "Epoch 807/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456921047040.0000\n",
            "Epoch 808/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457072041984.0000\n",
            "Epoch 809/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456994709504.0000\n",
            "Epoch 810/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456864948224.0000\n",
            "Epoch 811/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456964825088.0000\n",
            "Epoch 812/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456846860288.0000\n",
            "Epoch 813/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2456784994304.0000\n",
            "Epoch 814/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456894832640.0000\n",
            "Epoch 815/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456885919744.0000\n",
            "Epoch 816/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456820383744.0000\n",
            "Epoch 817/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456752750592.0000\n",
            "Epoch 818/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2457001787392.0000\n",
            "Epoch 819/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456804917248.0000\n",
            "Epoch 820/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456783421440.0000\n",
            "Epoch 821/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456799674368.0000\n",
            "Epoch 822/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456788402176.0000\n",
            "Epoch 823/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456584454144.0000\n",
            "Epoch 824/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456826937344.0000\n",
            "Epoch 825/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456734400512.0000\n",
            "Epoch 826/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456783421440.0000\n",
            "Epoch 827/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456957222912.0000\n",
            "Epoch 828/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456729157632.0000\n",
            "Epoch 829/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456793382912.0000\n",
            "Epoch 830/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456567676928.0000\n",
            "Epoch 831/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456829034496.0000\n",
            "Epoch 832/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456761401344.0000\n",
            "Epoch 833/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456570036224.0000\n",
            "Epoch 834/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456908464128.0000\n",
            "Epoch 835/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456599658496.0000\n",
            "Epoch 836/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456565579776.0000\n",
            "Epoch 837/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456686690304.0000\n",
            "Epoch 838/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456582094848.0000\n",
            "Epoch 839/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456716312576.0000\n",
            "Epoch 840/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456509743104.0000\n",
            "Epoch 841/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456405147648.0000\n",
            "Epoch 842/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456662835200.0000\n",
            "Epoch 843/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456556404736.0000\n",
            "Epoch 844/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456511053824.0000\n",
            "Epoch 845/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456420876288.0000\n",
            "Epoch 846/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456440799232.0000\n",
            "Epoch 847/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456610406400.0000\n",
            "Epoch 848/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456500305920.0000\n",
            "Epoch 849/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456387584000.0000\n",
            "Epoch 850/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456415109120.0000\n",
            "Epoch 851/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456382078976.0000\n",
            "Epoch 852/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456570036224.0000\n",
            "Epoch 853/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456378408960.0000\n",
            "Epoch 854/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456538578944.0000\n",
            "Epoch 855/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456427954176.0000\n",
            "Epoch 856/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456656805888.0000\n",
            "Epoch 857/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456313921536.0000\n",
            "Epoch 858/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456237899776.0000\n",
            "Epoch 859/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456278007808.0000\n",
            "Epoch 860/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456481169408.0000\n",
            "Epoch 861/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456302125056.0000\n",
            "Epoch 862/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456484315136.0000\n",
            "Epoch 863/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456235802624.0000\n",
            "Epoch 864/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456643436544.0000\n",
            "Epoch 865/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456192811008.0000\n",
            "Epoch 866/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456229773312.0000\n",
            "Epoch 867/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456398856192.0000\n",
            "Epoch 868/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456348524544.0000\n",
            "Epoch 869/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456229249024.0000\n",
            "Epoch 870/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456223219712.0000\n",
            "Epoch 871/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456241569792.0000\n",
            "Epoch 872/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456204869632.0000\n",
            "Epoch 873/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456143265792.0000\n",
            "Epoch 874/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456417730560.0000\n",
            "Epoch 875/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456104206336.0000\n",
            "Epoch 876/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456211947520.0000\n",
            "Epoch 877/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456024514560.0000\n",
            "Epoch 878/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456468848640.0000\n",
            "Epoch 879/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456019795968.0000\n",
            "Epoch 880/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456046272512.0000\n",
            "Epoch 881/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456113381376.0000\n",
            "Epoch 882/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456002232320.0000\n",
            "Epoch 883/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456172101632.0000\n",
            "Epoch 884/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456077991936.0000\n",
            "Epoch 885/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456116002816.0000\n",
            "Epoch 886/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456025825280.0000\n",
            "Epoch 887/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456164237312.0000\n",
            "Epoch 888/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456006426624.0000\n",
            "Epoch 889/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456040767488.0000\n",
            "Epoch 890/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456039194624.0000\n",
            "Epoch 891/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456077467648.0000\n",
            "Epoch 892/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456000135168.0000\n",
            "Epoch 893/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456011407360.0000\n",
            "Epoch 894/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456016388096.0000\n",
            "Epoch 895/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456241569792.0000\n",
            "Epoch 896/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455899209728.0000\n",
            "Epoch 897/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456029757440.0000\n",
            "Epoch 898/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2456021630976.0000\n",
            "Epoch 899/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455935385600.0000\n",
            "Epoch 900/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455893966848.0000\n",
            "Epoch 901/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2456013766656.0000\n",
            "Epoch 902/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455898161152.0000\n",
            "Epoch 903/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455843110912.0000\n",
            "Epoch 904/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455925161984.0000\n",
            "Epoch 905/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455803002880.0000\n",
            "Epoch 906/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455728029696.0000\n",
            "Epoch 907/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455900782592.0000\n",
            "Epoch 908/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455902355456.0000\n",
            "Epoch 909/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455896326144.0000\n",
            "Epoch 910/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455756603392.0000\n",
            "Epoch 911/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455746117632.0000\n",
            "Epoch 912/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455710728192.0000\n",
            "Epoch 913/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455899471872.0000\n",
            "Epoch 914/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455828430848.0000\n",
            "Epoch 915/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455750311936.0000\n",
            "Epoch 916/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455732748288.0000\n",
            "Epoch 917/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455694737408.0000\n",
            "Epoch 918/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455994630144.0000\n",
            "Epoch 919/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455586996224.0000\n",
            "Epoch 920/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455692378112.0000\n",
            "Epoch 921/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455684251648.0000\n",
            "Epoch 922/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455617404928.0000\n",
            "Epoch 923/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455730126848.0000\n",
            "Epoch 924/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455804313600.0000\n",
            "Epoch 925/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455585947648.0000\n",
            "Epoch 926/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455655415808.0000\n",
            "Epoch 927/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455684251648.0000\n",
            "Epoch 928/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455717543936.0000\n",
            "Epoch 929/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455462477824.0000\n",
            "Epoch 930/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455703650304.0000\n",
            "Epoch 931/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455589355520.0000\n",
            "Epoch 932/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455763156992.0000\n",
            "Epoch 933/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455505469440.0000\n",
            "Epoch 934/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455703126016.0000\n",
            "Epoch 935/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455440719872.0000\n",
            "Epoch 936/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455596957696.0000\n",
            "Epoch 937/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455472177152.0000\n",
            "Epoch 938/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455595909120.0000\n",
            "Epoch 939/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455444914176.0000\n",
            "Epoch 940/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455433641984.0000\n",
            "Epoch 941/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455466672128.0000\n",
            "Epoch 942/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455708631040.0000\n",
            "Epoch 943/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455287365632.0000\n",
            "Epoch 944/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455502323712.0000\n",
            "Epoch 945/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455361290240.0000\n",
            "Epoch 946/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2455424991232.0000\n",
            "Epoch 947/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455479517184.0000\n",
            "Epoch 948/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455290249216.0000\n",
            "Epoch 949/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455469555712.0000\n",
            "Epoch 950/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455630774272.0000\n",
            "Epoch 951/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455381475328.0000\n",
            "Epoch 952/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455170973696.0000\n",
            "Epoch 953/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455312269312.0000\n",
            "Epoch 954/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455470604288.0000\n",
            "Epoch 955/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455312793600.0000\n",
            "Epoch 956/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455287103488.0000\n",
            "Epoch 957/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455283957760.0000\n",
            "Epoch 958/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455280549888.0000\n",
            "Epoch 959/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455243849728.0000\n",
            "Epoch 960/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2455519625216.0000\n",
            "Epoch 961/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455259054080.0000\n",
            "Epoch 962/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455412670464.0000\n",
            "Epoch 963/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455148691456.0000\n",
            "Epoch 964/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455184343040.0000\n",
            "Epoch 965/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455274258432.0000\n",
            "Epoch 966/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455216062464.0000\n",
            "Epoch 967/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455297851392.0000\n",
            "Epoch 968/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455210295296.0000\n",
            "Epoch 969/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455110680576.0000\n",
            "Epoch 970/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455124836352.0000\n",
            "Epoch 971/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455187488768.0000\n",
            "Epoch 972/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455290773504.0000\n",
            "Epoch 973/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455288938496.0000\n",
            "Epoch 974/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455038066688.0000\n",
            "Epoch 975/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455218159616.0000\n",
            "Epoch 976/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455328260096.0000\n",
            "Epoch 977/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454967812096.0000\n",
            "Epoch 978/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455072407552.0000\n",
            "Epoch 979/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455229169664.0000\n",
            "Epoch 980/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454970695680.0000\n",
            "Epoch 981/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455234412544.0000\n",
            "Epoch 982/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455157080064.0000\n",
            "Epoch 983/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455118544896.0000\n",
            "Epoch 984/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455049338880.0000\n",
            "Epoch 985/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455184080896.0000\n",
            "Epoch 986/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455224713216.0000\n",
            "Epoch 987/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454980919296.0000\n",
            "Epoch 988/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455079223296.0000\n",
            "Epoch 989/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454972268544.0000\n",
            "Epoch 990/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454984327168.0000\n",
            "Epoch 991/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2455015522304.0000\n",
            "Epoch 992/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455034134528.0000\n",
            "Epoch 993/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455021289472.0000\n",
            "Epoch 994/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454984589312.0000\n",
            "Epoch 995/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455057727488.0000\n",
            "Epoch 996/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455079223296.0000\n",
            "Epoch 997/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454942384128.0000\n",
            "Epoch 998/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454892838912.0000\n",
            "Epoch 999/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454819438592.0000\n",
            "Epoch 1000/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454940549120.0000\n",
            "Epoch 1001/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454832807936.0000\n",
            "Epoch 1002/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2455054319616.0000\n",
            "Epoch 1003/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454831759360.0000\n",
            "Epoch 1004/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454963879936.0000\n",
            "Epoch 1005/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454890217472.0000\n",
            "Epoch 1006/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454899392512.0000\n",
            "Epoch 1007/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454850109440.0000\n",
            "Epoch 1008/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454823632896.0000\n",
            "Epoch 1009/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454986948608.0000\n",
            "Epoch 1010/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454774349824.0000\n",
            "Epoch 1011/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454769631232.0000\n",
            "Epoch 1012/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454765961216.0000\n",
            "Epoch 1013/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454846177280.0000\n",
            "Epoch 1014/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454627549184.0000\n",
            "Epoch 1015/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454644850688.0000\n",
            "Epoch 1016/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454826254336.0000\n",
            "Epoch 1017/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454703570944.0000\n",
            "Epoch 1018/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454714843136.0000\n",
            "Epoch 1019/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454705405952.0000\n",
            "Epoch 1020/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454716678144.0000\n",
            "Epoch 1021/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454651142144.0000\n",
            "Epoch 1022/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454655598592.0000\n",
            "Epoch 1023/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454668705792.0000\n",
            "Epoch 1024/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454733193216.0000\n",
            "Epoch 1025/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454589538304.0000\n",
            "Epoch 1026/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454755213312.0000\n",
            "Epoch 1027/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454727426048.0000\n",
            "Epoch 1028/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454528983040.0000\n",
            "Epoch 1029/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454757310464.0000\n",
            "Epoch 1030/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454667919360.0000\n",
            "Epoch 1031/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454772252672.0000\n",
            "Epoch 1032/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454614966272.0000\n",
            "Epoch 1033/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454669230080.0000\n",
            "Epoch 1034/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454629908480.0000\n",
            "Epoch 1035/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454639607808.0000\n",
            "Epoch 1036/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454423863296.0000\n",
            "Epoch 1037/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454461874176.0000\n",
            "Epoch 1038/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454410756096.0000\n",
            "Epoch 1039/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454478127104.0000\n",
            "Epoch 1040/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454630694912.0000\n",
            "Epoch 1041/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454633578496.0000\n",
            "Epoch 1042/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454425698304.0000\n",
            "Epoch 1043/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454510632960.0000\n",
            "Epoch 1044/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454511943680.0000\n",
            "Epoch 1045/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454574596096.0000\n",
            "Epoch 1046/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454436184064.0000\n",
            "Epoch 1047/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454392143872.0000\n",
            "Epoch 1048/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454310354944.0000\n",
            "Epoch 1049/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454590849024.0000\n",
            "Epoch 1050/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454366715904.0000\n",
            "Epoch 1051/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454654812160.0000\n",
            "Epoch 1052/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454543400960.0000\n",
            "Epoch 1053/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454333423616.0000\n",
            "Epoch 1054/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454241935360.0000\n",
            "Epoch 1055/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454485204992.0000\n",
            "Epoch 1056/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454301704192.0000\n",
            "Epoch 1057/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454191603712.0000\n",
            "Epoch 1058/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454392930304.0000\n",
            "Epoch 1059/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454579052544.0000\n",
            "Epoch 1060/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454346530816.0000\n",
            "Epoch 1061/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454388211712.0000\n",
            "Epoch 1062/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454355181568.0000\n",
            "Epoch 1063/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454366191616.0000\n",
            "Epoch 1064/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454237478912.0000\n",
            "Epoch 1065/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454401843200.0000\n",
            "Epoch 1066/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454187409408.0000\n",
            "Epoch 1067/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454382968832.0000\n",
            "Epoch 1068/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454457679872.0000\n",
            "Epoch 1069/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454160670720.0000\n",
            "Epoch 1070/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2454170107904.0000\n",
            "Epoch 1071/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454282305536.0000\n",
            "Epoch 1072/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454288072704.0000\n",
            "Epoch 1073/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454352297984.0000\n",
            "Epoch 1074/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454188720128.0000\n",
            "Epoch 1075/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454158049280.0000\n",
            "Epoch 1076/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454323986432.0000\n",
            "Epoch 1077/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454103785472.0000\n",
            "Epoch 1078/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2454184263680.0000\n",
            "Epoch 1079/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454053453824.0000\n",
            "Epoch 1080/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2454323724288.0000\n",
            "Epoch 1081/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454004432896.0000\n",
            "Epoch 1082/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454149398528.0000\n",
            "Epoch 1083/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454115581952.0000\n",
            "Epoch 1084/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454212050944.0000\n",
            "Epoch 1085/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454092775424.0000\n",
            "Epoch 1086/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454111387648.0000\n",
            "Epoch 1087/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454182690816.0000\n",
            "Epoch 1088/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454016229376.0000\n",
            "Epoch 1089/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454124494848.0000\n",
            "Epoch 1090/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454145466368.0000\n",
            "Epoch 1091/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2454110339072.0000\n",
            "Epoch 1092/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453910061056.0000\n",
            "Epoch 1093/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453950169088.0000\n",
            "Epoch 1094/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454190555136.0000\n",
            "Epoch 1095/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453898264576.0000\n",
            "Epoch 1096/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453958819840.0000\n",
            "Epoch 1097/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453988179968.0000\n",
            "Epoch 1098/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454030647296.0000\n",
            "Epoch 1099/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2454021734400.0000\n",
            "Epoch 1100/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453880176640.0000\n",
            "Epoch 1101/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454246391808.0000\n",
            "Epoch 1102/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453939945472.0000\n",
            "Epoch 1103/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453950955520.0000\n",
            "Epoch 1104/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454128427008.0000\n",
            "Epoch 1105/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2453883060224.0000\n",
            "Epoch 1106/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453889613824.0000\n",
            "Epoch 1107/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453869953024.0000\n",
            "Epoch 1108/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454027239424.0000\n",
            "Epoch 1109/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453955149824.0000\n",
            "Epoch 1110/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453983199232.0000\n",
            "Epoch 1111/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454003908608.0000\n",
            "Epoch 1112/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453932605440.0000\n",
            "Epoch 1113/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453774270464.0000\n",
            "Epoch 1114/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453894332416.0000\n",
            "Epoch 1115/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453857370112.0000\n",
            "Epoch 1116/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453862350848.0000\n",
            "Epoch 1117/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453917138944.0000\n",
            "Epoch 1118/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453919760384.0000\n",
            "Epoch 1119/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2453737308160.0000\n",
            "Epoch 1120/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2453784231936.0000\n",
            "Epoch 1121/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453913731072.0000\n",
            "Epoch 1122/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2454069444608.0000\n",
            "Epoch 1123/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453874933760.0000\n",
            "Epoch 1124/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453658664960.0000\n",
            "Epoch 1125/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453795766272.0000\n",
            "Epoch 1126/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453769551872.0000\n",
            "Epoch 1127/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2453777416192.0000\n",
            "Epoch 1128/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2453870215168.0000\n",
            "Epoch 1129/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2454044803072.0000\n",
            "Epoch 1130/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2453752250368.0000\n",
            "Epoch 1131/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2453700608000.0000\n",
            "Epoch 1132/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453753561088.0000\n",
            "Epoch 1133/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453577662464.0000\n",
            "Epoch 1134/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453957771264.0000\n",
            "Epoch 1135/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2453786853376.0000\n",
            "Epoch 1136/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2453744648192.0000\n",
            "Epoch 1137/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453620129792.0000\n",
            "Epoch 1138/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453744910336.0000\n",
            "Epoch 1139/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453855797248.0000\n",
            "Epoch 1140/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453727870976.0000\n",
            "Epoch 1141/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453605449728.0000\n",
            "Epoch 1142/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453565865984.0000\n",
            "Epoch 1143/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453728395264.0000\n",
            "Epoch 1144/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2453800222720.0000\n",
            "Epoch 1145/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453728395264.0000\n",
            "Epoch 1146/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453598633984.0000\n",
            "Epoch 1147/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453603352576.0000\n",
            "Epoch 1148/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453451571200.0000\n",
            "Epoch 1149/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453678587904.0000\n",
            "Epoch 1150/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453704802304.0000\n",
            "Epoch 1151/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453695889408.0000\n",
            "Epoch 1152/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453483290624.0000\n",
            "Epoch 1153/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453655257088.0000\n",
            "Epoch 1154/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453504524288.0000\n",
            "Epoch 1155/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453580021760.0000\n",
            "Epoch 1156/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453415919616.0000\n",
            "Epoch 1157/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453506621440.0000\n",
            "Epoch 1158/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453640052736.0000\n",
            "Epoch 1159/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453480669184.0000\n",
            "Epoch 1160/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453443706880.0000\n",
            "Epoch 1161/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453572681728.0000\n",
            "Epoch 1162/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453581856768.0000\n",
            "Epoch 1163/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453490630656.0000\n",
            "Epoch 1164/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453703753728.0000\n",
            "Epoch 1165/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453523398656.0000\n",
            "Epoch 1166/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453356937216.0000\n",
            "Epoch 1167/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453451571200.0000\n",
            "Epoch 1168/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453514223616.0000\n",
            "Epoch 1169/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453361655808.0000\n",
            "Epoch 1170/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453371092992.0000\n",
            "Epoch 1171/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453598109696.0000\n",
            "Epoch 1172/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453265711104.0000\n",
            "Epoch 1173/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453521825792.0000\n",
            "Epoch 1174/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453441085440.0000\n",
            "Epoch 1175/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453260206080.0000\n",
            "Epoch 1176/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453470183424.0000\n",
            "Epoch 1177/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453321023488.0000\n",
            "Epoch 1178/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453365587968.0000\n",
            "Epoch 1179/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453521825792.0000\n",
            "Epoch 1180/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453377122304.0000\n",
            "Epoch 1181/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453376335872.0000\n",
            "Epoch 1182/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453324169216.0000\n",
            "Epoch 1183/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453256536064.0000\n",
            "Epoch 1184/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453413822464.0000\n",
            "Epoch 1185/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453390229504.0000\n",
            "Epoch 1186/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453313945600.0000\n",
            "Epoch 1187/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453438726144.0000\n",
            "Epoch 1188/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453414084608.0000\n",
            "Epoch 1189/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453338849280.0000\n",
            "Epoch 1190/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453172912128.0000\n",
            "Epoch 1191/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453321023488.0000\n",
            "Epoch 1192/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453252079616.0000\n",
            "Epoch 1193/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453200699392.0000\n",
            "Epoch 1194/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453204631552.0000\n",
            "Epoch 1195/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453197815808.0000\n",
            "Epoch 1196/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453345665024.0000\n",
            "Epoch 1197/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453089550336.0000\n",
            "Epoch 1198/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453325217792.0000\n",
            "Epoch 1199/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453092958208.0000\n",
            "Epoch 1200/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453314994176.0000\n",
            "Epoch 1201/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453059141632.0000\n",
            "Epoch 1202/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453098463232.0000\n",
            "Epoch 1203/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453093482496.0000\n",
            "Epoch 1204/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453169766400.0000\n",
            "Epoch 1205/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453163737088.0000\n",
            "Epoch 1206/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453008023552.0000\n",
            "Epoch 1207/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453155086336.0000\n",
            "Epoch 1208/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453233467392.0000\n",
            "Epoch 1209/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452954808320.0000\n",
            "Epoch 1210/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2453098987520.0000\n",
            "Epoch 1211/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453132017664.0000\n",
            "Epoch 1212/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453052063744.0000\n",
            "Epoch 1213/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453291139072.0000\n",
            "Epoch 1214/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452911816704.0000\n",
            "Epoch 1215/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452984954880.0000\n",
            "Epoch 1216/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453175533568.0000\n",
            "Epoch 1217/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453034762240.0000\n",
            "Epoch 1218/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452991508480.0000\n",
            "Epoch 1219/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452897660928.0000\n",
            "Epoch 1220/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2453081161728.0000\n",
            "Epoch 1221/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453021392896.0000\n",
            "Epoch 1222/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452986789888.0000\n",
            "Epoch 1223/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453052325888.0000\n",
            "Epoch 1224/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453017198592.0000\n",
            "Epoch 1225/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452947468288.0000\n",
            "Epoch 1226/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452874330112.0000\n",
            "Epoch 1227/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452952186880.0000\n",
            "Epoch 1228/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452879310848.0000\n",
            "Epoch 1229/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452967129088.0000\n",
            "Epoch 1230/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452795949056.0000\n",
            "Epoch 1231/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452916273152.0000\n",
            "Epoch 1232/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2453126250496.0000\n",
            "Epoch 1233/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452919943168.0000\n",
            "Epoch 1234/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452856242176.0000\n",
            "Epoch 1235/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452864630784.0000\n",
            "Epoch 1236/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452758462464.0000\n",
            "Epoch 1237/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2453103706112.0000\n",
            "Epoch 1238/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452777336832.0000\n",
            "Epoch 1239/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452865679360.0000\n",
            "Epoch 1240/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452861485056.0000\n",
            "Epoch 1241/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452970012672.0000\n",
            "Epoch 1242/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452929642496.0000\n",
            "Epoch 1243/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452939603968.0000\n",
            "Epoch 1244/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452757413888.0000\n",
            "Epoch 1245/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452759248896.0000\n",
            "Epoch 1246/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452995702784.0000\n",
            "Epoch 1247/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452742733824.0000\n",
            "Epoch 1248/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452773142528.0000\n",
            "Epoch 1249/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452788346880.0000\n",
            "Epoch 1250/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452828717056.0000\n",
            "Epoch 1251/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452825047040.0000\n",
            "Epoch 1252/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452735393792.0000\n",
            "Epoch 1253/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452591476736.0000\n",
            "Epoch 1254/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452943011840.0000\n",
            "Epoch 1255/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452670906368.0000\n",
            "Epoch 1256/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452944060416.0000\n",
            "Epoch 1257/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452659634176.0000\n",
            "Epoch 1258/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452898971648.0000\n",
            "Epoch 1259/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452688732160.0000\n",
            "Epoch 1260/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452538785792.0000\n",
            "Epoch 1261/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452890845184.0000\n",
            "Epoch 1262/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452659634176.0000\n",
            "Epoch 1263/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452872232960.0000\n",
            "Epoch 1264/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452610088960.0000\n",
            "Epoch 1265/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452727791616.0000\n",
            "Epoch 1266/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452751908864.0000\n",
            "Epoch 1267/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452775763968.0000\n",
            "Epoch 1268/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452632633344.0000\n",
            "Epoch 1269/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452575223808.0000\n",
            "Epoch 1270/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452562378752.0000\n",
            "Epoch 1271/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452580466688.0000\n",
            "Epoch 1272/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452615593984.0000\n",
            "Epoch 1273/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452764229632.0000\n",
            "Epoch 1274/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452543504384.0000\n",
            "Epoch 1275/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452638138368.0000\n",
            "Epoch 1276/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452508639232.0000\n",
            "Epoch 1277/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452590428160.0000\n",
            "Epoch 1278/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452553203712.0000\n",
            "Epoch 1279/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452498415616.0000\n",
            "Epoch 1280/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452662255616.0000\n",
            "Epoch 1281/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452461715456.0000\n",
            "Epoch 1282/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452582301696.0000\n",
            "Epoch 1283/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452455686144.0000\n",
            "Epoch 1284/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452738539520.0000\n",
            "Epoch 1285/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452547960832.0000\n",
            "Epoch 1286/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452720713728.0000\n",
            "Epoch 1287/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452366032896.0000\n",
            "Epoch 1288/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452395130880.0000\n",
            "Epoch 1289/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452547698688.0000\n",
            "Epoch 1290/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452477706240.0000\n",
            "Epoch 1291/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452508901376.0000\n",
            "Epoch 1292/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452594622464.0000\n",
            "Epoch 1293/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452621885440.0000\n",
            "Epoch 1294/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452378091520.0000\n",
            "Epoch 1295/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452524105728.0000\n",
            "Epoch 1296/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452549533696.0000\n",
            "Epoch 1297/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452497367040.0000\n",
            "Epoch 1298/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452420820992.0000\n",
            "Epoch 1299/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452587806720.0000\n",
            "Epoch 1300/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452427112448.0000\n",
            "Epoch 1301/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452489502720.0000\n",
            "Epoch 1302/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452416102400.0000\n",
            "Epoch 1303/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452496842752.0000\n",
            "Epoch 1304/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452332740608.0000\n",
            "Epoch 1305/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452471414784.0000\n",
            "Epoch 1306/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452210581504.0000\n",
            "Epoch 1307/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452508114944.0000\n",
            "Epoch 1308/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452484521984.0000\n",
            "Epoch 1309/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452332216320.0000\n",
            "Epoch 1310/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452241252352.0000\n",
            "Epoch 1311/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452315439104.0000\n",
            "Epoch 1312/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452426063872.0000\n",
            "Epoch 1313/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452355809280.0000\n",
            "Epoch 1314/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452256194560.0000\n",
            "Epoch 1315/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452308361216.0000\n",
            "Epoch 1316/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452256718848.0000\n",
            "Epoch 1317/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452492386304.0000\n",
            "Epoch 1318/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452221853696.0000\n",
            "Epoch 1319/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452464336896.0000\n",
            "Epoch 1320/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452344537088.0000\n",
            "Epoch 1321/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452179124224.0000\n",
            "Epoch 1322/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452302331904.0000\n",
            "Epoch 1323/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452292370432.0000\n",
            "Epoch 1324/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452264583168.0000\n",
            "Epoch 1325/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452406140928.0000\n",
            "Epoch 1326/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452247281664.0000\n",
            "Epoch 1327/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452334051328.0000\n",
            "Epoch 1328/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452289748992.0000\n",
            "Epoch 1329/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452173619200.0000\n",
            "Epoch 1330/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452227358720.0000\n",
            "Epoch 1331/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452310196224.0000\n",
            "Epoch 1332/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452217397248.0000\n",
            "Epoch 1333/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452211105792.0000\n",
            "Epoch 1334/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452449132544.0000\n",
            "Epoch 1335/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452060372992.0000\n",
            "Epoch 1336/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452221853696.0000\n",
            "Epoch 1337/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452162609152.0000\n",
            "Epoch 1338/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452238630912.0000\n",
            "Epoch 1339/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452088946688.0000\n",
            "Epoch 1340/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452238630912.0000\n",
            "Epoch 1341/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452099432448.0000\n",
            "Epoch 1342/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452112539648.0000\n",
            "Epoch 1343/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452240728064.0000\n",
            "Epoch 1344/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452211367936.0000\n",
            "Epoch 1345/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452159201280.0000\n",
            "Epoch 1346/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452148977664.0000\n",
            "Epoch 1347/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452029702144.0000\n",
            "Epoch 1348/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452058275840.0000\n",
            "Epoch 1349/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452213465088.0000\n",
            "Epoch 1350/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452135346176.0000\n",
            "Epoch 1351/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452160774144.0000\n",
            "Epoch 1352/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452078198784.0000\n",
            "Epoch 1353/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452094713856.0000\n",
            "Epoch 1354/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452051722240.0000\n",
            "Epoch 1355/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451973603328.0000\n",
            "Epoch 1356/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452080820224.0000\n",
            "Epoch 1357/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452235747328.0000\n",
            "Epoch 1358/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452091043840.0000\n",
            "Epoch 1359/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451948699648.0000\n",
            "Epoch 1360/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452051197952.0000\n",
            "Epoch 1361/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452174929920.0000\n",
            "Epoch 1362/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451924320256.0000\n",
            "Epoch 1363/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452085800960.0000\n",
            "Epoch 1364/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451960758272.0000\n",
            "Epoch 1365/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452145569792.0000\n",
            "Epoch 1366/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451844628480.0000\n",
            "Epoch 1367/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451971506176.0000\n",
            "Epoch 1368/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451954728960.0000\n",
            "Epoch 1369/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452087898112.0000\n",
            "Epoch 1370/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451907280896.0000\n",
            "Epoch 1371/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452160774144.0000\n",
            "Epoch 1372/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452075053056.0000\n",
            "Epoch 1373/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452018692096.0000\n",
            "Epoch 1374/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451909640192.0000\n",
            "Epoch 1375/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451873202176.0000\n",
            "Epoch 1376/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451941883904.0000\n",
            "Epoch 1377/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2452222640128.0000\n",
            "Epoch 1378/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451834667008.0000\n",
            "Epoch 1379/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451976224768.0000\n",
            "Epoch 1380/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452029440000.0000\n",
            "Epoch 1381/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451779092480.0000\n",
            "Epoch 1382/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451831783424.0000\n",
            "Epoch 1383/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451952107520.0000\n",
            "Epoch 1384/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451721682944.0000\n",
            "Epoch 1385/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2452000866304.0000\n",
            "Epoch 1386/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451832569856.0000\n",
            "Epoch 1387/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451982516224.0000\n",
            "Epoch 1388/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451770703872.0000\n",
            "Epoch 1389/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451923795968.0000\n",
            "Epoch 1390/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451762315264.0000\n",
            "Epoch 1391/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451883950080.0000\n",
            "Epoch 1392/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451748159488.0000\n",
            "Epoch 1393/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451842793472.0000\n",
            "Epoch 1394/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451838599168.0000\n",
            "Epoch 1395/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451994836992.0000\n",
            "Epoch 1396/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451872153600.0000\n",
            "Epoch 1397/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451637272576.0000\n",
            "Epoch 1398/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451810811904.0000\n",
            "Epoch 1399/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451744227328.0000\n",
            "Epoch 1400/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451697565696.0000\n",
            "Epoch 1401/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451871105024.0000\n",
            "Epoch 1402/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451866124288.0000\n",
            "Epoch 1403/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451761790976.0000\n",
            "Epoch 1404/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451813957632.0000\n",
            "Epoch 1405/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451885522944.0000\n",
            "Epoch 1406/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451887620096.0000\n",
            "Epoch 1407/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451767820288.0000\n",
            "Epoch 1408/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451671351296.0000\n",
            "Epoch 1409/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451728760832.0000\n",
            "Epoch 1410/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451801112576.0000\n",
            "Epoch 1411/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451721420800.0000\n",
            "Epoch 1412/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451855114240.0000\n",
            "Epoch 1413/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451726401536.0000\n",
            "Epoch 1414/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451646709760.0000\n",
            "Epoch 1415/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451617873920.0000\n",
            "Epoch 1416/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451876347904.0000\n",
            "Epoch 1417/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451671351296.0000\n",
            "Epoch 1418/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451472121856.0000\n",
            "Epoch 1419/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451709886464.0000\n",
            "Epoch 1420/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451683147776.0000\n",
            "Epoch 1421/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451742654464.0000\n",
            "Epoch 1422/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451613417472.0000\n",
            "Epoch 1423/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451534774272.0000\n",
            "Epoch 1424/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451811860480.0000\n",
            "Epoch 1425/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451628359680.0000\n",
            "Epoch 1426/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451710148608.0000\n",
            "Epoch 1427/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451716702208.0000\n",
            "Epoch 1428/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451587203072.0000\n",
            "Epoch 1429/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451490734080.0000\n",
            "Epoch 1430/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451581435904.0000\n",
            "Epoch 1431/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451626262528.0000\n",
            "Epoch 1432/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451692060672.0000\n",
            "Epoch 1433/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451763625984.0000\n",
            "Epoch 1434/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451581698048.0000\n",
            "Epoch 1435/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451561775104.0000\n",
            "Epoch 1436/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451436732416.0000\n",
            "Epoch 1437/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451532677120.0000\n",
            "Epoch 1438/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451573309440.0000\n",
            "Epoch 1439/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451333447680.0000\n",
            "Epoch 1440/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451601883136.0000\n",
            "Epoch 1441/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451557056512.0000\n",
            "Epoch 1442/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451552337920.0000\n",
            "Epoch 1443/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451509608448.0000\n",
            "Epoch 1444/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451418644480.0000\n",
            "Epoch 1445/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451550502912.0000\n",
            "Epoch 1446/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451429130240.0000\n",
            "Epoch 1447/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451392692224.0000\n",
            "Epoch 1448/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451558105088.0000\n",
            "Epoch 1449/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451536347136.0000\n",
            "Epoch 1450/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451531628544.0000\n",
            "Epoch 1451/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451342098432.0000\n",
            "Epoch 1452/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451673448448.0000\n",
            "Epoch 1453/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451322175488.0000\n",
            "Epoch 1454/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451325583360.0000\n",
            "Epoch 1455/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451329777664.0000\n",
            "Epoch 1456/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451570163712.0000\n",
            "Epoch 1457/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451314835456.0000\n",
            "Epoch 1458/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451405537280.0000\n",
            "Epoch 1459/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451319554048.0000\n",
            "Epoch 1460/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451325583360.0000\n",
            "Epoch 1461/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451427033088.0000\n",
            "Epoch 1462/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451339476992.0000\n",
            "Epoch 1463/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451429130240.0000\n",
            "Epoch 1464/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451247726592.0000\n",
            "Epoch 1465/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2451530842112.0000\n",
            "Epoch 1466/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451375915008.0000\n",
            "Epoch 1467/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451582746624.0000\n",
            "Epoch 1468/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451218366464.0000\n",
            "Epoch 1469/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451370147840.0000\n",
            "Epoch 1470/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451331350528.0000\n",
            "Epoch 1471/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451310379008.0000\n",
            "Epoch 1472/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451421528064.0000\n",
            "Epoch 1473/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451287572480.0000\n",
            "Epoch 1474/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451434110976.0000\n",
            "Epoch 1475/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451515637760.0000\n",
            "Epoch 1476/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451295436800.0000\n",
            "Epoch 1477/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451335544832.0000\n",
            "Epoch 1478/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451190054912.0000\n",
            "Epoch 1479/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451430178816.0000\n",
            "Epoch 1480/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451266338816.0000\n",
            "Epoch 1481/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451286261760.0000\n",
            "Epoch 1482/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451283116032.0000\n",
            "Epoch 1483/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2451289145344.0000\n",
            "Epoch 1484/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451379585024.0000\n",
            "Epoch 1485/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451144179712.0000\n",
            "Epoch 1486/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451179831296.0000\n",
            "Epoch 1487/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451277611008.0000\n",
            "Epoch 1488/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451498598400.0000\n",
            "Epoch 1489/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451216007168.0000\n",
            "Epoch 1490/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451106955264.0000\n",
            "Epoch 1491/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451059769344.0000\n",
            "Epoch 1492/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451337904128.0000\n",
            "Epoch 1493/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451221250048.0000\n",
            "Epoch 1494/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451211026432.0000\n",
            "Epoch 1495/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451183239168.0000\n",
            "Epoch 1496/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451224395776.0000\n",
            "Epoch 1497/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451060031488.0000\n",
            "Epoch 1498/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2451408420864.0000\n",
            "Epoch 1499/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451164889088.0000\n",
            "Epoch 1500/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2451226492928.0000\n",
            "Epoch 1501/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451042467840.0000\n",
            "Epoch 1502/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451339476992.0000\n",
            "Epoch 1503/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451101188096.0000\n",
            "Epoch 1504/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451223609344.0000\n",
            "Epoch 1505/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451133956096.0000\n",
            "Epoch 1506/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451023331328.0000\n",
            "Epoch 1507/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451139985408.0000\n",
            "Epoch 1508/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451133693952.0000\n",
            "Epoch 1509/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450950979584.0000\n",
            "Epoch 1510/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451187433472.0000\n",
            "Epoch 1511/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451035914240.0000\n",
            "Epoch 1512/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451052167168.0000\n",
            "Epoch 1513/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451202899968.0000\n",
            "Epoch 1514/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451131072512.0000\n",
            "Epoch 1515/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451105382400.0000\n",
            "Epoch 1516/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450957271040.0000\n",
            "Epoch 1517/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451075497984.0000\n",
            "Epoch 1518/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451094110208.0000\n",
            "Epoch 1519/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451158597632.0000\n",
            "Epoch 1520/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451125829632.0000\n",
            "Epoch 1521/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450993184768.0000\n",
            "Epoch 1522/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450995281920.0000\n",
            "Epoch 1523/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450987679744.0000\n",
            "Epoch 1524/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451009699840.0000\n",
            "Epoch 1525/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451018350592.0000\n",
            "Epoch 1526/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450868142080.0000\n",
            "Epoch 1527/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451171704832.0000\n",
            "Epoch 1528/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450952290304.0000\n",
            "Epoch 1529/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450919522304.0000\n",
            "Epoch 1530/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451094372352.0000\n",
            "Epoch 1531/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451049545728.0000\n",
            "Epoch 1532/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451060293632.0000\n",
            "Epoch 1533/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450993184768.0000\n",
            "Epoch 1534/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450898550784.0000\n",
            "Epoch 1535/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450986369024.0000\n",
            "Epoch 1536/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450833801216.0000\n",
            "Epoch 1537/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451212599296.0000\n",
            "Epoch 1538/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450901434368.0000\n",
            "Epoch 1539/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450957008896.0000\n",
            "Epoch 1540/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450830393344.0000\n",
            "Epoch 1541/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451000524800.0000\n",
            "Epoch 1542/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450953338880.0000\n",
            "Epoch 1543/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450957533184.0000\n",
            "Epoch 1544/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2451000262656.0000\n",
            "Epoch 1545/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450885181440.0000\n",
            "Epoch 1546/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450985058304.0000\n",
            "Epoch 1547/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450798149632.0000\n",
            "Epoch 1548/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450770100224.0000\n",
            "Epoch 1549/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2451185860608.0000\n",
            "Epoch 1550/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2450845335552.0000\n",
            "Epoch 1551/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2450858442752.0000\n",
            "Epoch 1552/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450934726656.0000\n",
            "Epoch 1553/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450927648768.0000\n",
            "Epoch 1554/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450980339712.0000\n",
            "Epoch 1555/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450989514752.0000\n",
            "Epoch 1556/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2450682806272.0000\n",
            "Epoch 1557/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450826723328.0000\n",
            "Epoch 1558/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450867879936.0000\n",
            "Epoch 1559/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450793955328.0000\n",
            "Epoch 1560/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2450861064192.0000\n",
            "Epoch 1561/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450851889152.0000\n",
            "Epoch 1562/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450810470400.0000\n",
            "Epoch 1563/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450790285312.0000\n",
            "Epoch 1564/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450725273600.0000\n",
            "Epoch 1565/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450729467904.0000\n",
            "Epoch 1566/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450808373248.0000\n",
            "Epoch 1567/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450862374912.0000\n",
            "Epoch 1568/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450670223360.0000\n",
            "Epoch 1569/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450900385792.0000\n",
            "Epoch 1570/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450691719168.0000\n",
            "Epoch 1571/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450899075072.0000\n",
            "Epoch 1572/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450795003904.0000\n",
            "Epoch 1573/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450786877440.0000\n",
            "Epoch 1574/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450839568384.0000\n",
            "Epoch 1575/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450606260224.0000\n",
            "Epoch 1576/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450704302080.0000\n",
            "Epoch 1577/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450768527360.0000\n",
            "Epoch 1578/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2451037749248.0000\n",
            "Epoch 1579/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450638766080.0000\n",
            "Epoch 1580/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450667339776.0000\n",
            "Epoch 1581/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450853724160.0000\n",
            "Epoch 1582/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450624610304.0000\n",
            "Epoch 1583/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450624872448.0000\n",
            "Epoch 1584/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450818072576.0000\n",
            "Epoch 1585/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450811256832.0000\n",
            "Epoch 1586/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450566414336.0000\n",
            "Epoch 1587/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450651086848.0000\n",
            "Epoch 1588/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450808111104.0000\n",
            "Epoch 1589/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450576113664.0000\n",
            "Epoch 1590/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450799198208.0000\n",
            "Epoch 1591/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450688573440.0000\n",
            "Epoch 1592/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450701942784.0000\n",
            "Epoch 1593/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450594463744.0000\n",
            "Epoch 1594/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450582405120.0000\n",
            "Epoch 1595/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450593415168.0000\n",
            "Epoch 1596/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450796314624.0000\n",
            "Epoch 1597/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450707709952.0000\n",
            "Epoch 1598/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450687787008.0000\n",
            "Epoch 1599/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450688311296.0000\n",
            "Epoch 1600/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450585550848.0000\n",
            "Epoch 1601/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450792120320.0000\n",
            "Epoch 1602/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450813878272.0000\n",
            "Epoch 1603/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450497732608.0000\n",
            "Epoch 1604/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450739167232.0000\n",
            "Epoch 1605/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450506383360.0000\n",
            "Epoch 1606/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450662359040.0000\n",
            "Epoch 1607/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450652135424.0000\n",
            "Epoch 1608/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450571395072.0000\n",
            "Epoch 1609/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450559336448.0000\n",
            "Epoch 1610/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450522112000.0000\n",
            "Epoch 1611/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450558287872.0000\n",
            "Epoch 1612/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450671796224.0000\n",
            "Epoch 1613/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450591842304.0000\n",
            "Epoch 1614/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450713477120.0000\n",
            "Epoch 1615/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450504286208.0000\n",
            "Epoch 1616/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450612289536.0000\n",
            "Epoch 1617/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450412273664.0000\n",
            "Epoch 1618/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450739167232.0000\n",
            "Epoch 1619/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450475450368.0000\n",
            "Epoch 1620/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450543083520.0000\n",
            "Epoch 1621/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450658689024.0000\n",
            "Epoch 1622/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450431672320.0000\n",
            "Epoch 1623/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450570084352.0000\n",
            "Epoch 1624/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450556715008.0000\n",
            "Epoch 1625/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450457624576.0000\n",
            "Epoch 1626/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450542821376.0000\n",
            "Epoch 1627/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450618580992.0000\n",
            "Epoch 1628/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450465751040.0000\n",
            "Epoch 1629/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450551734272.0000\n",
            "Epoch 1630/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450446090240.0000\n",
            "Epoch 1631/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450331271168.0000\n",
            "Epoch 1632/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450491179008.0000\n",
            "Epoch 1633/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450565890048.0000\n",
            "Epoch 1634/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450756993024.0000\n",
            "Epoch 1635/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450380029952.0000\n",
            "Epoch 1636/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450421972992.0000\n",
            "Epoch 1637/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450399166464.0000\n",
            "Epoch 1638/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450424856576.0000\n",
            "Epoch 1639/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450399428608.0000\n",
            "Epoch 1640/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450382127104.0000\n",
            "Epoch 1641/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450419875840.0000\n",
            "Epoch 1642/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450419351552.0000\n",
            "Epoch 1643/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450520801280.0000\n",
            "Epoch 1644/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450476236800.0000\n",
            "Epoch 1645/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450512674816.0000\n",
            "Epoch 1646/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450427215872.0000\n",
            "Epoch 1647/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450233229312.0000\n",
            "Epoch 1648/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450343854080.0000\n",
            "Epoch 1649/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450403885056.0000\n",
            "Epoch 1650/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450416467968.0000\n",
            "Epoch 1651/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450556715008.0000\n",
            "Epoch 1652/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2450263900160.0000\n",
            "Epoch 1653/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450434293760.0000\n",
            "Epoch 1654/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450360107008.0000\n",
            "Epoch 1655/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450256035840.0000\n",
            "Epoch 1656/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450318426112.0000\n",
            "Epoch 1657/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450279628800.0000\n",
            "Epoch 1658/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450373476352.0000\n",
            "Epoch 1659/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450520801280.0000\n",
            "Epoch 1660/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450269929472.0000\n",
            "Epoch 1661/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450410962944.0000\n",
            "Epoch 1662/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450340970496.0000\n",
            "Epoch 1663/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450313445376.0000\n",
            "Epoch 1664/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450464964608.0000\n",
            "Epoch 1665/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450328911872.0000\n",
            "Epoch 1666/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450312396800.0000\n",
            "Epoch 1667/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450258919424.0000\n",
            "Epoch 1668/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450443993088.0000\n",
            "Epoch 1669/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450211995648.0000\n",
            "Epoch 1670/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450265210880.0000\n",
            "Epoch 1671/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450370330624.0000\n",
            "Epoch 1672/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450510315520.0000\n",
            "Epoch 1673/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450220646400.0000\n",
            "Epoch 1674/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450268618752.0000\n",
            "Epoch 1675/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450168479744.0000\n",
            "Epoch 1676/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450377146368.0000\n",
            "Epoch 1677/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450294308864.0000\n",
            "Epoch 1678/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450169528320.0000\n",
            "Epoch 1679/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450286444544.0000\n",
            "Epoch 1680/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450194694144.0000\n",
            "Epoch 1681/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450191548416.0000\n",
            "Epoch 1682/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450347261952.0000\n",
            "Epoch 1683/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450140692480.0000\n",
            "Epoch 1684/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450386059264.0000\n",
            "Epoch 1685/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450149867520.0000\n",
            "Epoch 1686/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450248957952.0000\n",
            "Epoch 1687/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2450196529152.0000\n",
            "Epoch 1688/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450336514048.0000\n",
            "Epoch 1689/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450063360000.0000\n",
            "Epoch 1690/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450369544192.0000\n",
            "Epoch 1691/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2450125225984.0000\n",
            "Epoch 1692/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450202034176.0000\n",
            "Epoch 1693/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450300862464.0000\n",
            "Epoch 1694/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2450120507392.0000\n",
            "Epoch 1695/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450090360832.0000\n",
            "Epoch 1696/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2450225889280.0000\n",
            "Epoch 1697/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450301124608.0000\n",
            "Epoch 1698/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450073321472.0000\n",
            "Epoch 1699/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450319474688.0000\n",
            "Epoch 1700/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450301648896.0000\n",
            "Epoch 1701/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449988648960.0000\n",
            "Epoch 1702/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450261540864.0000\n",
            "Epoch 1703/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450100060160.0000\n",
            "Epoch 1704/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450129158144.0000\n",
            "Epoch 1705/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450075418624.0000\n",
            "Epoch 1706/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450220384256.0000\n",
            "Epoch 1707/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450104254464.0000\n",
            "Epoch 1708/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450177654784.0000\n",
            "Epoch 1709/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450085642240.0000\n",
            "Epoch 1710/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450214354944.0000\n",
            "Epoch 1711/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450146459648.0000\n",
            "Epoch 1712/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450008834048.0000\n",
            "Epoch 1713/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449982881792.0000\n",
            "Epoch 1714/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450144886784.0000\n",
            "Epoch 1715/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449955880960.0000\n",
            "Epoch 1716/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450078302208.0000\n",
            "Epoch 1717/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450138857472.0000\n",
            "Epoch 1718/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450109759488.0000\n",
            "Epoch 1719/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450075680768.0000\n",
            "Epoch 1720/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450064146432.0000\n",
            "Epoch 1721/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449987076096.0000\n",
            "Epoch 1722/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450062049280.0000\n",
            "Epoch 1723/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450134925312.0000\n",
            "Epoch 1724/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449889820672.0000\n",
            "Epoch 1725/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450000445440.0000\n",
            "Epoch 1726/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450033737728.0000\n",
            "Epoch 1727/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2450151702528.0000\n",
            "Epoch 1728/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449975279616.0000\n",
            "Epoch 1729/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450062311424.0000\n",
            "Epoch 1730/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450010669056.0000\n",
            "Epoch 1731/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449971347456.0000\n",
            "Epoch 1732/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450067816448.0000\n",
            "Epoch 1733/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449961385984.0000\n",
            "Epoch 1734/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449908170752.0000\n",
            "Epoch 1735/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450061787136.0000\n",
            "Epoch 1736/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449845780480.0000\n",
            "Epoch 1737/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450098225152.0000\n",
            "Epoch 1738/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450019057664.0000\n",
            "Epoch 1739/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449917607936.0000\n",
            "Epoch 1740/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450044485632.0000\n",
            "Epoch 1741/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449883267072.0000\n",
            "Epoch 1742/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449965580288.0000\n",
            "Epoch 1743/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2450090622976.0000\n",
            "Epoch 1744/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449786273792.0000\n",
            "Epoch 1745/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449854431232.0000\n",
            "Epoch 1746/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450065457152.0000\n",
            "Epoch 1747/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449847353344.0000\n",
            "Epoch 1748/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449843945472.0000\n",
            "Epoch 1749/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450085642240.0000\n",
            "Epoch 1750/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449881169920.0000\n",
            "Epoch 1751/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449861509120.0000\n",
            "Epoch 1752/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449981833216.0000\n",
            "Epoch 1753/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450210422784.0000\n",
            "Epoch 1754/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449787846656.0000\n",
            "Epoch 1755/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449912889344.0000\n",
            "Epoch 1756/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449882480640.0000\n",
            "Epoch 1757/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449864392704.0000\n",
            "Epoch 1758/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449963483136.0000\n",
            "Epoch 1759/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449773690880.0000\n",
            "Epoch 1760/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449918918656.0000\n",
            "Epoch 1761/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449871208448.0000\n",
            "Epoch 1762/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449957978112.0000\n",
            "Epoch 1763/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449897160704.0000\n",
            "Epoch 1764/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449701863424.0000\n",
            "Epoch 1765/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449931763712.0000\n",
            "Epoch 1766/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449933598720.0000\n",
            "Epoch 1767/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449853382656.0000\n",
            "Epoch 1768/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449822187520.0000\n",
            "Epoch 1769/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449911054336.0000\n",
            "Epoch 1770/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449699504128.0000\n",
            "Epoch 1771/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449921802240.0000\n",
            "Epoch 1772/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449919442944.0000\n",
            "Epoch 1773/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449650483200.0000\n",
            "Epoch 1774/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449834246144.0000\n",
            "Epoch 1775/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449583636480.0000\n",
            "Epoch 1776/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2450147770368.0000\n",
            "Epoch 1777/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449699241984.0000\n",
            "Epoch 1778/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449855479808.0000\n",
            "Epoch 1779/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449693736960.0000\n",
            "Epoch 1780/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449752457216.0000\n",
            "Epoch 1781/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449837391872.0000\n",
            "Epoch 1782/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449703436288.0000\n",
            "Epoch 1783/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449771855872.0000\n",
            "Epoch 1784/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449901092864.0000\n",
            "Epoch 1785/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449846566912.0000\n",
            "Epoch 1786/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449779982336.0000\n",
            "Epoch 1787/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449723097088.0000\n",
            "Epoch 1788/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449740136448.0000\n",
            "Epoch 1789/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449700814848.0000\n",
            "Epoch 1790/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449712087040.0000\n",
            "Epoch 1791/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449582063616.0000\n",
            "Epoch 1792/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449711562752.0000\n",
            "Epoch 1793/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449757700096.0000\n",
            "Epoch 1794/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449577869312.0000\n",
            "Epoch 1795/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449611948032.0000\n",
            "Epoch 1796/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449663852544.0000\n",
            "Epoch 1797/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449922850816.0000\n",
            "Epoch 1798/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449719427072.0000\n",
            "Epoch 1799/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449669357568.0000\n",
            "Epoch 1800/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449786011648.0000\n",
            "Epoch 1801/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449675911168.0000\n",
            "Epoch 1802/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449666998272.0000\n",
            "Epoch 1803/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449792040960.0000\n",
            "Epoch 1804/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449814061056.0000\n",
            "Epoch 1805/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449856266240.0000\n",
            "Epoch 1806/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449482973184.0000\n",
            "Epoch 1807/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449699241984.0000\n",
            "Epoch 1808/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449633968128.0000\n",
            "Epoch 1809/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449650483200.0000\n",
            "Epoch 1810/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449694785536.0000\n",
            "Epoch 1811/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449603559424.0000\n",
            "Epoch 1812/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449481662464.0000\n",
            "Epoch 1813/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449727553536.0000\n",
            "Epoch 1814/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449617190912.0000\n",
            "Epoch 1815/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449821663232.0000\n",
            "Epoch 1816/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449608278016.0000\n",
            "Epoch 1817/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449594908672.0000\n",
            "Epoch 1818/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449676173312.0000\n",
            "Epoch 1819/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449455710208.0000\n",
            "Epoch 1820/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449740136448.0000\n",
            "Epoch 1821/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449586782208.0000\n",
            "Epoch 1822/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449392009216.0000\n",
            "Epoch 1823/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449841324032.0000\n",
            "Epoch 1824/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449583636480.0000\n",
            "Epoch 1825/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449502896128.0000\n",
            "Epoch 1826/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449565286400.0000\n",
            "Epoch 1827/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449680367616.0000\n",
            "Epoch 1828/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449626890240.0000\n",
            "Epoch 1829/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449590452224.0000\n",
            "Epoch 1830/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449787322368.0000\n",
            "Epoch 1831/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449516527616.0000\n",
            "Epoch 1832/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449532780544.0000\n",
            "Epoch 1833/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449576820736.0000\n",
            "Epoch 1834/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449672503296.0000\n",
            "Epoch 1835/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449478516736.0000\n",
            "Epoch 1836/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449566072832.0000\n",
            "Epoch 1837/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449680629760.0000\n",
            "Epoch 1838/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449527537664.0000\n",
            "Epoch 1839/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449595695104.0000\n",
            "Epoch 1840/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449616142336.0000\n",
            "Epoch 1841/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449570004992.0000\n",
            "Epoch 1842/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449620336640.0000\n",
            "Epoch 1843/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449467244544.0000\n",
            "Epoch 1844/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449653628928.0000\n",
            "Epoch 1845/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449655988224.0000\n",
            "Epoch 1846/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449795973120.0000\n",
            "Epoch 1847/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449558208512.0000\n",
            "Epoch 1848/2500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2449356619776.0000\n",
            "Epoch 1849/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449461477376.0000\n",
            "Epoch 1850/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449509711872.0000\n",
            "Epoch 1851/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449602510848.0000\n",
            "Epoch 1852/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449400397824.0000\n",
            "Epoch 1853/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449536712704.0000\n",
            "Epoch 1854/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449599627264.0000\n",
            "Epoch 1855/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449562402816.0000\n",
            "Epoch 1856/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449470652416.0000\n",
            "Epoch 1857/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449396989952.0000\n",
            "Epoch 1858/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449601986560.0000\n",
            "Epoch 1859/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449301307392.0000\n",
            "Epoch 1860/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449504731136.0000\n",
            "Epoch 1861/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449384669184.0000\n",
            "Epoch 1862/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449435262976.0000\n",
            "Epoch 1863/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449440243712.0000\n",
            "Epoch 1864/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449671979008.0000\n",
            "Epoch 1865/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449493983232.0000\n",
            "Epoch 1866/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449363173376.0000\n",
            "Epoch 1867/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449348755456.0000\n",
            "Epoch 1868/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449377591296.0000\n",
            "Epoch 1869/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449593597952.0000\n",
            "Epoch 1870/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449413505024.0000\n",
            "Epoch 1871/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449410883584.0000\n",
            "Epoch 1872/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449382834176.0000\n",
            "Epoch 1873/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449384669184.0000\n",
            "Epoch 1874/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449272733696.0000\n",
            "Epoch 1875/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449430282240.0000\n",
            "Epoch 1876/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449281122304.0000\n",
            "Epoch 1877/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449330929664.0000\n",
            "Epoch 1878/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449735942144.0000\n",
            "Epoch 1879/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449296326656.0000\n",
            "Epoch 1880/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449370513408.0000\n",
            "Epoch 1881/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449459904512.0000\n",
            "Epoch 1882/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449275355136.0000\n",
            "Epoch 1883/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449441554432.0000\n",
            "Epoch 1884/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449325686784.0000\n",
            "Epoch 1885/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449324376064.0000\n",
            "Epoch 1886/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449328046080.0000\n",
            "Epoch 1887/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449338007552.0000\n",
            "Epoch 1888/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449428185088.0000\n",
            "Epoch 1889/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449555849216.0000\n",
            "Epoch 1890/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449296588800.0000\n",
            "Epoch 1891/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449197236224.0000\n",
            "Epoch 1892/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449303404544.0000\n",
            "Epoch 1893/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449336958976.0000\n",
            "Epoch 1894/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449300258816.0000\n",
            "Epoch 1895/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449212964864.0000\n",
            "Epoch 1896/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449346396160.0000\n",
            "Epoch 1897/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449435787264.0000\n",
            "Epoch 1898/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449269063680.0000\n",
            "Epoch 1899/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449152147456.0000\n",
            "Epoch 1900/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449331453952.0000\n",
            "Epoch 1901/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449293443072.0000\n",
            "Epoch 1902/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449170235392.0000\n",
            "Epoch 1903/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449201168384.0000\n",
            "Epoch 1904/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449270374400.0000\n",
            "Epoch 1905/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449204051968.0000\n",
            "Epoch 1906/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449243897856.0000\n",
            "Epoch 1907/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449314414592.0000\n",
            "Epoch 1908/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449134059520.0000\n",
            "Epoch 1909/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449200119808.0000\n",
            "Epoch 1910/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449306025984.0000\n",
            "Epoch 1911/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449287938048.0000\n",
            "Epoch 1912/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449241276416.0000\n",
            "Epoch 1913/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449146642432.0000\n",
            "Epoch 1914/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449189896192.0000\n",
            "Epoch 1915/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449182818304.0000\n",
            "Epoch 1916/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449273520128.0000\n",
            "Epoch 1917/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449050435584.0000\n",
            "Epoch 1918/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449255956480.0000\n",
            "Epoch 1919/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449084514304.0000\n",
            "Epoch 1920/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449274568704.0000\n",
            "Epoch 1921/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449056727040.0000\n",
            "Epoch 1922/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449142185984.0000\n",
            "Epoch 1923/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449148215296.0000\n",
            "Epoch 1924/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449158963200.0000\n",
            "Epoch 1925/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449219780608.0000\n",
            "Epoch 1926/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449209556992.0000\n",
            "Epoch 1927/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449294753792.0000\n",
            "Epoch 1928/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449019764736.0000\n",
            "Epoch 1929/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449074552832.0000\n",
            "Epoch 1930/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449294491648.0000\n",
            "Epoch 1931/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449150050304.0000\n",
            "Epoch 1932/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449198809088.0000\n",
            "Epoch 1933/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449006395392.0000\n",
            "Epoch 1934/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449104961536.0000\n",
            "Epoch 1935/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449176788992.0000\n",
            "Epoch 1936/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449077698560.0000\n",
            "Epoch 1937/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449130651648.0000\n",
            "Epoch 1938/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449197236224.0000\n",
            "Epoch 1939/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448995909632.0000\n",
            "Epoch 1940/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2449126457344.0000\n",
            "Epoch 1941/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449066426368.0000\n",
            "Epoch 1942/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449108369408.0000\n",
            "Epoch 1943/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449172070400.0000\n",
            "Epoch 1944/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448962355200.0000\n",
            "Epoch 1945/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449070620672.0000\n",
            "Epoch 1946/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449216110592.0000\n",
            "Epoch 1947/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448978345984.0000\n",
            "Epoch 1948/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449289773056.0000\n",
            "Epoch 1949/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448998268928.0000\n",
            "Epoch 1950/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449138778112.0000\n",
            "Epoch 1951/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448974413824.0000\n",
            "Epoch 1952/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448990928896.0000\n",
            "Epoch 1953/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449433952256.0000\n",
            "Epoch 1954/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449047027712.0000\n",
            "Epoch 1955/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449119903744.0000\n",
            "Epoch 1956/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449090543616.0000\n",
            "Epoch 1957/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449005871104.0000\n",
            "Epoch 1958/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449095786496.0000\n",
            "Epoch 1959/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449049387008.0000\n",
            "Epoch 1960/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449097359360.0000\n",
            "Epoch 1961/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449053057024.0000\n",
            "Epoch 1962/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449047027712.0000\n",
            "Epoch 1963/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449111777280.0000\n",
            "Epoch 1964/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449013735424.0000\n",
            "Epoch 1965/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448896032768.0000\n",
            "Epoch 1966/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449391222784.0000\n",
            "Epoch 1967/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449053319168.0000\n",
            "Epoch 1968/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449021337600.0000\n",
            "Epoch 1969/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448996433920.0000\n",
            "Epoch 1970/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449009278976.0000\n",
            "Epoch 1971/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449018978304.0000\n",
            "Epoch 1972/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449066426368.0000\n",
            "Epoch 1973/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448962617344.0000\n",
            "Epoch 1974/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448975986688.0000\n",
            "Epoch 1975/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448935092224.0000\n",
            "Epoch 1976/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449032609792.0000\n",
            "Epoch 1977/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448788291584.0000\n",
            "Epoch 1978/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449111515136.0000\n",
            "Epoch 1979/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449020813312.0000\n",
            "Epoch 1980/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448847273984.0000\n",
            "Epoch 1981/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448891838464.0000\n",
            "Epoch 1982/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448991191040.0000\n",
            "Epoch 1983/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449092640768.0000\n",
            "Epoch 1984/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448899440640.0000\n",
            "Epoch 1985/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448978870272.0000\n",
            "Epoch 1986/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448962093056.0000\n",
            "Epoch 1987/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448991453184.0000\n",
            "Epoch 1988/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448879517696.0000\n",
            "Epoch 1989/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448799301632.0000\n",
            "Epoch 1990/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448911761408.0000\n",
            "Epoch 1991/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448989618176.0000\n",
            "Epoch 1992/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448963665920.0000\n",
            "Epoch 1993/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448898129920.0000\n",
            "Epoch 1994/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449047552000.0000\n",
            "Epoch 1995/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448948199424.0000\n",
            "Epoch 1996/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448758407168.0000\n",
            "Epoch 1997/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448792485888.0000\n",
            "Epoch 1998/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448983851008.0000\n",
            "Epoch 1999/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448874012672.0000\n",
            "Epoch 2000/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449034444800.0000\n",
            "Epoch 2001/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448798515200.0000\n",
            "Epoch 2002/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448791437312.0000\n",
            "Epoch 2003/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448940859392.0000\n",
            "Epoch 2004/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448804806656.0000\n",
            "Epoch 2005/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448941907968.0000\n",
            "Epoch 2006/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448879255552.0000\n",
            "Epoch 2007/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448941907968.0000\n",
            "Epoch 2008/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448707551232.0000\n",
            "Epoch 2009/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448885284864.0000\n",
            "Epoch 2010/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449066164224.0000\n",
            "Epoch 2011/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448825778176.0000\n",
            "Epoch 2012/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448873488384.0000\n",
            "Epoch 2013/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448773611520.0000\n",
            "Epoch 2014/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448838885376.0000\n",
            "Epoch 2015/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448863264768.0000\n",
            "Epoch 2016/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448639918080.0000\n",
            "Epoch 2017/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2449087135744.0000\n",
            "Epoch 2018/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448700735488.0000\n",
            "Epoch 2019/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448750542848.0000\n",
            "Epoch 2020/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448836788224.0000\n",
            "Epoch 2021/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448810835968.0000\n",
            "Epoch 2022/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448809263104.0000\n",
            "Epoch 2023/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448793534464.0000\n",
            "Epoch 2024/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448857235456.0000\n",
            "Epoch 2025/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2449091067904.0000\n",
            "Epoch 2026/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448789078016.0000\n",
            "Epoch 2027/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448713056256.0000\n",
            "Epoch 2028/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448810835968.0000\n",
            "Epoch 2029/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448903110656.0000\n",
            "Epoch 2030/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448746610688.0000\n",
            "Epoch 2031/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448749494272.0000\n",
            "Epoch 2032/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448681336832.0000\n",
            "Epoch 2033/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448747397120.0000\n",
            "Epoch 2034/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448845701120.0000\n",
            "Epoch 2035/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448728522752.0000\n",
            "Epoch 2036/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448810311680.0000\n",
            "Epoch 2037/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448622354432.0000\n",
            "Epoch 2038/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448802185216.0000\n",
            "Epoch 2039/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448800612352.0000\n",
            "Epoch 2040/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448872701952.0000\n",
            "Epoch 2041/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448728522752.0000\n",
            "Epoch 2042/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448612392960.0000\n",
            "Epoch 2043/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448578052096.0000\n",
            "Epoch 2044/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448974938112.0000\n",
            "Epoch 2045/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448641753088.0000\n",
            "Epoch 2046/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448850681856.0000\n",
            "Epoch 2047/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448624975872.0000\n",
            "Epoch 2048/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448724328448.0000\n",
            "Epoch 2049/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448675831808.0000\n",
            "Epoch 2050/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448713318400.0000\n",
            "Epoch 2051/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448650141696.0000\n",
            "Epoch 2052/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448608460800.0000\n",
            "Epoch 2053/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448709386240.0000\n",
            "Epoch 2054/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448638345216.0000\n",
            "Epoch 2055/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2448587489280.0000\n",
            "Epoch 2056/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448827351040.0000\n",
            "Epoch 2057/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448770203648.0000\n",
            "Epoch 2058/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448546070528.0000\n",
            "Epoch 2059/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448886595584.0000\n",
            "Epoch 2060/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2448634413056.0000\n",
            "Epoch 2061/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448694706176.0000\n",
            "Epoch 2062/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448739008512.0000\n",
            "Epoch 2063/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2448531390464.0000\n",
            "Epoch 2064/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448650665984.0000\n",
            "Epoch 2065/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448823418880.0000\n",
            "Epoch 2066/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448571498496.0000\n",
            "Epoch 2067/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448513040384.0000\n",
            "Epoch 2068/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448629432320.0000\n",
            "Epoch 2069/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448770203648.0000\n",
            "Epoch 2070/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448553410560.0000\n",
            "Epoch 2071/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448599810048.0000\n",
            "Epoch 2072/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2448624451584.0000\n",
            "Epoch 2073/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448670588928.0000\n",
            "Epoch 2074/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448649355264.0000\n",
            "Epoch 2075/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448755523584.0000\n",
            "Epoch 2076/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448509632512.0000\n",
            "Epoch 2077/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448629170176.0000\n",
            "Epoch 2078/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448825253888.0000\n",
            "Epoch 2079/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448593780736.0000\n",
            "Epoch 2080/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448763125760.0000\n",
            "Epoch 2081/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448520380416.0000\n",
            "Epoch 2082/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448558653440.0000\n",
            "Epoch 2083/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448646995968.0000\n",
            "Epoch 2084/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448584605696.0000\n",
            "Epoch 2085/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448493117440.0000\n",
            "Epoch 2086/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448669016064.0000\n",
            "Epoch 2087/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448465330176.0000\n",
            "Epoch 2088/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448679763968.0000\n",
            "Epoch 2089/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448511991808.0000\n",
            "Epoch 2090/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448524574720.0000\n",
            "Epoch 2091/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448539254784.0000\n",
            "Epoch 2092/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448883187712.0000\n",
            "Epoch 2093/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448499933184.0000\n",
            "Epoch 2094/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448488398848.0000\n",
            "Epoch 2095/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448485515264.0000\n",
            "Epoch 2096/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448592207872.0000\n",
            "Epoch 2097/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448568352768.0000\n",
            "Epoch 2098/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448634150912.0000\n",
            "Epoch 2099/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448482893824.0000\n",
            "Epoch 2100/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448678453248.0000\n",
            "Epoch 2101/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448467689472.0000\n",
            "Epoch 2102/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448567566336.0000\n",
            "Epoch 2103/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448659578880.0000\n",
            "Epoch 2104/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448520380416.0000\n",
            "Epoch 2105/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448566779904.0000\n",
            "Epoch 2106/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448669016064.0000\n",
            "Epoch 2107/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448433086464.0000\n",
            "Epoch 2108/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448532701184.0000\n",
            "Epoch 2109/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448472670208.0000\n",
            "Epoch 2110/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448519856128.0000\n",
            "Epoch 2111/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448603480064.0000\n",
            "Epoch 2112/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448399007744.0000\n",
            "Epoch 2113/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448492331008.0000\n",
            "Epoch 2114/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448519856128.0000\n",
            "Epoch 2115/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448614227968.0000\n",
            "Epoch 2116/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448441475072.0000\n",
            "Epoch 2117/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448347627520.0000\n",
            "Epoch 2118/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448489185280.0000\n",
            "Epoch 2119/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448516972544.0000\n",
            "Epoch 2120/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448536371200.0000\n",
            "Epoch 2121/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448623927296.0000\n",
            "Epoch 2122/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448445669376.0000\n",
            "Epoch 2123/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448455368704.0000\n",
            "Epoch 2124/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448556818432.0000\n",
            "Epoch 2125/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448714629120.0000\n",
            "Epoch 2126/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448587227136.0000\n",
            "Epoch 2127/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448453795840.0000\n",
            "Epoch 2128/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448511991808.0000\n",
            "Epoch 2129/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448466378752.0000\n",
            "Epoch 2130/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448456417280.0000\n",
            "Epoch 2131/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448387997696.0000\n",
            "Epoch 2132/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448449863680.0000\n",
            "Epoch 2133/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448371482624.0000\n",
            "Epoch 2134/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448446717952.0000\n",
            "Epoch 2135/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448346841088.0000\n",
            "Epoch 2136/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448399007744.0000\n",
            "Epoch 2137/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448499671040.0000\n",
            "Epoch 2138/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448399532032.0000\n",
            "Epoch 2139/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448568352768.0000\n",
            "Epoch 2140/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448336355328.0000\n",
            "Epoch 2141/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448417095680.0000\n",
            "Epoch 2142/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448357588992.0000\n",
            "Epoch 2143/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448395075584.0000\n",
            "Epoch 2144/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448378036224.0000\n",
            "Epoch 2145/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448356016128.0000\n",
            "Epoch 2146/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448704143360.0000\n",
            "Epoch 2147/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448376201216.0000\n",
            "Epoch 2148/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448293101568.0000\n",
            "Epoch 2149/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448401629184.0000\n",
            "Epoch 2150/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448457990144.0000\n",
            "Epoch 2151/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448320102400.0000\n",
            "Epoch 2152/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448368861184.0000\n",
            "Epoch 2153/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448273702912.0000\n",
            "Epoch 2154/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448375152640.0000\n",
            "Epoch 2155/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448374366208.0000\n",
            "Epoch 2156/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448334520320.0000\n",
            "Epoch 2157/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448520904704.0000\n",
            "Epoch 2158/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448380133376.0000\n",
            "Epoch 2159/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448280256512.0000\n",
            "Epoch 2160/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448536895488.0000\n",
            "Epoch 2161/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448384065536.0000\n",
            "Epoch 2162/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448316694528.0000\n",
            "Epoch 2163/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448187981824.0000\n",
            "Epoch 2164/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448456417280.0000\n",
            "Epoch 2165/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448447242240.0000\n",
            "Epoch 2166/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448412114944.0000\n",
            "Epoch 2167/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448333471744.0000\n",
            "Epoch 2168/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448324296704.0000\n",
            "Epoch 2169/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448631005184.0000\n",
            "Epoch 2170/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448311189504.0000\n",
            "Epoch 2171/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448280780800.0000\n",
            "Epoch 2172/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448426795008.0000\n",
            "Epoch 2173/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448376463360.0000\n",
            "Epoch 2174/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448196894720.0000\n",
            "Epoch 2175/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448225992704.0000\n",
            "Epoch 2176/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448266625024.0000\n",
            "Epoch 2177/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448530604032.0000\n",
            "Epoch 2178/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448330850304.0000\n",
            "Epoch 2179/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448279994368.0000\n",
            "Epoch 2180/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448330326016.0000\n",
            "Epoch 2181/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448302800896.0000\n",
            "Epoch 2182/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448315908096.0000\n",
            "Epoch 2183/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448269770752.0000\n",
            "Epoch 2184/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448198205440.0000\n",
            "Epoch 2185/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448387473408.0000\n",
            "Epoch 2186/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448180641792.0000\n",
            "Epoch 2187/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448275537920.0000\n",
            "Epoch 2188/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448341073920.0000\n",
            "Epoch 2189/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448221536256.0000\n",
            "Epoch 2190/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448375152640.0000\n",
            "Epoch 2191/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448219701248.0000\n",
            "Epoch 2192/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448233594880.0000\n",
            "Epoch 2193/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448331898880.0000\n",
            "Epoch 2194/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448135290880.0000\n",
            "Epoch 2195/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448307257344.0000\n",
            "Epoch 2196/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448285237248.0000\n",
            "Epoch 2197/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448081289216.0000\n",
            "Epoch 2198/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448328753152.0000\n",
            "Epoch 2199/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448329539584.0000\n",
            "Epoch 2200/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448116154368.0000\n",
            "Epoch 2201/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448147087360.0000\n",
            "Epoch 2202/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448348938240.0000\n",
            "Epoch 2203/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448121397248.0000\n",
            "Epoch 2204/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448261120000.0000\n",
            "Epoch 2205/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448175923200.0000\n",
            "Epoch 2206/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448304111616.0000\n",
            "Epoch 2207/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448094920704.0000\n",
            "Epoch 2208/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448313286656.0000\n",
            "Epoch 2209/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448223371264.0000\n",
            "Epoch 2210/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448165961728.0000\n",
            "Epoch 2211/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448167534592.0000\n",
            "Epoch 2212/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448164388864.0000\n",
            "Epoch 2213/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448155213824.0000\n",
            "Epoch 2214/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448165175296.0000\n",
            "Epoch 2215/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448385638400.0000\n",
            "Epoch 2216/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448170156032.0000\n",
            "Epoch 2217/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448235954176.0000\n",
            "Epoch 2218/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448158359552.0000\n",
            "Epoch 2219/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448179331072.0000\n",
            "Epoch 2220/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448251420672.0000\n",
            "Epoch 2221/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448258498560.0000\n",
            "Epoch 2222/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448009723904.0000\n",
            "Epoch 2223/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448095707136.0000\n",
            "Epoch 2224/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448425746432.0000\n",
            "Epoch 2225/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448092823552.0000\n",
            "Epoch 2226/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448082075648.0000\n",
            "Epoch 2227/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448120348672.0000\n",
            "Epoch 2228/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448293888000.0000\n",
            "Epoch 2229/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448107503616.0000\n",
            "Epoch 2230/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448134242304.0000\n",
            "Epoch 2231/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448110911488.0000\n",
            "Epoch 2232/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448158097408.0000\n",
            "Epoch 2233/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448083124224.0000\n",
            "Epoch 2234/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448148660224.0000\n",
            "Epoch 2235/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448132407296.0000\n",
            "Epoch 2236/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448083910656.0000\n",
            "Epoch 2237/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448101998592.0000\n",
            "Epoch 2238/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2448207380480.0000\n",
            "Epoch 2239/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448198205440.0000\n",
            "Epoch 2240/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2448178806784.0000\n",
            "Epoch 2241/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448300965888.0000\n",
            "Epoch 2242/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2447974596608.0000\n",
            "Epoch 2243/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448283140096.0000\n",
            "Epoch 2244/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447997927424.0000\n",
            "Epoch 2245/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448223633408.0000\n",
            "Epoch 2246/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447992684544.0000\n",
            "Epoch 2247/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448014442496.0000\n",
            "Epoch 2248/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2448020996096.0000\n",
            "Epoch 2249/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2448024141824.0000\n",
            "Epoch 2250/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448210526208.0000\n",
            "Epoch 2251/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448102785024.0000\n",
            "Epoch 2252/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448026501120.0000\n",
            "Epoch 2253/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448172253184.0000\n",
            "Epoch 2254/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448117989376.0000\n",
            "Epoch 2255/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447924527104.0000\n",
            "Epoch 2256/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447973023744.0000\n",
            "Epoch 2257/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448411852800.0000\n",
            "Epoch 2258/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448032530432.0000\n",
            "Epoch 2259/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448128475136.0000\n",
            "Epoch 2260/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447945760768.0000\n",
            "Epoch 2261/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447959130112.0000\n",
            "Epoch 2262/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447875244032.0000\n",
            "Epoch 2263/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448092561408.0000\n",
            "Epoch 2264/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448194273280.0000\n",
            "Epoch 2265/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448051142656.0000\n",
            "Epoch 2266/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447974858752.0000\n",
            "Epoch 2267/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2448034627584.0000\n",
            "Epoch 2268/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447943401472.0000\n",
            "Epoch 2269/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448109600768.0000\n",
            "Epoch 2270/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447995043840.0000\n",
            "Epoch 2271/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447974334464.0000\n",
            "Epoch 2272/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2447958867968.0000\n",
            "Epoch 2273/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448090202112.0000\n",
            "Epoch 2274/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447830417408.0000\n",
            "Epoch 2275/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448100687872.0000\n",
            "Epoch 2276/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447915352064.0000\n",
            "Epoch 2277/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447863709696.0000\n",
            "Epoch 2278/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448117465088.0000\n",
            "Epoch 2279/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448049307648.0000\n",
            "Epoch 2280/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448156262400.0000\n",
            "Epoch 2281/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448105930752.0000\n",
            "Epoch 2282/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447914827776.0000\n",
            "Epoch 2283/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447894380544.0000\n",
            "Epoch 2284/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448158359552.0000\n",
            "Epoch 2285/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447996878848.0000\n",
            "Epoch 2286/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448072114176.0000\n",
            "Epoch 2287/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448054812672.0000\n",
            "Epoch 2288/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447975383040.0000\n",
            "Epoch 2289/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447981412352.0000\n",
            "Epoch 2290/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447904604160.0000\n",
            "Epoch 2291/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448082337792.0000\n",
            "Epoch 2292/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447871836160.0000\n",
            "Epoch 2293/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448030171136.0000\n",
            "Epoch 2294/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448027287552.0000\n",
            "Epoch 2295/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447944187904.0000\n",
            "Epoch 2296/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2448005529600.0000\n",
            "Epoch 2297/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447996354560.0000\n",
            "Epoch 2298/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447906701312.0000\n",
            "Epoch 2299/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448069230592.0000\n",
            "Epoch 2300/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447987441664.0000\n",
            "Epoch 2301/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447872884736.0000\n",
            "Epoch 2302/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447921643520.0000\n",
            "Epoch 2303/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448036986880.0000\n",
            "Epoch 2304/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447854272512.0000\n",
            "Epoch 2305/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447879176192.0000\n",
            "Epoch 2306/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447749939200.0000\n",
            "Epoch 2307/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447966732288.0000\n",
            "Epoch 2308/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447833300992.0000\n",
            "Epoch 2309/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447876030464.0000\n",
            "Epoch 2310/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2447964110848.0000\n",
            "Epoch 2311/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447863709696.0000\n",
            "Epoch 2312/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447830417408.0000\n",
            "Epoch 2313/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447818096640.0000\n",
            "Epoch 2314/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447970664448.0000\n",
            "Epoch 2315/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447876554752.0000\n",
            "Epoch 2316/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447904866304.0000\n",
            "Epoch 2317/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447989538816.0000\n",
            "Epoch 2318/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2448053239808.0000\n",
            "Epoch 2319/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447850864640.0000\n",
            "Epoch 2320/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448117727232.0000\n",
            "Epoch 2321/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447905652736.0000\n",
            "Epoch 2322/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447756754944.0000\n",
            "Epoch 2323/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447877603328.0000\n",
            "Epoch 2324/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447891234816.0000\n",
            "Epoch 2325/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2447861350400.0000\n",
            "Epoch 2326/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447969878016.0000\n",
            "Epoch 2327/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447811543040.0000\n",
            "Epoch 2328/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447821242368.0000\n",
            "Epoch 2329/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447983509504.0000\n",
            "Epoch 2330/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447763570688.0000\n",
            "Epoch 2331/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447835922432.0000\n",
            "Epoch 2332/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447924264960.0000\n",
            "Epoch 2333/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447854534656.0000\n",
            "Epoch 2334/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2447872884736.0000\n",
            "Epoch 2335/2500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2447760949248.0000\n",
            "Epoch 2336/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447808397312.0000\n",
            "Epoch 2337/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447872098304.0000\n",
            "Epoch 2338/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447945760768.0000\n",
            "Epoch 2339/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2447812067328.0000\n",
            "Epoch 2340/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447731064832.0000\n",
            "Epoch 2341/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447765929984.0000\n",
            "Epoch 2342/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447915352064.0000\n",
            "Epoch 2343/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447746793472.0000\n",
            "Epoch 2344/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448014966784.0000\n",
            "Epoch 2345/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447683354624.0000\n",
            "Epoch 2346/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447825698816.0000\n",
            "Epoch 2347/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2448041967616.0000\n",
            "Epoch 2348/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447762784256.0000\n",
            "Epoch 2349/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447872884736.0000\n",
            "Epoch 2350/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447718744064.0000\n",
            "Epoch 2351/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447903817728.0000\n",
            "Epoch 2352/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447772745728.0000\n",
            "Epoch 2353/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447726870528.0000\n",
            "Epoch 2354/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447791357952.0000\n",
            "Epoch 2355/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447818096640.0000\n",
            "Epoch 2356/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447798435840.0000\n",
            "Epoch 2357/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447792144384.0000\n",
            "Epoch 2358/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447639314432.0000\n",
            "Epoch 2359/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447740764160.0000\n",
            "Epoch 2360/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447857942528.0000\n",
            "Epoch 2361/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447851913216.0000\n",
            "Epoch 2362/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447731851264.0000\n",
            "Epoch 2363/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447727132672.0000\n",
            "Epoch 2364/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447661334528.0000\n",
            "Epoch 2365/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2447981936640.0000\n",
            "Epoch 2366/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447675752448.0000\n",
            "Epoch 2367/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2447588720640.0000\n",
            "Epoch 2368/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447601041408.0000\n",
            "Epoch 2369/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447930294272.0000\n",
            "Epoch 2370/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447944712192.0000\n",
            "Epoch 2371/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447890448384.0000\n",
            "Epoch 2372/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447647440896.0000\n",
            "Epoch 2373/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447871311872.0000\n",
            "Epoch 2374/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447566700544.0000\n",
            "Epoch 2375/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447680471040.0000\n",
            "Epoch 2376/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447776153600.0000\n",
            "Epoch 2377/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447776677888.0000\n",
            "Epoch 2378/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447687548928.0000\n",
            "Epoch 2379/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447887040512.0000\n",
            "Epoch 2380/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447627517952.0000\n",
            "Epoch 2381/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447752036352.0000\n",
            "Epoch 2382/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2447880486912.0000\n",
            "Epoch 2383/2500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2447595274240.0000\n",
            "Epoch 2384/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447752822784.0000\n",
            "Epoch 2385/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447678636032.0000\n",
            "Epoch 2386/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447733161984.0000\n",
            "Epoch 2387/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447749939200.0000\n",
            "Epoch 2388/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447967780864.0000\n",
            "Epoch 2389/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447640363008.0000\n",
            "Epoch 2390/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447715598336.0000\n",
            "Epoch 2391/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447629090816.0000\n",
            "Epoch 2392/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447614672896.0000\n",
            "Epoch 2393/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447659237376.0000\n",
            "Epoch 2394/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447602614272.0000\n",
            "Epoch 2395/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447719268352.0000\n",
            "Epoch 2396/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447548612608.0000\n",
            "Epoch 2397/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447785852928.0000\n",
            "Epoch 2398/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447550971904.0000\n",
            "Epoch 2399/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447604973568.0000\n",
            "Epoch 2400/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447803678720.0000\n",
            "Epoch 2401/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447754133504.0000\n",
            "Epoch 2402/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447634595840.0000\n",
            "Epoch 2403/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447587147776.0000\n",
            "Epoch 2404/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447680208896.0000\n",
            "Epoch 2405/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447613624320.0000\n",
            "Epoch 2406/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447702491136.0000\n",
            "Epoch 2407/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447755706368.0000\n",
            "Epoch 2408/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447474425856.0000\n",
            "Epoch 2409/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447652421632.0000\n",
            "Epoch 2410/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447597895680.0000\n",
            "Epoch 2411/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447530524672.0000\n",
            "Epoch 2412/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447673393152.0000\n",
            "Epoch 2413/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447555690496.0000\n",
            "Epoch 2414/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447689383936.0000\n",
            "Epoch 2415/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447569059840.0000\n",
            "Epoch 2416/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447725821952.0000\n",
            "Epoch 2417/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447700131840.0000\n",
            "Epoch 2418/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447615721472.0000\n",
            "Epoch 2419/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447620177920.0000\n",
            "Epoch 2420/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447678373888.0000\n",
            "Epoch 2421/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447761735680.0000\n",
            "Epoch 2422/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447493038080.0000\n",
            "Epoch 2423/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447661858816.0000\n",
            "Epoch 2424/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447579807744.0000\n",
            "Epoch 2425/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447586361344.0000\n",
            "Epoch 2426/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447557525504.0000\n",
            "Epoch 2427/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447437987840.0000\n",
            "Epoch 2428/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447738667008.0000\n",
            "Epoch 2429/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447677587456.0000\n",
            "Epoch 2430/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447532359680.0000\n",
            "Epoch 2431/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447638003712.0000\n",
            "Epoch 2432/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447532359680.0000\n",
            "Epoch 2433/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447460007936.0000\n",
            "Epoch 2434/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447763832832.0000\n",
            "Epoch 2435/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447490940928.0000\n",
            "Epoch 2436/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447450570752.0000\n",
            "Epoch 2437/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447490416640.0000\n",
            "Epoch 2438/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447612051456.0000\n",
            "Epoch 2439/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447550709760.0000\n",
            "Epoch 2440/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447558311936.0000\n",
            "Epoch 2441/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447515320320.0000\n",
            "Epoch 2442/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447462367232.0000\n",
            "Epoch 2443/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447635120128.0000\n",
            "Epoch 2444/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447540224000.0000\n",
            "Epoch 2445/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447638003712.0000\n",
            "Epoch 2446/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447501164544.0000\n",
            "Epoch 2447/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447507718144.0000\n",
            "Epoch 2448/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447489105920.0000\n",
            "Epoch 2449/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447565127680.0000\n",
            "Epoch 2450/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447643508736.0000\n",
            "Epoch 2451/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447450832896.0000\n",
            "Epoch 2452/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447517417472.0000\n",
            "Epoch 2453/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447423569920.0000\n",
            "Epoch 2454/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447456862208.0000\n",
            "Epoch 2455/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447538388992.0000\n",
            "Epoch 2456/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447739453440.0000\n",
            "Epoch 2457/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447483338752.0000\n",
            "Epoch 2458/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447398928384.0000\n",
            "Epoch 2459/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447482290176.0000\n",
            "Epoch 2460/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447504048128.0000\n",
            "Epoch 2461/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447695151104.0000\n",
            "Epoch 2462/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447585312768.0000\n",
            "Epoch 2463/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447513485312.0000\n",
            "Epoch 2464/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447431958528.0000\n",
            "Epoch 2465/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447449260032.0000\n",
            "Epoch 2466/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447468396544.0000\n",
            "Epoch 2467/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447452930048.0000\n",
            "Epoch 2468/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447407054848.0000\n",
            "Epoch 2469/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447552020480.0000\n",
            "Epoch 2470/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447453716480.0000\n",
            "Epoch 2471/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447449260032.0000\n",
            "Epoch 2472/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447383461888.0000\n",
            "Epoch 2473/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447501164544.0000\n",
            "Epoch 2474/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447331295232.0000\n",
            "Epoch 2475/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447649013760.0000\n",
            "Epoch 2476/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447519514624.0000\n",
            "Epoch 2477/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447373762560.0000\n",
            "Epoch 2478/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447633547264.0000\n",
            "Epoch 2479/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447492775936.0000\n",
            "Epoch 2480/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447430385664.0000\n",
            "Epoch 2481/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447408103424.0000\n",
            "Epoch 2482/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447652683776.0000\n",
            "Epoch 2483/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447384510464.0000\n",
            "Epoch 2484/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447394734080.0000\n",
            "Epoch 2485/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447410724864.0000\n",
            "Epoch 2486/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447414919168.0000\n",
            "Epoch 2487/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447557263360.0000\n",
            "Epoch 2488/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447412822016.0000\n",
            "Epoch 2489/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447352528896.0000\n",
            "Epoch 2490/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447749414912.0000\n",
            "Epoch 2491/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447344140288.0000\n",
            "Epoch 2492/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447304294400.0000\n",
            "Epoch 2493/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447418589184.0000\n",
            "Epoch 2494/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447598682112.0000\n",
            "Epoch 2495/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447625158656.0000\n",
            "Epoch 2496/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447425929216.0000\n",
            "Epoch 2497/2500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2447396569088.0000\n",
            "Epoch 2498/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447424618496.0000\n",
            "Epoch 2499/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447374548992.0000\n",
            "Epoch 2500/2500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2447404957696.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7e35957038b0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df = pd.DataFrame(model.history.history)"
      ],
      "metadata": {
        "id": "-kgeW1uWzjyD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "-2aWVTuXzuZJ",
        "outputId": "20b635a6-c707-4b18-9dcf-52c4565419cb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test,verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZVtePWMzvMy",
        "outputId": "9c10eb7b-a069-449c-a389-c00527eea4a2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2424014635008.0"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train,y_train,verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_ASlKQL2Tp8",
        "outputId": "3b1e96c6-c845-4483-cdab-361ebe3f325d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2447142289408.0"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7TuNCJT2e5A",
        "outputId": "1c8dcef0-d1cc-4320-d747-2d1d0461109c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = pd.Series(test_prediction.reshape(164,))"
      ],
      "metadata": {
        "id": "DsAzltb43PSr"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGJiF_e43mT9",
        "outputId": "d8c1a0a1-b795-4021-9061-8e6805ff23ad"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      3698244.25\n",
              "1      5878722.00\n",
              "2      5878722.00\n",
              "3      4276865.50\n",
              "4      3698244.25\n",
              "          ...    \n",
              "159    4276866.00\n",
              "160    3698244.25\n",
              "161    6457342.50\n",
              "162    5878722.00\n",
              "163    4276865.50\n",
              "Length: 164, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.DataFrame(y_test,columns=['Test True Y'])"
      ],
      "metadata": {
        "id": "XZ-zozMt32fY"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6XMUAbfw3_sA",
        "outputId": "93c8397f-526f-4268-be7b-e2a0d8567bcc"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Test True Y\n",
              "0      4753000\n",
              "1      8890000\n",
              "2      7455000\n",
              "3      3773000\n",
              "4      3780000"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-5691b17c-9a94-4e7b-a10d-b0fca844941e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test True Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4753000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8890000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7455000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3773000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3780000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5691b17c-9a94-4e7b-a10d-b0fca844941e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e17866e7-c18e-4d62-84f8-0bed27f74402\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e17866e7-c18e-4d62-84f8-0bed27f74402')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e17866e7-c18e-4d62-84f8-0bed27f74402 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5691b17c-9a94-4e7b-a10d-b0fca844941e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5691b17c-9a94-4e7b-a10d-b0fca844941e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.concat([pred_df,test_predictions],axis=1)"
      ],
      "metadata": {
        "id": "VCUrWsbJ4BZy"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "t0a-abNx4QrI",
        "outputId": "1ae9a10b-13f3-48aa-e0da-aa02e0f3ccae"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Test True Y           0\n",
              "0    4753000.0  3698244.25\n",
              "1    8890000.0  5878722.00\n",
              "2    7455000.0  5878722.00\n",
              "3    3773000.0  4276865.50\n",
              "4    3780000.0  3698244.25"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-b73b5732-2095-487a-aa59-8c24c798e3ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test True Y</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4753000.0</td>\n",
              "      <td>3698244.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8890000.0</td>\n",
              "      <td>5878722.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7455000.0</td>\n",
              "      <td>5878722.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3773000.0</td>\n",
              "      <td>4276865.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3780000.0</td>\n",
              "      <td>3698244.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b73b5732-2095-487a-aa59-8c24c798e3ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-6f6c68f2-c5f8-41a5-853c-2c7962786631\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f6c68f2-c5f8-41a5-853c-2c7962786631')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-6f6c68f2-c5f8-41a5-853c-2c7962786631 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b73b5732-2095-487a-aa59-8c24c798e3ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b73b5732-2095-487a-aa59-8c24c798e3ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.columns = ['Test True Y','Model Predictions']"
      ],
      "metadata": {
        "id": "8n_YtZ9E4SGv"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Bu2PNKOr41dG",
        "outputId": "eab7aa0e-1d95-478a-d858-474143b4bfc5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Test True Y  Model Predictions\n",
              "0    4753000.0         3698244.25\n",
              "1    8890000.0         5878722.00"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-828f4d5b-4eae-40d9-9820-8b77fb29fbbb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test True Y</th>\n",
              "      <th>Model Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4753000.0</td>\n",
              "      <td>3698244.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8890000.0</td>\n",
              "      <td>5878722.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-828f4d5b-4eae-40d9-9820-8b77fb29fbbb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-38355b1c-16ec-48a8-840b-78eb3bf69814\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38355b1c-16ec-48a8-840b-78eb3bf69814')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-38355b1c-16ec-48a8-840b-78eb3bf69814 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-828f4d5b-4eae-40d9-9820-8b77fb29fbbb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-828f4d5b-4eae-40d9-9820-8b77fb29fbbb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x = 'Test True Y',y='Model Predictions',data = pred_df)\n",
        "\n",
        "#The Model dont fit very well"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "H8eiKxg243KA",
        "outputId": "4bbe658a-5133-4290-d976-95e9f3148755"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Test True Y', ylabel='Model Predictions'>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.dropna(inplace = True)"
      ],
      "metadata": {
        "id": "4n41XWfi6HT1"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error,mean_squared_error"
      ],
      "metadata": {
        "id": "RDpkhFtP5uv9"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(pred_df['Test True Y'],pred_df['Model Predictions'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ls6loLt5zj2",
        "outputId": "543c408b-df79-47e6-e664-1b3e8cf9f2c1"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1136690.631097561"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "c4kNqeqs5aFl",
        "outputId": "326377a1-c44a-4eaf-f108-6ec27e6d765f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              price    bedrooms   bathrooms\n",
              "count  5.450000e+02  545.000000  545.000000\n",
              "mean   4.766729e+06    2.965138    1.286239\n",
              "std    1.870440e+06    0.738064    0.502470\n",
              "min    1.750000e+06    1.000000    1.000000\n",
              "25%    3.430000e+06    2.000000    1.000000\n",
              "50%    4.340000e+06    3.000000    1.000000\n",
              "75%    5.740000e+06    3.000000    2.000000\n",
              "max    1.330000e+07    6.000000    4.000000"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-6512f53b-2df5-4fa1-8cd7-f443eb128485\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.450000e+02</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>545.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.766729e+06</td>\n",
              "      <td>2.965138</td>\n",
              "      <td>1.286239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.870440e+06</td>\n",
              "      <td>0.738064</td>\n",
              "      <td>0.502470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.750000e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.430000e+06</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.340000e+06</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.740000e+06</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.330000e+07</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6512f53b-2df5-4fa1-8cd7-f443eb128485')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-d579c840-4934-4c75-8be3-27944d401eb0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d579c840-4934-4c75-8be3-27944d401eb0')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-d579c840-4934-4c75-8be3-27944d401eb0 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6512f53b-2df5-4fa1-8cd7-f443eb128485 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6512f53b-2df5-4fa1-8cd7-f443eb128485');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(pred_df['Test True Y'],pred_df['Model Predictions'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TFp7AT360HB",
        "outputId": "deec6a63-f10c-4a0f-bfcb-c5bafa95a3a6"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2424014648492.0815"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(mean_squared_error(pred_df['Test True Y'],pred_df['Model Predictions']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEt6kkau7b6R",
        "outputId": "b091ae23-7f7e-49db-e488-cd8b7627b705"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1556924.7407925925"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_gem = [[2,3]]"
      ],
      "metadata": {
        "id": "lbhiGE4M79n3"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_gem = scaler.transform(new_gem)"
      ],
      "metadata": {
        "id": "YL7nWnWD8I6i"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicted Value\n",
        "model.predict(new_gem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI2Z4zHO8OMH",
        "outputId": "c2f641e7-7ff9-4aec-ec92-acfee5fc78e7"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5878721.5]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "eRm-drWK8cih"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_gem_model.h5')"
      ],
      "metadata": {
        "id": "Bud-8umc8gkS"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "later_model = load_model('my_gem_model.h5')"
      ],
      "metadata": {
        "id": "lA0AxrEx8n4o"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "later_model.predict(new_gem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zei6k-ax8tNF",
        "outputId": "efcfaa90-569f-4e0f-a0f7-93e290e920a7"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 247ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5878721.5]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    }
  ]
}